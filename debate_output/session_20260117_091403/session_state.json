{
  "initial_prompt": "Design a simple task queue system with priority support",
  "rounds": [
    {
      "round_number": 1,
      "agent_a": {
        "content": "## Design\n\n# Priority Task Queue System\n\n## Architecture Overview\n\nA priority task queue system with in-memory storage, supporting task submission, priority-based retrieval, status tracking, and concurrent access.\n\n## Core Components\n\n### 1. Task Model\n```python\nfrom enum import Enum\nfrom dataclasses import dataclass\nfrom typing import Optional, Any\nfrom datetime import datetime\nimport uuid\n\nclass TaskStatus(Enum):\n    PENDING = \"pending\"\n    IN_PROGRESS = \"in_progress\"\n    COMPLETED = \"completed\"\n    FAILED = \"failed\"\n    CANCELLED = \"cancelled\"\n\nclass TaskPriority(Enum):\n    LOW = 1\n    MEDIUM = 2\n    HIGH = 3\n    CRITICAL = 4\n\n@dataclass\nclass Task:\n    id: str\n    payload: Any\n    priority: TaskPriority\n    status: TaskStatus\n    created_at: datetime\n    updated_at: datetime\n    started_at: Optional[datetime] = None\n    completed_at: Optional[datetime] = None\n    error_message: Optional[str] = None\n    retry_count: int = 0\n    max_retries: int = 3\n```\n\n### 2. Priority Queue Storage\n```python\nimport heapq\nimport threading\nfrom collections import defaultdict\n\nclass PriorityTaskQueue:\n    def __init__(self):\n        self._lock = threading.RLock()\n        # Min-heap: (-priority, timestamp, task_id) for FIFO within priority\n        self._heap = []\n        # Fast lookup by task ID\n        self._tasks: dict[str, Task] = {}\n        # Counter for insertion order (FIFO within priority)\n        self._counter = 0\n        \n    def enqueue(self, payload: Any, priority: TaskPriority = TaskPriority.MEDIUM) -> str:\n        \"\"\"Add task to queue, return task ID\"\"\"\n        with self._lock:\n            task = Task(\n                id=str(uuid.uuid4()),\n                payload=payload,\n                priority=priority,\n                status=TaskStatus.PENDING,\n                created_at=datetime.utcnow(),\n                updated_at=datetime.utcnow()\n            )\n            self._tasks[task.id] = task\n            # Negative priority for max-heap behavior, counter for FIFO\n            heapq.heappush(self._heap, (-priority.value, self._counter, task.id))\n            self._counter += 1\n            return task.id\n    \n    def dequeue(self) -> Optional[Task]:\n        \"\"\"Get highest priority pending task\"\"\"\n        with self._lock:\n            while self._heap:\n                _, _, task_id = heapq.heappop(self._heap)\n                task = self._tasks.get(task_id)\n                \n                if task and task.status == TaskStatus.PENDING:\n                    task.status = TaskStatus.IN_PROGRESS\n                    task.started_at = datetime.utcnow()\n                    task.updated_at = datetime.utcnow()\n                    return task\n            return None\n    \n    def get_task(self, task_id: str) -> Optional[Task]:\n        \"\"\"Retrieve task by ID\"\"\"\n        with self._lock:\n            return self._tasks.get(task_id)\n    \n    def update_status(self, task_id: str, status: TaskStatus, \n                     error_message: Optional[str] = None):\n        \"\"\"Update task status\"\"\"\n        with self._lock:\n            task = self._tasks.get(task_id)\n            if not task:\n                raise ValueError(f\"Task {task_id} not found\")\n            \n            task.status = status\n            task.updated_at = datetime.utcnow()\n            \n            if status == TaskStatus.COMPLETED:\n                task.completed_at = datetime.utcnow()\n            elif status == TaskStatus.FAILED:\n                task.error_message = error_message\n                task.retry_count += 1\n                \n                # Re-enqueue if retries available\n                if task.retry_count < task.max_retries:\n                    task.status = TaskStatus.PENDING\n                    heapq.heappush(self._heap, \n                                 (-task.priority.value, self._counter, task.id))\n                    self._counter += 1\n    \n    def cancel_task(self, task_id: str) -> bool:\n        \"\"\"Cancel a pending task\"\"\"\n        with self._lock:\n            task = self._tasks.get(task_id)\n            if not task:\n                return False\n            if task.status == TaskStatus.PENDING:\n                task.status = TaskStatus.CANCELLED\n                task.updated_at = datetime.utcnow()\n                return True\n            return False\n    \n    def get_queue_stats(self) -> dict:\n        \"\"\"Get queue statistics\"\"\"\n        with self._lock:\n            status_counts = defaultdict(int)\n            for task in self._tasks.values():\n                status_counts[task.status.value] += 1\n            \n            return {\n                \"total_tasks\": len(self._tasks),\n                \"pending\": status_counts[TaskStatus.PENDING.value],\n                \"in_progress\": status_counts[TaskStatus.IN_PROGRESS.value],\n                \"completed\": status_counts[TaskStatus.COMPLETED.value],\n                \"failed\": status_counts[TaskStatus.FAILED.value],\n                \"cancelled\": status_counts[TaskStatus.CANCELLED.value]\n            }\n```\n\n### 3. Queue Manager Interface\n```python\nclass TaskQueueManager:\n    def __init__(self):\n        self.queue = PriorityTaskQueue()\n    \n    def submit_task(self, payload: Any, priority: str = \"medium\") -> dict:\n        \"\"\"Submit a new task\"\"\"\n        try:\n            priority_enum = TaskPriority[priority.upper()]\n        except KeyError:\n            raise ValueError(f\"Invalid priority: {priority}\")\n        \n        task_id = self.queue.enqueue(payload, priority_enum)\n        return {\"task_id\": task_id, \"status\": \"pending\"}\n    \n    def get_next_task(self) -> Optional[dict]:\n        \"\"\"Worker polls for next task\"\"\"\n        task = self.queue.dequeue()\n        if task:\n            return {\n                \"task_id\": task.id,\n                \"payload\": task.payload,\n                \"priority\": task.priority.name,\n                \"retry_count\": task.retry_count\n            }\n        return None\n    \n    def complete_task(self, task_id: str, success: bool = True, \n                     error: Optional[str] = None):\n        \"\"\"Mark task as completed or failed\"\"\"\n        status = TaskStatus.COMPLETED if success else TaskStatus.FAILED\n        self.queue.update_status(task_id, status, error)\n    \n    def get_task_status(self, task_id: str) -> Optional[dict]:\n        \"\"\"Check task status\"\"\"\n        task = self.queue.get_task(task_id)\n        if not task:\n            return None\n        \n        return {\n            \"task_id\": task.id,\n            \"status\": task.status.value,\n            \"priority\": task.priority.name,\n            \"created_at\": task.created_at.isoformat(),\n            \"started_at\": task.started_at.isoformat() if task.started_at else None,\n            \"completed_at\": task.completed_at.isoformat() if task.completed_at else None,\n            \"error_message\": task.error_message,\n            \"retry_count\": task.retry_count\n        }\n    \n    def cancel_task(self, task_id: str) -> bool:\n        \"\"\"Cancel a pending task\"\"\"\n        return self.queue.cancel_task(task_id)\n    \n    def get_statistics(self) -> dict:\n        \"\"\"Get queue statistics\"\"\"\n        return self.queue.get_queue_stats()\n```\n\n## Error Handling\n\n### 1. Error Categories\n- **ValidationError**: Invalid priority, malformed payload\n- **NotFoundError**: Task ID doesn't exist\n- **StateError**: Invalid state transition (e.g., completing cancelled task)\n- **ConcurrencyError**: Race conditions (handled by locks)\n\n### 2. Retry Logic\n- Tasks automatically retry up to `max_retries` times on failure\n- Exponential backoff can be added by workers between retries\n- Failed tasks preserve error messages for debugging\n\n### 3. Edge Cases\n- Empty queue: `dequeue()` returns `None`\n- Duplicate operations: Idempotent status updates\n- Cancelled tasks: Skipped during dequeue\n- Thread safety: All operations protected by RLock\n\n## Usage Example\n\n```python\n# Initialize\nmanager = TaskQueueManager()\n\n# Submit tasks\ntask1 = manager.submit_task({\"action\": \"send_email\", \"to\": \"user@example.com\"}, \"high\")\ntask2 = manager.submit_task({\"action\": \"generate_report\"}, \"low\")\n\n# Worker loop\nwhile True:\n    task = manager.get_next_task()\n    if task:\n        try:\n            # Process task\n            process(task['payload'])\n            manager.complete_task(task['task_id'], success=True)\n        except Exception as e:\n            manager.complete_task(task['task_id'], success=False, error=str(e))\n    else:\n        time.sleep(1)\n\n# Check status\nstatus = manager.get_task_status(task1['task_id'])\nprint(status)\n```\n\n## Rationale\n\n**In-memory storage**: Chosen for simplicity and speed. For production, this would be replaced with Redis or a persistent database.\n\n**Heap-based priority queue**: Provides O(log n) enqueue and O(log n) dequeue with O(1) task lookup via dictionary. The heap stores tuples of (-priority, counter, task_id) to ensure FIFO ordering within the same priority level.\n\n**Thread-safe design**: RLock allows reentrant locking, preventing deadlocks in complex operations while ensuring atomicity.\n\n**Automatic retry logic**: Built into the queue to handle transient failures without worker complexity.\n\n**Status tracking**: Comprehensive lifecycle tracking enables monitoring, debugging, and audit trails.\n\n## What I Changed\n\nN/A - Initial design\n\n## What I Kept\n\nN/A - Initial design\n\n## Open Questions\n\n1. Should we add task expiration/TTL?\n2. Should we support delayed task execution (schedule for future)?\n3. What's the expected queue size? May need queue length limits.\n4. Should we add batch operations for bulk submission?\n5. Persistence strategy if the system restarts?\n\n## Convergence Status\n\n**ITERATING** - This is the initial design and needs review and refinement.",
        "prompt_for_other": "Please evaluate the thread-safety approach and the retry mechanism. Are there any race conditions I've missed? Is the automatic retry logic appropriately designed, or should retry decisions be left to the workers?",
        "convergence_signal": "ITERATING",
        "raw_response": "## Design\n\n# Priority Task Queue System\n\n## Architecture Overview\n\nA priority task queue system with in-memory storage, supporting task submission, priority-based retrieval, status tracking, and concurrent access.\n\n## Core Components\n\n### 1. Task Model\n```python\nfrom enum import Enum\nfrom dataclasses import dataclass\nfrom typing import Optional, Any\nfrom datetime import datetime\nimport uuid\n\nclass TaskStatus(Enum):\n    PENDING = \"pending\"\n    IN_PROGRESS = \"in_progress\"\n    COMPLETED = \"completed\"\n    FAILED = \"failed\"\n    CANCELLED = \"cancelled\"\n\nclass TaskPriority(Enum):\n    LOW = 1\n    MEDIUM = 2\n    HIGH = 3\n    CRITICAL = 4\n\n@dataclass\nclass Task:\n    id: str\n    payload: Any\n    priority: TaskPriority\n    status: TaskStatus\n    created_at: datetime\n    updated_at: datetime\n    started_at: Optional[datetime] = None\n    completed_at: Optional[datetime] = None\n    error_message: Optional[str] = None\n    retry_count: int = 0\n    max_retries: int = 3\n```\n\n### 2. Priority Queue Storage\n```python\nimport heapq\nimport threading\nfrom collections import defaultdict\n\nclass PriorityTaskQueue:\n    def __init__(self):\n        self._lock = threading.RLock()\n        # Min-heap: (-priority, timestamp, task_id) for FIFO within priority\n        self._heap = []\n        # Fast lookup by task ID\n        self._tasks: dict[str, Task] = {}\n        # Counter for insertion order (FIFO within priority)\n        self._counter = 0\n        \n    def enqueue(self, payload: Any, priority: TaskPriority = TaskPriority.MEDIUM) -> str:\n        \"\"\"Add task to queue, return task ID\"\"\"\n        with self._lock:\n            task = Task(\n                id=str(uuid.uuid4()),\n                payload=payload,\n                priority=priority,\n                status=TaskStatus.PENDING,\n                created_at=datetime.utcnow(),\n                updated_at=datetime.utcnow()\n            )\n            self._tasks[task.id] = task\n            # Negative priority for max-heap behavior, counter for FIFO\n            heapq.heappush(self._heap, (-priority.value, self._counter, task.id))\n            self._counter += 1\n            return task.id\n    \n    def dequeue(self) -> Optional[Task]:\n        \"\"\"Get highest priority pending task\"\"\"\n        with self._lock:\n            while self._heap:\n                _, _, task_id = heapq.heappop(self._heap)\n                task = self._tasks.get(task_id)\n                \n                if task and task.status == TaskStatus.PENDING:\n                    task.status = TaskStatus.IN_PROGRESS\n                    task.started_at = datetime.utcnow()\n                    task.updated_at = datetime.utcnow()\n                    return task\n            return None\n    \n    def get_task(self, task_id: str) -> Optional[Task]:\n        \"\"\"Retrieve task by ID\"\"\"\n        with self._lock:\n            return self._tasks.get(task_id)\n    \n    def update_status(self, task_id: str, status: TaskStatus, \n                     error_message: Optional[str] = None):\n        \"\"\"Update task status\"\"\"\n        with self._lock:\n            task = self._tasks.get(task_id)\n            if not task:\n                raise ValueError(f\"Task {task_id} not found\")\n            \n            task.status = status\n            task.updated_at = datetime.utcnow()\n            \n            if status == TaskStatus.COMPLETED:\n                task.completed_at = datetime.utcnow()\n            elif status == TaskStatus.FAILED:\n                task.error_message = error_message\n                task.retry_count += 1\n                \n                # Re-enqueue if retries available\n                if task.retry_count < task.max_retries:\n                    task.status = TaskStatus.PENDING\n                    heapq.heappush(self._heap, \n                                 (-task.priority.value, self._counter, task.id))\n                    self._counter += 1\n    \n    def cancel_task(self, task_id: str) -> bool:\n        \"\"\"Cancel a pending task\"\"\"\n        with self._lock:\n            task = self._tasks.get(task_id)\n            if not task:\n                return False\n            if task.status == TaskStatus.PENDING:\n                task.status = TaskStatus.CANCELLED\n                task.updated_at = datetime.utcnow()\n                return True\n            return False\n    \n    def get_queue_stats(self) -> dict:\n        \"\"\"Get queue statistics\"\"\"\n        with self._lock:\n            status_counts = defaultdict(int)\n            for task in self._tasks.values():\n                status_counts[task.status.value] += 1\n            \n            return {\n                \"total_tasks\": len(self._tasks),\n                \"pending\": status_counts[TaskStatus.PENDING.value],\n                \"in_progress\": status_counts[TaskStatus.IN_PROGRESS.value],\n                \"completed\": status_counts[TaskStatus.COMPLETED.value],\n                \"failed\": status_counts[TaskStatus.FAILED.value],\n                \"cancelled\": status_counts[TaskStatus.CANCELLED.value]\n            }\n```\n\n### 3. Queue Manager Interface\n```python\nclass TaskQueueManager:\n    def __init__(self):\n        self.queue = PriorityTaskQueue()\n    \n    def submit_task(self, payload: Any, priority: str = \"medium\") -> dict:\n        \"\"\"Submit a new task\"\"\"\n        try:\n            priority_enum = TaskPriority[priority.upper()]\n        except KeyError:\n            raise ValueError(f\"Invalid priority: {priority}\")\n        \n        task_id = self.queue.enqueue(payload, priority_enum)\n        return {\"task_id\": task_id, \"status\": \"pending\"}\n    \n    def get_next_task(self) -> Optional[dict]:\n        \"\"\"Worker polls for next task\"\"\"\n        task = self.queue.dequeue()\n        if task:\n            return {\n                \"task_id\": task.id,\n                \"payload\": task.payload,\n                \"priority\": task.priority.name,\n                \"retry_count\": task.retry_count\n            }\n        return None\n    \n    def complete_task(self, task_id: str, success: bool = True, \n                     error: Optional[str] = None):\n        \"\"\"Mark task as completed or failed\"\"\"\n        status = TaskStatus.COMPLETED if success else TaskStatus.FAILED\n        self.queue.update_status(task_id, status, error)\n    \n    def get_task_status(self, task_id: str) -> Optional[dict]:\n        \"\"\"Check task status\"\"\"\n        task = self.queue.get_task(task_id)\n        if not task:\n            return None\n        \n        return {\n            \"task_id\": task.id,\n            \"status\": task.status.value,\n            \"priority\": task.priority.name,\n            \"created_at\": task.created_at.isoformat(),\n            \"started_at\": task.started_at.isoformat() if task.started_at else None,\n            \"completed_at\": task.completed_at.isoformat() if task.completed_at else None,\n            \"error_message\": task.error_message,\n            \"retry_count\": task.retry_count\n        }\n    \n    def cancel_task(self, task_id: str) -> bool:\n        \"\"\"Cancel a pending task\"\"\"\n        return self.queue.cancel_task(task_id)\n    \n    def get_statistics(self) -> dict:\n        \"\"\"Get queue statistics\"\"\"\n        return self.queue.get_queue_stats()\n```\n\n## Error Handling\n\n### 1. Error Categories\n- **ValidationError**: Invalid priority, malformed payload\n- **NotFoundError**: Task ID doesn't exist\n- **StateError**: Invalid state transition (e.g., completing cancelled task)\n- **ConcurrencyError**: Race conditions (handled by locks)\n\n### 2. Retry Logic\n- Tasks automatically retry up to `max_retries` times on failure\n- Exponential backoff can be added by workers between retries\n- Failed tasks preserve error messages for debugging\n\n### 3. Edge Cases\n- Empty queue: `dequeue()` returns `None`\n- Duplicate operations: Idempotent status updates\n- Cancelled tasks: Skipped during dequeue\n- Thread safety: All operations protected by RLock\n\n## Usage Example\n\n```python\n# Initialize\nmanager = TaskQueueManager()\n\n# Submit tasks\ntask1 = manager.submit_task({\"action\": \"send_email\", \"to\": \"user@example.com\"}, \"high\")\ntask2 = manager.submit_task({\"action\": \"generate_report\"}, \"low\")\n\n# Worker loop\nwhile True:\n    task = manager.get_next_task()\n    if task:\n        try:\n            # Process task\n            process(task['payload'])\n            manager.complete_task(task['task_id'], success=True)\n        except Exception as e:\n            manager.complete_task(task['task_id'], success=False, error=str(e))\n    else:\n        time.sleep(1)\n\n# Check status\nstatus = manager.get_task_status(task1['task_id'])\nprint(status)\n```\n\n## Rationale\n\n**In-memory storage**: Chosen for simplicity and speed. For production, this would be replaced with Redis or a persistent database.\n\n**Heap-based priority queue**: Provides O(log n) enqueue and O(log n) dequeue with O(1) task lookup via dictionary. The heap stores tuples of (-priority, counter, task_id) to ensure FIFO ordering within the same priority level.\n\n**Thread-safe design**: RLock allows reentrant locking, preventing deadlocks in complex operations while ensuring atomicity.\n\n**Automatic retry logic**: Built into the queue to handle transient failures without worker complexity.\n\n**Status tracking**: Comprehensive lifecycle tracking enables monitoring, debugging, and audit trails.\n\n## What I Changed\n\nN/A - Initial design\n\n## What I Kept\n\nN/A - Initial design\n\n## Open Questions\n\n1. Should we add task expiration/TTL?\n2. Should we support delayed task execution (schedule for future)?\n3. What's the expected queue size? May need queue length limits.\n4. Should we add batch operations for bulk submission?\n5. Persistence strategy if the system restarts?\n\n## Convergence Status\n\n**ITERATING** - This is the initial design and needs review and refinement.\n\nPROMPT_FOR_CRITIC:\nPlease evaluate the thread-safety approach and the retry mechanism. Are there any race conditions I've missed? Is the automatic retry logic appropriately designed, or should retry decisions be left to the workers?"
      },
      "agent_b": {
        "content": "## Design\n\n# Priority Task Queue System\n\n## Architecture Overview\n\nA priority task queue system with in-memory storage, supporting task submission, priority-based retrieval, status tracking, and concurrent access with robust retry mechanisms and worker-controlled retry policies.\n\n## Core Components\n\n### 1. Task Model\n```python\nfrom enum import Enum\nfrom dataclasses import dataclass, field\nfrom typing import Optional, Any, Callable\nfrom datetime import datetime\nimport uuid\n\nclass TaskStatus(Enum):\n    PENDING = \"pending\"\n    IN_PROGRESS = \"in_progress\"\n    COMPLETED = \"completed\"\n    FAILED = \"failed\"\n    CANCELLED = \"cancelled\"\n\nclass TaskPriority(Enum):\n    LOW = 1\n    MEDIUM = 2\n    HIGH = 3\n    CRITICAL = 4\n\n@dataclass\nclass Task:\n    id: str\n    payload: Any\n    priority: TaskPriority\n    status: TaskStatus\n    created_at: datetime\n    updated_at: datetime\n    started_at: Optional[datetime] = None\n    completed_at: Optional[datetime] = None\n    error_message: Optional[str] = None\n    retry_count: int = 0\n    max_retries: int = 3\n    # Insertion order for stable FIFO within priority\n    sequence: int = 0\n    # Worker ID tracking for debugging\n    worker_id: Optional[str] = None\n    \n    def __post_init__(self):\n        # Ensure immutable task ID\n        object.__setattr__(self, 'id', self.id)\n```\n\n### 2. Priority Queue Storage\n```python\nimport heapq\nimport threading\nfrom collections import defaultdict\nfrom typing import Set\n\nclass PriorityTaskQueue:\n    def __init__(self, max_queue_size: Optional[int] = None):\n        self._lock = threading.RLock()\n        # Min-heap: (-priority, sequence, task_id) for FIFO within priority\n        self._heap = []\n        # Fast lookup by task ID\n        self._tasks: dict[str, Task] = {}\n        # Track which tasks are in the heap (for lazy deletion)\n        self._heap_task_ids: Set[str] = set()\n        # Counter for insertion order (FIFO within priority)\n        self._counter = 0\n        # Optional queue size limit\n        self._max_queue_size = max_queue_size\n        \n    def enqueue(self, payload: Any, priority: TaskPriority = TaskPriority.MEDIUM,\n                max_retries: int = 3) -> str:\n        \"\"\"Add task to queue, return task ID\"\"\"\n        with self._lock:\n            # Check queue size limit\n            pending_count = sum(1 for t in self._tasks.values() \n                              if t.status == TaskStatus.PENDING)\n            if self._max_queue_size and pending_count >= self._max_queue_size:\n                raise QueueFullError(f\"Queue is at capacity: {self._max_queue_size}\")\n            \n            task = Task(\n                id=str(uuid.uuid4()),\n                payload=payload,\n                priority=priority,\n                status=TaskStatus.PENDING,\n                created_at=datetime.utcnow(),\n                updated_at=datetime.utcnow(),\n                max_retries=max_retries,\n                sequence=self._counter\n            )\n            self._tasks[task.id] = task\n            # Negative priority for max-heap behavior, sequence for FIFO\n            heapq.heappush(self._heap, (-priority.value, self._counter, task.id))\n            self._heap_task_ids.add(task.id)\n            self._counter += 1\n            return task.id\n    \n    def dequeue(self, worker_id: Optional[str] = None) -> Optional[Task]:\n        \"\"\"Get highest priority pending task\"\"\"\n        with self._lock:\n            while self._heap:\n                _, _, task_id = heapq.heappop(self._heap)\n                self._heap_task_ids.discard(task_id)\n                \n                task = self._tasks.get(task_id)\n                \n                # Skip if task doesn't exist or isn't pending (lazy deletion)\n                if not task or task.status != TaskStatus.PENDING:\n                    continue\n                \n                # Transition to in-progress\n                task.status = TaskStatus.IN_PROGRESS\n                task.started_at = datetime.utcnow()\n                task.updated_at = datetime.utcnow()\n                task.worker_id = worker_id\n                return task\n            \n            return None\n    \n    def get_task(self, task_id: str) -> Optional[Task]:\n        \"\"\"Retrieve task by ID (returns a copy to prevent external mutation)\"\"\"\n        with self._lock:\n            task = self._tasks.get(task_id)\n            if task:\n                # Return a shallow copy to prevent external mutation of task fields\n                return dataclass_replace(task)\n            return None\n    \n    def update_status(self, task_id: str, status: TaskStatus, \n                     error_message: Optional[str] = None,\n                     allow_retry: bool = True) -> bool:\n        \"\"\"\n        Update task status with state validation.\n        Returns True if retry was scheduled, False otherwise.\n        \"\"\"\n        with self._lock:\n            task = self._tasks.get(task_id)\n            if not task:\n                raise TaskNotFoundError(f\"Task {task_id} not found\")\n            \n            # Validate state transition\n            if not self._is_valid_transition(task.status, status):\n                raise InvalidStateTransitionError(\n                    f\"Cannot transition from {task.status.value} to {status.value}\"\n                )\n            \n            old_status = task.status\n            task.status = status\n            task.updated_at = datetime.utcnow()\n            \n            if status == TaskStatus.COMPLETED:\n                task.completed_at = datetime.utcnow()\n                return False\n            \n            elif status == TaskStatus.FAILED:\n                task.error_message = error_message\n                task.retry_count += 1\n                \n                # Re-enqueue if retries available AND allowed by caller\n                if allow_retry and task.retry_count < task.max_retries:\n                    task.status = TaskStatus.PENDING\n                    task.started_at = None  # Reset for retry\n                    task.worker_id = None\n                    \n                    # Only add to heap if not already there\n                    if task_id not in self._heap_task_ids:\n                        heapq.heappush(self._heap, \n                                     (-task.priority.value, self._counter, task.id))\n                        self._heap_task_ids.add(task_id)\n                        self._counter += 1\n                    return True\n                return False\n            \n            elif status == TaskStatus.CANCELLED:\n                # Remove from heap if present (lazy deletion marker)\n                # Actual removal happens during dequeue\n                return False\n            \n            return False\n    \n    def _is_valid_transition(self, from_status: TaskStatus, \n                            to_status: TaskStatus) -> bool:\n        \"\"\"Validate state machine transitions\"\"\"\n        valid_transitions = {\n            TaskStatus.PENDING: {TaskStatus.IN_PROGRESS, TaskStatus.CANCELLED},\n            TaskStatus.IN_PROGRESS: {TaskStatus.COMPLETED, TaskStatus.FAILED, \n                                    TaskStatus.CANCELLED},\n            TaskStatus.FAILED: set(),  # Terminal state\n            TaskStatus.COMPLETED: set(),  # Terminal state\n            TaskStatus.CANCELLED: set(),  # Terminal state\n        }\n        return to_status in valid_transitions.get(from_status, set())\n    \n    def cancel_task(self, task_id: str) -> bool:\n        \"\"\"Cancel a pending task\"\"\"\n        with self._lock:\n            task = self._tasks.get(task_id)\n            if not task:\n                return False\n            if task.status == TaskStatus.PENDING:\n                task.status = TaskStatus.CANCELLED\n                task.updated_at = datetime.utcnow()\n                # Lazy deletion - will be skipped during dequeue\n                return True\n            return False\n    \n    def requeue_task(self, task_id: str) -> bool:\n        \"\"\"\n        Manually requeue an in-progress task (e.g., worker died).\n        Only works for IN_PROGRESS tasks.\n        \"\"\"\n        with self._lock:\n            task = self._tasks.get(task_id)\n            if not task or task.status != TaskStatus.IN_PROGRESS:\n                return False\n            \n            task.status = TaskStatus.PENDING\n            task.started_at = None\n            task.worker_id = None\n            task.updated_at = datetime.utcnow()\n            \n            if task_id not in self._heap_task_ids:\n                heapq.heappush(self._heap, \n                             (-task.priority.value, self._counter, task.id))\n                self._heap_task_ids.add(task_id)\n                self._counter += 1\n            return True\n    \n    def get_queue_stats(self) -> dict:\n        \"\"\"Get queue statistics\"\"\"\n        with self._lock:\n            status_counts = defaultdict(int)\n            priority_counts = defaultdict(int)\n            \n            for task in self._tasks.values():\n                status_counts[task.status.value] += 1\n                if task.status == TaskStatus.PENDING:\n                    priority_counts[task.priority.name] += 1\n            \n            return {\n                \"total_tasks\": len(self._tasks),\n                \"pending\": status_counts[TaskStatus.PENDING.value],\n                \"in_progress\": status_counts[TaskStatus.IN_PROGRESS.value],\n                \"completed\": status_counts[TaskStatus.COMPLETED.value],\n                \"failed\": status_counts[TaskStatus.FAILED.value],\n                \"cancelled\": status_counts[TaskStatus.CANCELLED.value],\n                \"pending_by_priority\": dict(priority_counts),\n                \"heap_size\": len(self._heap)\n            }\n\n# Custom exceptions\nclass QueueFullError(Exception):\n    pass\n\nclass TaskNotFoundError(Exception):\n    pass\n\nclass InvalidStateTransitionError(Exception):\n    pass\n\ndef dataclass_replace(task: Task) -> Task:\n    \"\"\"Create a copy of a task\"\"\"\n    return Task(\n        id=task.id,\n        payload=task.payload,\n        priority=task.priority,\n        status=task.status,\n        created_at=task.created_at,\n        updated_at=task.updated_at,\n        started_at=task.started_at,\n        completed_at=task.completed_at,\n        error_message=task.error_message,\n        retry_count=task.retry_count,\n        max_retries=task.max_retries,\n        sequence=task.sequence,\n        worker_id=task.worker_id\n    )\n```\n\n### 3. Queue Manager Interface\n```python\nclass TaskQueueManager:\n    def __init__(self, max_queue_size: Optional[int] = None):\n        self.queue = PriorityTaskQueue(max_queue_size=max_queue_size)\n    \n    def submit_task(self, payload: Any, priority: str = \"medium\",\n                   max_retries: int = 3) -> dict:\n        \"\"\"Submit a new task\"\"\"\n        try:\n            priority_enum = TaskPriority[priority.upper()]\n        except KeyError:\n            raise ValueError(f\"Invalid priority: {priority}. \"\n                           f\"Valid options: {[p.name.lower() for p in TaskPriority]}\")\n        \n        if max_retries < 0:\n            raise ValueError(\"max_retries must be non-negative\")\n        \n        try:\n            task_id = self.queue.enqueue(payload, priority_enum, max_retries)\n            return {\"task_id\": task_id, \"status\": \"pending\"}\n        except QueueFullError as e:\n            return {\"error\": str(e), \"status\": \"rejected\"}\n    \n    def get_next_task(self, worker_id: Optional[str] = None) -> Optional[dict]:\n        \"\"\"Worker polls for next task\"\"\"\n        task = self.queue.dequeue(worker_id=worker_id)\n        if task:\n            return {\n                \"task_id\": task.id,\n                \"payload\": task.payload,\n                \"priority\": task.priority.name,\n                \"retry_count\": task.retry_count,\n                \"max_retries\": task.max_retries\n            }\n        return None\n    \n    def complete_task(self, task_id: str, success: bool = True, \n                     error: Optional[str] = None,\n                     allow_retry: bool = True) -> dict:\n        \"\"\"\n        Mark task as completed or failed.\n        \n        Args:\n            task_id: The task identifier\n            success: Whether task completed successfully\n            error: Error message if failed\n            allow_retry: Whether to automatically retry on failure (worker can override)\n        \n        Returns:\n            dict with status and retry information\n        \"\"\"\n        try:\n            status = TaskStatus.COMPLETED if success else TaskStatus.FAILED\n            was_retried = self.queue.update_status(task_id, status, error, allow_retry)\n            \n            return {\n                \"task_id\": task_id,\n                \"status\": status.value,\n                \"retried\": was_retried\n            }\n        except (TaskNotFoundError, InvalidStateTransitionError) as e:\n            return {\"error\": str(e)}\n    \n    def get_task_status(self, task_id: str) -> Optional[dict]:\n        \"\"\"Check task status\"\"\"\n        task = self.queue.get_task(task_id)\n        if not task:\n            return None\n        \n        return {\n            \"task_id\": task.id,\n            \"status\": task.status.value,\n            \"priority\": task.priority.name,\n            \"created_at\": task.created_at.isoformat(),\n            \"started_at\": task.started_at.isoformat() if task.started_at else None,\n            \"completed_at\": task.completed_at.isoformat() if task.completed_at else None,\n            \"error_message\": task.error_message,\n            \"retry_count\": task.retry_count,\n            \"max_retries\": task.max_retries,\n            \"worker_id\": task.worker_id\n        }\n    \n    def cancel_task(self, task_id: str) -> dict:\n        \"\"\"Cancel a pending task\"\"\"\n        success = self.queue.cancel_task(task_id)\n        return {\n            \"task_id\": task_id,\n            \"cancelled\": success,\n            \"message\": \"Task cancelled\" if success else \"Task not pending or not found\"\n        }\n    \n    def requeue_task(self, task_id: str) -> dict:\n        \"\"\"Manually requeue an in-progress task (e.g., worker failure)\"\"\"\n        success = self.queue.requeue_task(task_id)\n        return {\n            \"task_id\": task_id,\n            \"requeued\": success,\n            \"message\": \"Task requeued\" if success else \"Task not in-progress or not found\"\n        }\n    \n    def get_statistics(self) -> dict:\n        \"\"\"Get queue statistics\"\"\"\n        return self.queue.get_queue_stats()\n```\n\n## Error Handling\n\n### 1. Error Categories\n- **QueueFullError**: Queue at capacity (configurable max size)\n- **TaskNotFoundError**: Task ID doesn't exist\n- **InvalidStateTransitionError**: Invalid state machine transition\n- **ValueError**: Invalid priority or negative max_retries\n\n### 2. Retry Strategy (Worker-Controlled)\nThe system supports **flexible retry policies**:\n\n1. **Automatic retry** (default): Tasks retry up to `max_retries` automatically\n2. **Worker-controlled retry**: Workers can pass `allow_retry=False` to prevent automatic retry and implement custom logic (exponential backoff, conditional retry, etc.)\n3. **Manual requeue**: Workers or supervisors can manually requeue stuck tasks\n\nThis hybrid approach provides:\n- Simplicity for standard cases (automatic retry)\n- Flexibility for complex scenarios (worker-controlled)\n- Recovery from worker failures (manual requeue)\n\n### 3. State Machine Validation\nValid transitions:\n- PENDING \u2192 IN_PROGRESS, CANCELLED\n- IN_PROGRESS \u2192 COMPLETED, FAILED, CANCELLED\n- COMPLETED, FAILED, CANCELLED \u2192 (terminal states)\n\nInvalid transitions raise `InvalidStateTransitionError`.\n\n### 4. Thread Safety Guarantees\n\n**Race condition mitigations:**\n\n1. **Atomic dequeue**: RLock ensures only one worker gets each task\n2. **Lazy deletion**: Cancelled tasks removed during dequeue, preventing heap corruption\n3. **Heap consistency**: Track heap membership with `_heap_task_ids` set to prevent duplicate insertions\n4. **Idempotent updates**: Status updates validate current state before transition\n5. **Worker tracking**: `worker_id` recorded for debugging concurrent access\n\n**Known safe patterns:**\n- Multiple workers calling `get_next_task()` concurrently\n- Status updates while other workers are dequeuing\n- Cancellation while task is in heap\n\n## Usage Examples\n\n### Basic Usage\n```python\n# Initialize with optional queue size limit\nmanager = TaskQueueManager(max_queue_size=10000)\n\n# Submit tasks\ntask1 = manager.submit_task(\n    {\"action\": \"send_email\", \"to\": \"user@example.com\"}, \n    priority=\"high\",\n    max_retries=5\n)\ntask2 = manager.submit_task({\"action\": \"generate_report\"}, priority=\"low\")\n\n# Worker loop with automatic retry\nworker_id = \"worker-1\"\nwhile True:\n    task = manager.get_next_task(worker_id=worker_id)\n    if task:\n        try:\n            result = process(task['payload'])\n            manager.complete_task(task['task_id'], success=True)\n        except Exception as e:\n            # Automatic retry enabled\n            manager.complete_task(task['task_id'], success=False, error=str(e))\n    else:\n        time.sleep(1)\n```\n\n### Advanced: Worker-Controlled Retry\n```python\n# Worker with custom retry logic\ndef smart_worker():\n    while True:\n        task = manager.get_next_task(worker_id=\"smart-worker\")\n        if task:\n            try:\n                result = process(task['payload'])\n                manager.complete_task(task['task_id'], success=True)\n            except TransientError as e:\n                # Allow automatic retry for transient errors\n                manager.complete_task(\n                    task['task_id'], \n                    success=False, \n                    error=str(e),\n                    allow_retry=True\n                )\n            except PermanentError as e:\n                # Skip retry for permanent errors\n                manager.complete_task(\n                    task['task_id'], \n                    success=False, \n                    error=str(e),\n                    allow_retry=False\n                )\n```\n\n### Supervisor Pattern (Worker Failure Recovery)\n```python\n# Monitor and requeue stuck tasks\ndef supervisor_loop():\n    while True:\n        stats = manager.get_statistics()\n        for task_id in get_in_progress_tasks():\n            task = manager.get_task_status(task_id)\n            \n            # Requeue if stuck for > 5 minutes\n            if task and (datetime.utcnow() - task['started_at']).seconds > 300:\n                manager.requeue_task(task_id)\n        \n        time.sleep(60)\n```\n\n## What I Improved\n\n### 1. **Thread Safety Enhancements**\n- **Lazy deletion**: Cancelled tasks are marked but removed during dequeue, preventing heap corruption from mid-operation removals\n- **Heap membership tracking**: `_heap_task_ids` set prevents duplicate insertions during retry\n- **State validation**: `_is_valid_transition()` prevents invalid state changes in concurrent scenarios\n- **Worker ID tracking**: Helps debug which worker has a task, critical for recovery\n\n### 2. **Flexible Retry Control**\n- **Worker-controlled retry**: Added `allow_retry` parameter so workers can decide retry policy per failure\n- **Per-task max_retries**: Configurable at submission time (not hardcoded)\n- **Manual requeue**: Added `requeue_task()` for supervisor-driven recovery\n- This addresses the original question: retry decisions can now be made by workers OR automatic\n\n### 3. **Robust Error Handling**\n- **Custom exceptions**: Specific exception types for different failure modes\n- **State machine validation**: Explicit transition rules prevent invalid states\n- **Queue capacity**: Optional `max_queue_size` prevents unbounded memory growth\n\n### 4. **Enhanced Observability**\n- **Worker tracking**: Know which worker is processing each task\n- **Sequence numbers**: Stable FIFO ordering within priority levels\n- **Extended stats**: Priority breakdown in statistics\n- **Immutable task copies**: `get_task()` returns copies to prevent external mutation\n\n### 5. **Production-Ready Details**\n- **Validation**: Input validation with helpful error messages\n- **Edge case handling**: Empty queue, duplicate operations, concurrent cancellation\n- **Supervisor pattern**: Example shows how to detect and recover from worker failures\n\n## What I Kept\n\n- **Core heap-based architecture**: Efficient O(log n) operations with O(1) lookup\n- **RLock for thread safety**: Solid foundation for concurrent access\n- **Comprehensive task model**: Good balance of fields for tracking lifecycle\n- **Clean API design**: Intuitive methods with clear responsibilities\n- **Automatic retry foundation**: Built-in retry logic with room for customization\n\n## Remaining Concerns\n\n### Addressed from Original\n\u2705 **Thread safety**: Lazy deletion and heap tracking prevent race conditions\n\u2705 **Retry control**: Hybrid approach gives workers control when needed\n\n### New Considerations\n1. **Memory growth**: Even with lazy deletion, cancelled tasks remain in `_tasks` dict forever. Should we add periodic cleanup or TTL?\n2. **Heap bloat**: Lazy deletion means heap can contain many stale entries. Consider periodic heap rebuild if this becomes an issue.\n3. **Worker failure detection**: The supervisor pattern is manual. Should we add automatic heartbeat/timeout detection?\n4. **Persistence**: Still fully in-memory. What's the migration path to Redis/DB?\n5. **Metrics/observability**: Should we add hooks for Prometheus/StatsD integration?\n\n## Convergence Status\n\n**ITERATING** - Design is significantly improved but needs architect feedback on:\n1. Trade-offs of lazy deletion vs. eager cleanup\n2. Whether worker-controlled retry adds useful flexibility or unnecessary complexity\n3. Production deployment concerns (persistence, monitoring)\n\n## Prompt for Collaborator",
        "prompt_for_other": "I've added worker-controlled retry and lazy deletion for thread safety. Key questions:\n\n1. **Lazy deletion trade-off**: Tasks stay in the heap until dequeued (marked as invalid). This prevents race conditions but can bloat the heap with cancelled tasks. Is this acceptable, or should we add periodic heap rebuilding?\n\n2. **Retry flexibility**: I added `allow_retry` parameter so workers can override automatic retry per failure. Does this add useful flexibility for your use case, or is pure automatic retry simpler and sufficient?\n\n3. **Memory management**: Should we add automatic cleanup of old completed/failed tasks, or is manual cleanup via a background job acceptable?",
        "convergence_signal": "ITERATING",
        "raw_response": "## Design\n\n# Priority Task Queue System\n\n## Architecture Overview\n\nA priority task queue system with in-memory storage, supporting task submission, priority-based retrieval, status tracking, and concurrent access with robust retry mechanisms and worker-controlled retry policies.\n\n## Core Components\n\n### 1. Task Model\n```python\nfrom enum import Enum\nfrom dataclasses import dataclass, field\nfrom typing import Optional, Any, Callable\nfrom datetime import datetime\nimport uuid\n\nclass TaskStatus(Enum):\n    PENDING = \"pending\"\n    IN_PROGRESS = \"in_progress\"\n    COMPLETED = \"completed\"\n    FAILED = \"failed\"\n    CANCELLED = \"cancelled\"\n\nclass TaskPriority(Enum):\n    LOW = 1\n    MEDIUM = 2\n    HIGH = 3\n    CRITICAL = 4\n\n@dataclass\nclass Task:\n    id: str\n    payload: Any\n    priority: TaskPriority\n    status: TaskStatus\n    created_at: datetime\n    updated_at: datetime\n    started_at: Optional[datetime] = None\n    completed_at: Optional[datetime] = None\n    error_message: Optional[str] = None\n    retry_count: int = 0\n    max_retries: int = 3\n    # Insertion order for stable FIFO within priority\n    sequence: int = 0\n    # Worker ID tracking for debugging\n    worker_id: Optional[str] = None\n    \n    def __post_init__(self):\n        # Ensure immutable task ID\n        object.__setattr__(self, 'id', self.id)\n```\n\n### 2. Priority Queue Storage\n```python\nimport heapq\nimport threading\nfrom collections import defaultdict\nfrom typing import Set\n\nclass PriorityTaskQueue:\n    def __init__(self, max_queue_size: Optional[int] = None):\n        self._lock = threading.RLock()\n        # Min-heap: (-priority, sequence, task_id) for FIFO within priority\n        self._heap = []\n        # Fast lookup by task ID\n        self._tasks: dict[str, Task] = {}\n        # Track which tasks are in the heap (for lazy deletion)\n        self._heap_task_ids: Set[str] = set()\n        # Counter for insertion order (FIFO within priority)\n        self._counter = 0\n        # Optional queue size limit\n        self._max_queue_size = max_queue_size\n        \n    def enqueue(self, payload: Any, priority: TaskPriority = TaskPriority.MEDIUM,\n                max_retries: int = 3) -> str:\n        \"\"\"Add task to queue, return task ID\"\"\"\n        with self._lock:\n            # Check queue size limit\n            pending_count = sum(1 for t in self._tasks.values() \n                              if t.status == TaskStatus.PENDING)\n            if self._max_queue_size and pending_count >= self._max_queue_size:\n                raise QueueFullError(f\"Queue is at capacity: {self._max_queue_size}\")\n            \n            task = Task(\n                id=str(uuid.uuid4()),\n                payload=payload,\n                priority=priority,\n                status=TaskStatus.PENDING,\n                created_at=datetime.utcnow(),\n                updated_at=datetime.utcnow(),\n                max_retries=max_retries,\n                sequence=self._counter\n            )\n            self._tasks[task.id] = task\n            # Negative priority for max-heap behavior, sequence for FIFO\n            heapq.heappush(self._heap, (-priority.value, self._counter, task.id))\n            self._heap_task_ids.add(task.id)\n            self._counter += 1\n            return task.id\n    \n    def dequeue(self, worker_id: Optional[str] = None) -> Optional[Task]:\n        \"\"\"Get highest priority pending task\"\"\"\n        with self._lock:\n            while self._heap:\n                _, _, task_id = heapq.heappop(self._heap)\n                self._heap_task_ids.discard(task_id)\n                \n                task = self._tasks.get(task_id)\n                \n                # Skip if task doesn't exist or isn't pending (lazy deletion)\n                if not task or task.status != TaskStatus.PENDING:\n                    continue\n                \n                # Transition to in-progress\n                task.status = TaskStatus.IN_PROGRESS\n                task.started_at = datetime.utcnow()\n                task.updated_at = datetime.utcnow()\n                task.worker_id = worker_id\n                return task\n            \n            return None\n    \n    def get_task(self, task_id: str) -> Optional[Task]:\n        \"\"\"Retrieve task by ID (returns a copy to prevent external mutation)\"\"\"\n        with self._lock:\n            task = self._tasks.get(task_id)\n            if task:\n                # Return a shallow copy to prevent external mutation of task fields\n                return dataclass_replace(task)\n            return None\n    \n    def update_status(self, task_id: str, status: TaskStatus, \n                     error_message: Optional[str] = None,\n                     allow_retry: bool = True) -> bool:\n        \"\"\"\n        Update task status with state validation.\n        Returns True if retry was scheduled, False otherwise.\n        \"\"\"\n        with self._lock:\n            task = self._tasks.get(task_id)\n            if not task:\n                raise TaskNotFoundError(f\"Task {task_id} not found\")\n            \n            # Validate state transition\n            if not self._is_valid_transition(task.status, status):\n                raise InvalidStateTransitionError(\n                    f\"Cannot transition from {task.status.value} to {status.value}\"\n                )\n            \n            old_status = task.status\n            task.status = status\n            task.updated_at = datetime.utcnow()\n            \n            if status == TaskStatus.COMPLETED:\n                task.completed_at = datetime.utcnow()\n                return False\n            \n            elif status == TaskStatus.FAILED:\n                task.error_message = error_message\n                task.retry_count += 1\n                \n                # Re-enqueue if retries available AND allowed by caller\n                if allow_retry and task.retry_count < task.max_retries:\n                    task.status = TaskStatus.PENDING\n                    task.started_at = None  # Reset for retry\n                    task.worker_id = None\n                    \n                    # Only add to heap if not already there\n                    if task_id not in self._heap_task_ids:\n                        heapq.heappush(self._heap, \n                                     (-task.priority.value, self._counter, task.id))\n                        self._heap_task_ids.add(task_id)\n                        self._counter += 1\n                    return True\n                return False\n            \n            elif status == TaskStatus.CANCELLED:\n                # Remove from heap if present (lazy deletion marker)\n                # Actual removal happens during dequeue\n                return False\n            \n            return False\n    \n    def _is_valid_transition(self, from_status: TaskStatus, \n                            to_status: TaskStatus) -> bool:\n        \"\"\"Validate state machine transitions\"\"\"\n        valid_transitions = {\n            TaskStatus.PENDING: {TaskStatus.IN_PROGRESS, TaskStatus.CANCELLED},\n            TaskStatus.IN_PROGRESS: {TaskStatus.COMPLETED, TaskStatus.FAILED, \n                                    TaskStatus.CANCELLED},\n            TaskStatus.FAILED: set(),  # Terminal state\n            TaskStatus.COMPLETED: set(),  # Terminal state\n            TaskStatus.CANCELLED: set(),  # Terminal state\n        }\n        return to_status in valid_transitions.get(from_status, set())\n    \n    def cancel_task(self, task_id: str) -> bool:\n        \"\"\"Cancel a pending task\"\"\"\n        with self._lock:\n            task = self._tasks.get(task_id)\n            if not task:\n                return False\n            if task.status == TaskStatus.PENDING:\n                task.status = TaskStatus.CANCELLED\n                task.updated_at = datetime.utcnow()\n                # Lazy deletion - will be skipped during dequeue\n                return True\n            return False\n    \n    def requeue_task(self, task_id: str) -> bool:\n        \"\"\"\n        Manually requeue an in-progress task (e.g., worker died).\n        Only works for IN_PROGRESS tasks.\n        \"\"\"\n        with self._lock:\n            task = self._tasks.get(task_id)\n            if not task or task.status != TaskStatus.IN_PROGRESS:\n                return False\n            \n            task.status = TaskStatus.PENDING\n            task.started_at = None\n            task.worker_id = None\n            task.updated_at = datetime.utcnow()\n            \n            if task_id not in self._heap_task_ids:\n                heapq.heappush(self._heap, \n                             (-task.priority.value, self._counter, task.id))\n                self._heap_task_ids.add(task_id)\n                self._counter += 1\n            return True\n    \n    def get_queue_stats(self) -> dict:\n        \"\"\"Get queue statistics\"\"\"\n        with self._lock:\n            status_counts = defaultdict(int)\n            priority_counts = defaultdict(int)\n            \n            for task in self._tasks.values():\n                status_counts[task.status.value] += 1\n                if task.status == TaskStatus.PENDING:\n                    priority_counts[task.priority.name] += 1\n            \n            return {\n                \"total_tasks\": len(self._tasks),\n                \"pending\": status_counts[TaskStatus.PENDING.value],\n                \"in_progress\": status_counts[TaskStatus.IN_PROGRESS.value],\n                \"completed\": status_counts[TaskStatus.COMPLETED.value],\n                \"failed\": status_counts[TaskStatus.FAILED.value],\n                \"cancelled\": status_counts[TaskStatus.CANCELLED.value],\n                \"pending_by_priority\": dict(priority_counts),\n                \"heap_size\": len(self._heap)\n            }\n\n# Custom exceptions\nclass QueueFullError(Exception):\n    pass\n\nclass TaskNotFoundError(Exception):\n    pass\n\nclass InvalidStateTransitionError(Exception):\n    pass\n\ndef dataclass_replace(task: Task) -> Task:\n    \"\"\"Create a copy of a task\"\"\"\n    return Task(\n        id=task.id,\n        payload=task.payload,\n        priority=task.priority,\n        status=task.status,\n        created_at=task.created_at,\n        updated_at=task.updated_at,\n        started_at=task.started_at,\n        completed_at=task.completed_at,\n        error_message=task.error_message,\n        retry_count=task.retry_count,\n        max_retries=task.max_retries,\n        sequence=task.sequence,\n        worker_id=task.worker_id\n    )\n```\n\n### 3. Queue Manager Interface\n```python\nclass TaskQueueManager:\n    def __init__(self, max_queue_size: Optional[int] = None):\n        self.queue = PriorityTaskQueue(max_queue_size=max_queue_size)\n    \n    def submit_task(self, payload: Any, priority: str = \"medium\",\n                   max_retries: int = 3) -> dict:\n        \"\"\"Submit a new task\"\"\"\n        try:\n            priority_enum = TaskPriority[priority.upper()]\n        except KeyError:\n            raise ValueError(f\"Invalid priority: {priority}. \"\n                           f\"Valid options: {[p.name.lower() for p in TaskPriority]}\")\n        \n        if max_retries < 0:\n            raise ValueError(\"max_retries must be non-negative\")\n        \n        try:\n            task_id = self.queue.enqueue(payload, priority_enum, max_retries)\n            return {\"task_id\": task_id, \"status\": \"pending\"}\n        except QueueFullError as e:\n            return {\"error\": str(e), \"status\": \"rejected\"}\n    \n    def get_next_task(self, worker_id: Optional[str] = None) -> Optional[dict]:\n        \"\"\"Worker polls for next task\"\"\"\n        task = self.queue.dequeue(worker_id=worker_id)\n        if task:\n            return {\n                \"task_id\": task.id,\n                \"payload\": task.payload,\n                \"priority\": task.priority.name,\n                \"retry_count\": task.retry_count,\n                \"max_retries\": task.max_retries\n            }\n        return None\n    \n    def complete_task(self, task_id: str, success: bool = True, \n                     error: Optional[str] = None,\n                     allow_retry: bool = True) -> dict:\n        \"\"\"\n        Mark task as completed or failed.\n        \n        Args:\n            task_id: The task identifier\n            success: Whether task completed successfully\n            error: Error message if failed\n            allow_retry: Whether to automatically retry on failure (worker can override)\n        \n        Returns:\n            dict with status and retry information\n        \"\"\"\n        try:\n            status = TaskStatus.COMPLETED if success else TaskStatus.FAILED\n            was_retried = self.queue.update_status(task_id, status, error, allow_retry)\n            \n            return {\n                \"task_id\": task_id,\n                \"status\": status.value,\n                \"retried\": was_retried\n            }\n        except (TaskNotFoundError, InvalidStateTransitionError) as e:\n            return {\"error\": str(e)}\n    \n    def get_task_status(self, task_id: str) -> Optional[dict]:\n        \"\"\"Check task status\"\"\"\n        task = self.queue.get_task(task_id)\n        if not task:\n            return None\n        \n        return {\n            \"task_id\": task.id,\n            \"status\": task.status.value,\n            \"priority\": task.priority.name,\n            \"created_at\": task.created_at.isoformat(),\n            \"started_at\": task.started_at.isoformat() if task.started_at else None,\n            \"completed_at\": task.completed_at.isoformat() if task.completed_at else None,\n            \"error_message\": task.error_message,\n            \"retry_count\": task.retry_count,\n            \"max_retries\": task.max_retries,\n            \"worker_id\": task.worker_id\n        }\n    \n    def cancel_task(self, task_id: str) -> dict:\n        \"\"\"Cancel a pending task\"\"\"\n        success = self.queue.cancel_task(task_id)\n        return {\n            \"task_id\": task_id,\n            \"cancelled\": success,\n            \"message\": \"Task cancelled\" if success else \"Task not pending or not found\"\n        }\n    \n    def requeue_task(self, task_id: str) -> dict:\n        \"\"\"Manually requeue an in-progress task (e.g., worker failure)\"\"\"\n        success = self.queue.requeue_task(task_id)\n        return {\n            \"task_id\": task_id,\n            \"requeued\": success,\n            \"message\": \"Task requeued\" if success else \"Task not in-progress or not found\"\n        }\n    \n    def get_statistics(self) -> dict:\n        \"\"\"Get queue statistics\"\"\"\n        return self.queue.get_queue_stats()\n```\n\n## Error Handling\n\n### 1. Error Categories\n- **QueueFullError**: Queue at capacity (configurable max size)\n- **TaskNotFoundError**: Task ID doesn't exist\n- **InvalidStateTransitionError**: Invalid state machine transition\n- **ValueError**: Invalid priority or negative max_retries\n\n### 2. Retry Strategy (Worker-Controlled)\nThe system supports **flexible retry policies**:\n\n1. **Automatic retry** (default): Tasks retry up to `max_retries` automatically\n2. **Worker-controlled retry**: Workers can pass `allow_retry=False` to prevent automatic retry and implement custom logic (exponential backoff, conditional retry, etc.)\n3. **Manual requeue**: Workers or supervisors can manually requeue stuck tasks\n\nThis hybrid approach provides:\n- Simplicity for standard cases (automatic retry)\n- Flexibility for complex scenarios (worker-controlled)\n- Recovery from worker failures (manual requeue)\n\n### 3. State Machine Validation\nValid transitions:\n- PENDING \u2192 IN_PROGRESS, CANCELLED\n- IN_PROGRESS \u2192 COMPLETED, FAILED, CANCELLED\n- COMPLETED, FAILED, CANCELLED \u2192 (terminal states)\n\nInvalid transitions raise `InvalidStateTransitionError`.\n\n### 4. Thread Safety Guarantees\n\n**Race condition mitigations:**\n\n1. **Atomic dequeue**: RLock ensures only one worker gets each task\n2. **Lazy deletion**: Cancelled tasks removed during dequeue, preventing heap corruption\n3. **Heap consistency**: Track heap membership with `_heap_task_ids` set to prevent duplicate insertions\n4. **Idempotent updates**: Status updates validate current state before transition\n5. **Worker tracking**: `worker_id` recorded for debugging concurrent access\n\n**Known safe patterns:**\n- Multiple workers calling `get_next_task()` concurrently\n- Status updates while other workers are dequeuing\n- Cancellation while task is in heap\n\n## Usage Examples\n\n### Basic Usage\n```python\n# Initialize with optional queue size limit\nmanager = TaskQueueManager(max_queue_size=10000)\n\n# Submit tasks\ntask1 = manager.submit_task(\n    {\"action\": \"send_email\", \"to\": \"user@example.com\"}, \n    priority=\"high\",\n    max_retries=5\n)\ntask2 = manager.submit_task({\"action\": \"generate_report\"}, priority=\"low\")\n\n# Worker loop with automatic retry\nworker_id = \"worker-1\"\nwhile True:\n    task = manager.get_next_task(worker_id=worker_id)\n    if task:\n        try:\n            result = process(task['payload'])\n            manager.complete_task(task['task_id'], success=True)\n        except Exception as e:\n            # Automatic retry enabled\n            manager.complete_task(task['task_id'], success=False, error=str(e))\n    else:\n        time.sleep(1)\n```\n\n### Advanced: Worker-Controlled Retry\n```python\n# Worker with custom retry logic\ndef smart_worker():\n    while True:\n        task = manager.get_next_task(worker_id=\"smart-worker\")\n        if task:\n            try:\n                result = process(task['payload'])\n                manager.complete_task(task['task_id'], success=True)\n            except TransientError as e:\n                # Allow automatic retry for transient errors\n                manager.complete_task(\n                    task['task_id'], \n                    success=False, \n                    error=str(e),\n                    allow_retry=True\n                )\n            except PermanentError as e:\n                # Skip retry for permanent errors\n                manager.complete_task(\n                    task['task_id'], \n                    success=False, \n                    error=str(e),\n                    allow_retry=False\n                )\n```\n\n### Supervisor Pattern (Worker Failure Recovery)\n```python\n# Monitor and requeue stuck tasks\ndef supervisor_loop():\n    while True:\n        stats = manager.get_statistics()\n        for task_id in get_in_progress_tasks():\n            task = manager.get_task_status(task_id)\n            \n            # Requeue if stuck for > 5 minutes\n            if task and (datetime.utcnow() - task['started_at']).seconds > 300:\n                manager.requeue_task(task_id)\n        \n        time.sleep(60)\n```\n\n## What I Improved\n\n### 1. **Thread Safety Enhancements**\n- **Lazy deletion**: Cancelled tasks are marked but removed during dequeue, preventing heap corruption from mid-operation removals\n- **Heap membership tracking**: `_heap_task_ids` set prevents duplicate insertions during retry\n- **State validation**: `_is_valid_transition()` prevents invalid state changes in concurrent scenarios\n- **Worker ID tracking**: Helps debug which worker has a task, critical for recovery\n\n### 2. **Flexible Retry Control**\n- **Worker-controlled retry**: Added `allow_retry` parameter so workers can decide retry policy per failure\n- **Per-task max_retries**: Configurable at submission time (not hardcoded)\n- **Manual requeue**: Added `requeue_task()` for supervisor-driven recovery\n- This addresses the original question: retry decisions can now be made by workers OR automatic\n\n### 3. **Robust Error Handling**\n- **Custom exceptions**: Specific exception types for different failure modes\n- **State machine validation**: Explicit transition rules prevent invalid states\n- **Queue capacity**: Optional `max_queue_size` prevents unbounded memory growth\n\n### 4. **Enhanced Observability**\n- **Worker tracking**: Know which worker is processing each task\n- **Sequence numbers**: Stable FIFO ordering within priority levels\n- **Extended stats**: Priority breakdown in statistics\n- **Immutable task copies**: `get_task()` returns copies to prevent external mutation\n\n### 5. **Production-Ready Details**\n- **Validation**: Input validation with helpful error messages\n- **Edge case handling**: Empty queue, duplicate operations, concurrent cancellation\n- **Supervisor pattern**: Example shows how to detect and recover from worker failures\n\n## What I Kept\n\n- **Core heap-based architecture**: Efficient O(log n) operations with O(1) lookup\n- **RLock for thread safety**: Solid foundation for concurrent access\n- **Comprehensive task model**: Good balance of fields for tracking lifecycle\n- **Clean API design**: Intuitive methods with clear responsibilities\n- **Automatic retry foundation**: Built-in retry logic with room for customization\n\n## Remaining Concerns\n\n### Addressed from Original\n\u2705 **Thread safety**: Lazy deletion and heap tracking prevent race conditions\n\u2705 **Retry control**: Hybrid approach gives workers control when needed\n\n### New Considerations\n1. **Memory growth**: Even with lazy deletion, cancelled tasks remain in `_tasks` dict forever. Should we add periodic cleanup or TTL?\n2. **Heap bloat**: Lazy deletion means heap can contain many stale entries. Consider periodic heap rebuild if this becomes an issue.\n3. **Worker failure detection**: The supervisor pattern is manual. Should we add automatic heartbeat/timeout detection?\n4. **Persistence**: Still fully in-memory. What's the migration path to Redis/DB?\n5. **Metrics/observability**: Should we add hooks for Prometheus/StatsD integration?\n\n## Convergence Status\n\n**ITERATING** - Design is significantly improved but needs architect feedback on:\n1. Trade-offs of lazy deletion vs. eager cleanup\n2. Whether worker-controlled retry adds useful flexibility or unnecessary complexity\n3. Production deployment concerns (persistence, monitoring)\n\n## Prompt for Collaborator\n\nPROMPT_FOR_ARCHITECT:\nI've added worker-controlled retry and lazy deletion for thread safety. Key questions:\n\n1. **Lazy deletion trade-off**: Tasks stay in the heap until dequeued (marked as invalid). This prevents race conditions but can bloat the heap with cancelled tasks. Is this acceptable, or should we add periodic heap rebuilding?\n\n2. **Retry flexibility**: I added `allow_retry` parameter so workers can override automatic retry per failure. Does this add useful flexibility for your use case, or is pure automatic retry simpler and sufficient?\n\n3. **Memory management**: Should we add automatic cleanup of old completed/failed tasks, or is manual cleanup via a background job acceptable?"
      }
    },
    {
      "round_number": 2,
      "agent_a": {
        "content": "## Design\n\n# Priority Task Queue System with Bounded Memory & Smart Cleanup\n\n## Architecture Overview\n\nA production-ready priority task queue system with in-memory storage, automatic memory management, and flexible retry policies. Key improvements: bounded memory through automatic cleanup, heap health monitoring, and simplified worker API.\n\n## Core Components\n\n### 1. Task Model\n```python\nfrom enum import Enum\nfrom dataclasses import dataclass, field\nfrom typing import Optional, Any, Dict\nfrom datetime import datetime, timedelta\nimport uuid\n\nclass TaskStatus(Enum):\n    PENDING = \"pending\"\n    IN_PROGRESS = \"in_progress\"\n    COMPLETED = \"completed\"\n    FAILED = \"failed\"\n    CANCELLED = \"cancelled\"\n\nclass TaskPriority(Enum):\n    LOW = 1\n    MEDIUM = 2\n    HIGH = 3\n    CRITICAL = 4\n\n@dataclass\nclass Task:\n    id: str\n    payload: Any\n    priority: TaskPriority\n    status: TaskStatus\n    created_at: datetime\n    updated_at: datetime\n    started_at: Optional[datetime] = None\n    completed_at: Optional[datetime] = None\n    error_message: Optional[str] = None\n    retry_count: int = 0\n    max_retries: int = 3\n    sequence: int = 0\n    worker_id: Optional[str] = None\n    # Retry policy metadata\n    retry_policy: Optional[Dict[str, Any]] = None\n    \n    def is_terminal(self) -> bool:\n        \"\"\"Check if task is in a terminal state\"\"\"\n        return self.status in {TaskStatus.COMPLETED, TaskStatus.FAILED, \n                               TaskStatus.CANCELLED}\n    \n    def age_seconds(self) -> float:\n        \"\"\"Get task age in seconds\"\"\"\n        return (datetime.utcnow() - self.created_at).total_seconds()\n    \n    def time_in_progress_seconds(self) -> Optional[float]:\n        \"\"\"Get time spent in progress (None if not started)\"\"\"\n        if not self.started_at:\n            return None\n        end_time = self.completed_at or datetime.utcnow()\n        return (end_time - self.started_at).total_seconds()\n```\n\n### 2. Heap Health Monitor\n```python\n@dataclass\nclass HeapHealth:\n    \"\"\"Track heap efficiency for automatic maintenance\"\"\"\n    total_entries: int = 0\n    valid_entries: int = 0\n    invalid_entries: int = 0\n    last_rebuild: datetime = field(default_factory=datetime.utcnow)\n    \n    @property\n    def efficiency(self) -> float:\n        \"\"\"Percentage of valid entries in heap\"\"\"\n        if self.total_entries == 0:\n            return 1.0\n        return self.valid_entries / self.total_entries\n    \n    @property\n    def should_rebuild(self) -> bool:\n        \"\"\"Rebuild if efficiency drops below 50% and heap has 100+ entries\"\"\"\n        return (self.efficiency < 0.5 and self.total_entries >= 100)\n```\n\n### 3. Priority Queue Storage with Auto-Cleanup\n```python\nimport heapq\nimport threading\nfrom collections import defaultdict\nfrom typing import Set, Optional, Tuple\n\nclass PriorityTaskQueue:\n    def __init__(self, \n                 max_queue_size: Optional[int] = None,\n                 task_retention_seconds: int = 3600,\n                 cleanup_interval_seconds: int = 300):\n        \"\"\"\n        Args:\n            max_queue_size: Max pending tasks (None = unlimited)\n            task_retention_seconds: How long to keep completed/failed tasks (default 1hr)\n            cleanup_interval_seconds: How often to run cleanup (default 5min)\n        \"\"\"\n        self._lock = threading.RLock()\n        self._heap = []\n        self._tasks: Dict[str, Task] = {}\n        self._heap_task_ids: Set[str] = set()\n        self._counter = 0\n        self._max_queue_size = max_queue_size\n        self._task_retention = timedelta(seconds=task_retention_seconds)\n        self._cleanup_interval = timedelta(seconds=cleanup_interval_seconds)\n        self._last_cleanup = datetime.utcnow()\n        self._heap_health = HeapHealth()\n        \n    def enqueue(self, payload: Any, priority: TaskPriority = TaskPriority.MEDIUM,\n                max_retries: int = 3, retry_policy: Optional[Dict] = None) -> str:\n        \"\"\"Add task to queue, return task ID\"\"\"\n        with self._lock:\n            # Run cleanup opportunistically\n            self._maybe_cleanup()\n            \n            # Check queue size limit (only count PENDING)\n            pending_count = sum(1 for t in self._tasks.values() \n                              if t.status == TaskStatus.PENDING)\n            if self._max_queue_size and pending_count >= self._max_queue_size:\n                raise QueueFullError(f\"Queue at capacity: {self._max_queue_size}\")\n            \n            task = Task(\n                id=str(uuid.uuid4()),\n                payload=payload,\n                priority=priority,\n                status=TaskStatus.PENDING,\n                created_at=datetime.utcnow(),\n                updated_at=datetime.utcnow(),\n                max_retries=max_retries,\n                sequence=self._counter,\n                retry_policy=retry_policy\n            )\n            self._tasks[task.id] = task\n            self._add_to_heap(task)\n            return task.id\n    \n    def _add_to_heap(self, task: Task):\n        \"\"\"Add task to heap with health tracking\"\"\"\n        heapq.heappush(self._heap, (-task.priority.value, task.sequence, task.id))\n        self._heap_task_ids.add(task.id)\n        self._counter += 1\n        self._heap_health.total_entries += 1\n        self._heap_health.valid_entries += 1\n    \n    def dequeue(self, worker_id: Optional[str] = None) -> Optional[Task]:\n        \"\"\"Get highest priority pending task\"\"\"\n        with self._lock:\n            self._maybe_cleanup()\n            \n            found_valid = False\n            while self._heap:\n                _, _, task_id = heapq.heappop(self._heap)\n                self._heap_task_ids.discard(task_id)\n                self._heap_health.total_entries -= 1\n                \n                task = self._tasks.get(task_id)\n                \n                if not task or task.status != TaskStatus.PENDING:\n                    # Invalid entry, continue searching\n                    continue\n                \n                # Found valid task\n                found_valid = True\n                self._heap_health.valid_entries -= 1\n                task.status = TaskStatus.IN_PROGRESS\n                task.started_at = datetime.utcnow()\n                task.updated_at = datetime.utcnow()\n                task.worker_id = worker_id\n                \n                # Check if heap needs rebuilding\n                if self._heap_health.should_rebuild:\n                    self._rebuild_heap()\n                \n                return task\n            \n            # Heap exhausted\n            if not found_valid and self._heap_health.total_entries > 0:\n                # All remaining entries are invalid, rebuild\n                self._rebuild_heap()\n            \n            return None\n    \n    def _rebuild_heap(self):\n        \"\"\"Rebuild heap with only valid pending tasks\"\"\"\n        with self._lock:\n            valid_tasks = [t for t in self._tasks.values() \n                          if t.status == TaskStatus.PENDING]\n            \n            self._heap.clear()\n            self._heap_task_ids.clear()\n            \n            for task in valid_tasks:\n                heapq.heappush(self._heap, \n                             (-task.priority.value, task.sequence, task.id))\n                self._heap_task_ids.add(task.id)\n            \n            self._heap_health = HeapHealth(\n                total_entries=len(self._heap),\n                valid_entries=len(self._heap),\n                invalid_entries=0,\n                last_rebuild=datetime.utcnow()\n            )\n    \n    def _maybe_cleanup(self):\n        \"\"\"Run cleanup if enough time has passed\"\"\"\n        now = datetime.utcnow()\n        if now - self._last_cleanup > self._cleanup_interval:\n            self._cleanup_old_tasks()\n            self._last_cleanup = now\n    \n    def _cleanup_old_tasks(self):\n        \"\"\"Remove old terminal tasks to prevent unbounded memory growth\"\"\"\n        with self._lock:\n            now = datetime.utcnow()\n            cutoff = now - self._task_retention\n            \n            to_delete = []\n            for task_id, task in self._tasks.items():\n                if task.is_terminal() and task.updated_at < cutoff:\n                    to_delete.append(task_id)\n            \n            for task_id in to_delete:\n                del self._tasks[task_id]\n                # Note: task might still be in heap, but will be skipped during dequeue\n    \n    def get_task(self, task_id: str) -> Optional[Task]:\n        \"\"\"Retrieve task by ID (returns reference for internal use)\"\"\"\n        with self._lock:\n            return self._tasks.get(task_id)\n    \n    def update_status(self, task_id: str, status: TaskStatus, \n                     error_message: Optional[str] = None) -> Tuple[bool, bool]:\n        \"\"\"\n        Update task status with state validation.\n        Returns: (success, was_retried)\n        \"\"\"\n        with self._lock:\n            task = self._tasks.get(task_id)\n            if not task:\n                raise TaskNotFoundError(f\"Task {task_id} not found\")\n            \n            if not self._is_valid_transition(task.status, status):\n                raise InvalidStateTransitionError(\n                    f\"Cannot transition from {task.status.value} to {status.value}\"\n                )\n            \n            task.status = status\n            task.updated_at = datetime.utcnow()\n            \n            if status == TaskStatus.COMPLETED:\n                task.completed_at = datetime.utcnow()\n                return (True, False)\n            \n            elif status == TaskStatus.FAILED:\n                task.error_message = error_message\n                task.completed_at = datetime.utcnow()\n                task.retry_count += 1\n                \n                # Check if should retry (automatic based on max_retries)\n                if task.retry_count < task.max_retries:\n                    # Reset for retry\n                    task.status = TaskStatus.PENDING\n                    task.started_at = None\n                    task.completed_at = None\n                    task.worker_id = None\n                    \n                    # Add back to heap if not already present\n                    if task_id not in self._heap_task_ids:\n                        self._add_to_heap(task)\n                    \n                    return (True, True)\n                return (True, False)\n            \n            elif status == TaskStatus.CANCELLED:\n                task.completed_at = datetime.utcnow()\n                return (True, False)\n            \n            return (True, False)\n    \n    def _is_valid_transition(self, from_status: TaskStatus, \n                            to_status: TaskStatus) -> bool:\n        \"\"\"Validate state machine transitions\"\"\"\n        valid_transitions = {\n            TaskStatus.PENDING: {TaskStatus.IN_PROGRESS, TaskStatus.CANCELLED},\n            TaskStatus.IN_PROGRESS: {TaskStatus.COMPLETED, TaskStatus.FAILED, \n                                    TaskStatus.CANCELLED},\n            TaskStatus.FAILED: set(),\n            TaskStatus.COMPLETED: set(),\n            TaskStatus.CANCELLED: set(),\n        }\n        return to_status in valid_transitions.get(from_status, set())\n    \n    def cancel_task(self, task_id: str) -> bool:\n        \"\"\"Cancel a pending task\"\"\"\n        with self._lock:\n            task = self._tasks.get(task_id)\n            if not task:\n                return False\n            if task.status == TaskStatus.PENDING:\n                try:\n                    self.update_status(task_id, TaskStatus.CANCELLED)\n                    return True\n                except (TaskNotFoundError, InvalidStateTransitionError):\n                    return False\n            return False\n    \n    def requeue_task(self, task_id: str, reset_retries: bool = False) -> bool:\n        \"\"\"\n        Manually requeue a task (for worker failures or manual retry).\n        Only works for IN_PROGRESS tasks.\n        \"\"\"\n        with self._lock:\n            task = self._tasks.get(task_id)\n            if not task or task.status != TaskStatus.IN_PROGRESS:\n                return False\n            \n            task.status = TaskStatus.PENDING\n            task.started_at = None\n            task.worker_id = None\n            task.updated_at = datetime.utcnow()\n            \n            if reset_retries:\n                task.retry_count = 0\n                task.error_message = None\n            \n            if task_id not in self._heap_task_ids:\n                self._add_to_heap(task)\n            \n            return True\n    \n    def get_queue_stats(self) -> dict:\n        \"\"\"Get comprehensive queue statistics\"\"\"\n        with self._lock:\n            status_counts = defaultdict(int)\n            priority_counts = defaultdict(int)\n            \n            for task in self._tasks.values():\n                status_counts[task.status.value] += 1\n                if task.status == TaskStatus.PENDING:\n                    priority_counts[task.priority.name] += 1\n            \n            return {\n                \"total_tasks\": len(self._tasks),\n                \"pending\": status_counts[TaskStatus.PENDING.value],\n                \"in_progress\": status_counts[TaskStatus.IN_PROGRESS.value],\n                \"completed\": status_counts[TaskStatus.COMPLETED.value],\n                \"failed\": status_counts[TaskStatus.FAILED.value],\n                \"cancelled\": status_counts[TaskStatus.CANCELLED.value],\n                \"pending_by_priority\": dict(priority_counts),\n                \"heap_size\": len(self._heap),\n                \"heap_efficiency\": self._heap_health.efficiency,\n                \"last_cleanup\": self._last_cleanup.isoformat(),\n                \"last_heap_rebuild\": self._heap_health.last_rebuild.isoformat()\n            }\n    \n    def force_cleanup(self) -> dict:\n        \"\"\"Manually trigger cleanup and return results\"\"\"\n        with self._lock:\n            before_count = len(self._tasks)\n            self._cleanup_old_tasks()\n            after_count = len(self._tasks)\n            \n            before_heap = len(self._heap)\n            self._rebuild_heap()\n            after_heap = len(self._heap)\n            \n            return {\n                \"tasks_removed\": before_count - after_count,\n                \"heap_entries_removed\": before_heap - after_heap,\n                \"tasks_remaining\": after_count,\n                \"heap_size\": after_heap\n            }\n\n# Custom exceptions\nclass QueueFullError(Exception):\n    pass\n\nclass TaskNotFoundError(Exception):\n    pass\n\nclass InvalidStateTransitionError(Exception):\n    pass\n```\n\n### 4. Task Queue Manager Interface\n```python\nclass TaskQueueManager:\n    \"\"\"High-level interface for task queue operations\"\"\"\n    \n    def __init__(self, \n                 max_queue_size: Optional[int] = None,\n                 task_retention_seconds: int = 3600,\n                 cleanup_interval_seconds: int = 300):\n        \"\"\"\n        Args:\n            max_queue_size: Max pending tasks (None = unlimited)\n            task_retention_seconds: Keep terminal tasks for this long (default 1hr)\n            cleanup_interval_seconds: Run cleanup every N seconds (default 5min)\n        \"\"\"\n        self.queue = PriorityTaskQueue(\n            max_queue_size=max_queue_size,\n            task_retention_seconds=task_retention_seconds,\n            cleanup_interval_seconds=cleanup_interval_seconds\n        )\n    \n    def submit_task(self, \n                   payload: Any, \n                   priority: str = \"medium\",\n                   max_retries: int = 3,\n                   retry_policy: Optional[Dict] = None) -> dict:\n        \"\"\"\n        Submit a new task.\n        \n        Args:\n            payload: Task data\n            priority: \"low\", \"medium\", \"high\", or \"critical\"\n            max_retries: Max automatic retries (0 = no retry)\n            retry_policy: Optional metadata for worker-side retry logic\n                         e.g., {\"backoff\": \"exponential\", \"max_delay\": 300}\n        \"\"\"\n        try:\n            priority_enum = TaskPriority[priority.upper()]\n        except KeyError:\n            raise ValueError(f\"Invalid priority: {priority}. \"\n                           f\"Valid: {[p.name.lower() for p in TaskPriority]}\")\n        \n        if max_retries < 0:\n            raise ValueError(\"max_retries must be non-negative\")\n        \n        try:\n            task_id = self.queue.enqueue(payload, priority_enum, max_retries, \n                                        retry_policy)\n            return {\n                \"task_id\": task_id, \n                \"status\": \"pending\",\n                \"priority\": priority\n            }\n        except QueueFullError as e:\n            return {\"error\": str(e), \"status\": \"rejected\"}\n    \n    def get_next_task(self, worker_id: Optional[str] = None) -> Optional[dict]:\n        \"\"\"\n        Worker polls for next task.\n        Returns None if queue is empty.\n        \"\"\"\n        task = self.queue.dequeue(worker_id=worker_id)\n        if task:\n            return {\n                \"task_id\": task.id,\n                \"payload\": task.payload,\n                \"priority\": task.priority.name,\n                \"retry_count\": task.retry_count,\n                \"max_retries\": task.max_retries,\n                \"retry_policy\": task.retry_policy\n            }\n        return None\n    \n    def complete_task(self, task_id: str, success: bool = True, \n                     error: Optional[str] = None) -> dict:\n        \"\"\"\n        Mark task as completed or failed.\n        Automatic retry happens based on max_retries.\n        \"\"\"\n        try:\n            status = TaskStatus.COMPLETED if success else TaskStatus.FAILED\n            success_flag, was_retried = self.queue.update_status(\n                task_id, status, error\n            )\n            \n            return {\n                \"task_id\": task_id,\n                \"status\": status.value,\n                \"retried\": was_retried\n            }\n        except (TaskNotFoundError, InvalidStateTransitionError) as e:\n            return {\"error\": str(e)}\n    \n    def get_task_status(self, task_id: str) -> Optional[dict]:\n        \"\"\"Get detailed task status\"\"\"\n        task = self.queue.get_task(task_id)\n        if not task:\n            return None\n        \n        return {\n            \"task_id\": task.id,\n            \"status\": task.status.value,\n            \"priority\": task.priority.name,\n            \"created_at\": task.created_at.isoformat(),\n            \"started_at\": task.started_at.isoformat() if task.started_at else None,\n            \"completed_at\": task.completed_at.isoformat() if task.completed_at else None,\n            \"error_message\": task.error_message,\n            \"retry_count\": task.retry_count,\n            \"max_retries\": task.max_retries,\n            \"worker_id\": task.worker_id,\n            \"age_seconds\": task.age_seconds(),\n            \"time_in_progress\": task.time_in_progress_seconds()\n        }\n    \n    def cancel_task(self, task_id: str) -> dict:\n        \"\"\"Cancel a pending task\"\"\"\n        success = self.queue.cancel_task(task_id)\n        return {\n            \"task_id\": task_id,\n            \"cancelled\": success,\n            \"message\": \"Task cancelled\" if success \n                      else \"Task not pending or not found\"\n        }\n    \n    def requeue_task(self, task_id: str, reset_retries: bool = False) -> dict:\n        \"\"\"\n        Manually requeue an in-progress task.\n        Useful for worker failure recovery.\n        \"\"\"\n        success = self.queue.requeue_task(task_id, reset_retries)\n        return {\n            \"task_id\": task_id,\n            \"requeued\": success,\n            \"reset_retries\": reset_retries,\n            \"message\": \"Task requeued\" if success \n                      else \"Task not in-progress or not found\"\n        }\n    \n    def get_statistics(self) -> dict:\n        \"\"\"Get comprehensive queue statistics\"\"\"\n        return self.queue.get_queue_stats()\n    \n    def force_maintenance(self) -> dict:\n        \"\"\"\n        Manually trigger cleanup and heap rebuild.\n        Useful for testing or emergency maintenance.\n        \"\"\"\n        return self.queue.force_cleanup()\n```\n\n### 5. Health Monitor & Supervisor Utilities\n```python\nclass TaskSupervisor:\n    \"\"\"Monitor and recover stuck tasks\"\"\"\n    \n    def __init__(self, manager: TaskQueueManager, \n                 stuck_threshold_seconds: int = 300):\n        self.manager = manager\n        self.stuck_threshold = stuck_threshold_seconds\n    \n    def check_stuck_tasks(self) -> list[dict]:\n        \"\"\"Find tasks stuck in IN_PROGRESS state\"\"\"\n        stats = self.manager.get_statistics()\n        stuck_tasks = []\n        \n        # Would need to iterate tasks - simplified here\n        # In production, maintain a separate index of in-progress tasks\n        \n        return stuck_tasks\n    \n    def requeue_stuck_tasks(self) -> dict:\n        \"\"\"Automatically requeue stuck tasks\"\"\"\n        stuck = self.check_stuck_tasks()\n        requeued = []\n        \n        for task_info in stuck:\n            result = self.manager.requeue_task(task_info['task_id'])\n            if result['requeued']:\n                requeued.append(task_info['task_id'])\n        \n        return {\n            \"stuck_tasks_found\": len(stuck),\n            \"tasks_requeued\": len(requeued),\n            \"task_ids\": requeued\n        }\n```\n\n## Usage Examples\n\n### Basic Worker (Automatic Retry)\n```python\n# Initialize with bounded memory\nmanager = TaskQueueManager(\n    max_queue_size=10000,\n    task_retention_seconds=3600,  # Keep completed tasks for 1 hour\n    cleanup_interval_seconds=300   # Cleanup every 5 minutes\n)\n\n# Submit tasks with automatic retry\ntask1 = manager.submit_task(\n    {\"action\": \"send_email\", \"to\": \"user@example.com\"}, \n    priority=\"high\",\n    max_retries=3  # Will retry up to 3 times automatically\n)\n\n# Simple worker loop - retry is automatic\nworker_id = \"worker-1\"\nwhile True:\n    task = manager.get_next_task(worker_id=worker_id)\n    if task:\n        try:\n            result = process(task['payload'])\n            manager.complete_task(task['task_id'], success=True)\n        except Exception as e:\n            # Automatic retry based on max_retries\n            manager.complete_task(task['task_id'], success=False, error=str(e))\n    else:\n        time.sleep(1)\n```\n\n### Advanced Worker with Retry Policy Metadata\n```python\n# Submit task with retry policy hints for worker\ntask = manager.submit_task(\n    {\"action\": \"api_call\", \"url\": \"https://api.example.com\"},\n    priority=\"medium\",\n    max_retries=5,\n    retry_policy={\n        \"backoff\": \"exponential\",\n        \"base_delay\": 2,\n        \"max_delay\": 60,\n        \"retryable_errors\": [\"timeout\", \"rate_limit\"]\n    }\n)\n\n# Worker interprets retry_policy for smart delays\ndef smart_worker():\n    while True:\n        task = manager.get_next_task(worker_id=\"smart-worker\")\n        if not task:\n            time.sleep(1)\n            continue\n        \n        try:\n            result = process(task['payload'])\n            manager.complete_task(task['task_id'], success=True)\n        except Exception as e:\n            # Mark as failed (automatic retry happens in queue)\n            manager.complete_task(task['task_id'], success=False, error=str(e))\n            \n            # Worker can implement smart delay before next poll\n            if task.get('retry_policy'):\n                policy = task['retry_policy']\n                if policy.get('backoff') == 'exponential':\n                    delay = min(\n                        policy['base_delay'] ** task['retry_count'],\n                        policy['max_delay']\n                    )\n                    time.sleep(delay)\n```\n\n### Monitoring & Maintenance\n```python\n# Check queue health\nstats = manager.get_statistics()\nprint(f\"Heap efficiency: {stats['heap_efficiency']:.2%}\")\nprint(f\"Pending tasks: {stats['pending']}\")\nprint(f\"Tasks in progress: {stats['in_progress']}\")\n\n# Force maintenance if needed\nif stats['heap_efficiency'] < 0.3:\n    result = manager.force_maintenance()\n    print(f\"Cleaned up {result['tasks_removed']} old tasks\")\n    print(f\"Removed {result['heap_entries_removed']} stale heap entries\")\n\n# Supervisor for stuck task recovery\nsupervisor = TaskSupervisor(manager, stuck_threshold_seconds=300)\nrecovery = supervisor.requeue_stuck_tasks()\nprint(f\"Requeued {recovery['tasks_requeued']} stuck tasks\")\n```\n\n## Rationale\n\n### 1. **Simplified Retry Philosophy**\n- **Removed** `allow_retry` parameter - added complexity without clear benefit\n- **Automatic retry** based on `max_retries` is simple and covers 95% of cases\n- **Worker flexibility** maintained through `retry_policy` metadata (hints, not control)\n- **Manual override** still possible via `requeue_task()` for special cases\n- **Result**: Simpler API, clearer semantics, less cognitive load\n\n### 2. **Bounded Memory via Automatic Cleanup**\n- **Problem**: Previous design accumulated terminal tasks forever\n- **Solution**: Automatic cleanup of old completed/failed/cancelled tasks\n- **Configurable retention**: Keep tasks for N seconds (default 1 hour)\n- **Periodic execution**: Cleanup runs every M seconds (default 5 minutes)\n- **Opportunistic**: Also runs during enqueue/dequeue for zero-overhead\n- **Result**: Bounded memory growth, predictable resource usage\n\n### 3. **Heap Health Monitoring & Auto-Rebuild**\n- **Problem**: Lazy deletion causes heap bloat with cancelled tasks\n- **Solution**: Track heap efficiency (valid/total entries)\n- **Automatic rebuild**: Trigger when efficiency < 50% and heap > 100 entries\n- **Graceful degradation**: System works even with bloated heap, just slower\n- **Manual override**: `force_maintenance()` for emergency cleanup\n- **Result**: Self-healing system, maintains O(log n) performance\n\n### 4. **Enhanced Observability**\n- Added `age_seconds()` and `time_in_progress_seconds()` to Task\n- Heap efficiency metrics in statistics\n- Last cleanup/rebuild timestamps\n- **Result**: Easy to diagnose performance issues, monitor health\n\n### 5. **Retry Policy as Metadata**\n- Workers receive `retry_policy` dict with task\n- Queue doesn't interpret it - just passes it along\n- Workers can implement smart delays, conditional retry, etc.\n- **Result**: Flexibility without complicating queue internals\n\n## What I Changed\n\n### Removed `allow_retry` Parameter\n- Simplified `complete_task()` signature\n- Retry is now purely based on `max_retries` counter\n- Workers who need custom logic use `retry_policy` metadata + manual `requeue_task()`\n- **Why**: The hybrid approach added API complexity. Most users want simple automatic retry.\n\n### Added Automatic Memory Management\n- `task_retention_seconds`: Configurable TTL for terminal tasks\n- `cleanup_interval_seconds`: How often to run cleanup\n- `_cleanup_old_tasks()`: Removes tasks past retention period\n- `_maybe_cleanup()`: Opportunistic cleanup on enqueue/dequeue\n- **Why**: Prevents unbounded memory growth in long-running systems\n\n### Added Heap Health Tracking\n- `HeapHealth` dataclass tracks valid/invalid entries\n- Automatic rebuild when efficiency drops below 50%\n- Manual `force_maintenance()` for emergency cleanup\n- **Why**: Lazy deletion is correct but can degrade performance; this fixes it\n\n### Simplified State Transitions\n- Removed separate retry logic from `update_status()`\n- Retry happens inline when marking FAILED\n- Returns `(success, was_retried)` tuple\n- **Why**: Clearer flow, easier to reason about\n\n### Added Task Helper Methods\n- `is_terminal()`: Check if task is done\n- `age_seconds()`: Task age for monitoring\n- `time_in_progress_seconds()`: Execution time tracking\n- **Why**: Common queries shouldn't require datetime math everywhere\n\n## What I Kept\n\n- **Core heap architecture**: Efficient, proven design\n- **RLock for thread safety**: Essential for concurrent workers\n- **Lazy deletion strategy**: Still correct, now with health monitoring\n- **State machine validation**: Prevents invalid transitions\n- **Worker ID tracking**: Useful for debugging\n- **Manual requeue**: Critical for supervisor pattern\n- **Comprehensive statistics**: Good observability foundation\n- **Sequence numbers**: Stable FIFO within priority\n\n## Open Questions\n\n### Performance Under Load\n- How does cleanup impact throughput under heavy load?\n- Should cleanup run in a background thread instead of opportunistically?\n- What's the optimal cleanup interval for different workloads?\n\n### Persistence Strategy\n- Migration path to Redis/PostgreSQL for durability?\n- Should we maintain API compatibility when adding persistence?\n- How to handle queue initialization from persistent storage?\n\n### Monitoring Integration\n- Should we add built-in Prometheus metrics?\n- Event hooks for external monitoring systems?\n- Structured logging for task lifecycle events?\n\n### Advanced Scheduling\n- Should we support scheduled/delayed tasks (execute_after timestamp)?\n- Task dependencies (task B runs after task A completes)?\n- Task groups for batch operations?\n\n## Convergence Status\n\n**ITERATING** - Design is production-ready for basic use cases but needs validation on:\n1. Whether automatic cleanup intervals work for your workload\n2. If simplified retry model (no `allow_retry`) meets requirements\n3. Trade-offs between cleanup overhead and memory bounds\n\n## Prompt for Collaborator",
        "prompt_for_other": "I've simplified the retry model and added automatic memory management. Key decisions:\n\n1. **Removed `allow_retry` parameter**: Retry is now purely automatic based on `max_retries`. Workers who need custom logic can use `retry_policy` metadata (the queue just passes it along) or manual `requeue_task()`. Is this simpler model sufficient, or do you see use cases where workers truly need per-failure retry control at the API level?\n\n2. **Automatic cleanup**: Tasks are removed after `task_retention_seconds` (default 1 hour). Cleanup runs every 5 minutes opportunistically. Does this solve the memory growth concern? Are the defaults reasonable, or should we expose more tuning knobs?\n\n3. **Heap auto-rebuild**: Triggers when efficiency < 50% and size > 100. This prevents lazy deletion from degrading performance. Are these thresholds reasonable, or should they be configurable?\n\n4. **What did I over-simplify?** Did removing `allow_retry` lose important functionality? Should cleanup be more sophisticated (per-status retention policies)?",
        "convergence_signal": "ITERATING",
        "raw_response": "## Design\n\n# Priority Task Queue System with Bounded Memory & Smart Cleanup\n\n## Architecture Overview\n\nA production-ready priority task queue system with in-memory storage, automatic memory management, and flexible retry policies. Key improvements: bounded memory through automatic cleanup, heap health monitoring, and simplified worker API.\n\n## Core Components\n\n### 1. Task Model\n```python\nfrom enum import Enum\nfrom dataclasses import dataclass, field\nfrom typing import Optional, Any, Dict\nfrom datetime import datetime, timedelta\nimport uuid\n\nclass TaskStatus(Enum):\n    PENDING = \"pending\"\n    IN_PROGRESS = \"in_progress\"\n    COMPLETED = \"completed\"\n    FAILED = \"failed\"\n    CANCELLED = \"cancelled\"\n\nclass TaskPriority(Enum):\n    LOW = 1\n    MEDIUM = 2\n    HIGH = 3\n    CRITICAL = 4\n\n@dataclass\nclass Task:\n    id: str\n    payload: Any\n    priority: TaskPriority\n    status: TaskStatus\n    created_at: datetime\n    updated_at: datetime\n    started_at: Optional[datetime] = None\n    completed_at: Optional[datetime] = None\n    error_message: Optional[str] = None\n    retry_count: int = 0\n    max_retries: int = 3\n    sequence: int = 0\n    worker_id: Optional[str] = None\n    # Retry policy metadata\n    retry_policy: Optional[Dict[str, Any]] = None\n    \n    def is_terminal(self) -> bool:\n        \"\"\"Check if task is in a terminal state\"\"\"\n        return self.status in {TaskStatus.COMPLETED, TaskStatus.FAILED, \n                               TaskStatus.CANCELLED}\n    \n    def age_seconds(self) -> float:\n        \"\"\"Get task age in seconds\"\"\"\n        return (datetime.utcnow() - self.created_at).total_seconds()\n    \n    def time_in_progress_seconds(self) -> Optional[float]:\n        \"\"\"Get time spent in progress (None if not started)\"\"\"\n        if not self.started_at:\n            return None\n        end_time = self.completed_at or datetime.utcnow()\n        return (end_time - self.started_at).total_seconds()\n```\n\n### 2. Heap Health Monitor\n```python\n@dataclass\nclass HeapHealth:\n    \"\"\"Track heap efficiency for automatic maintenance\"\"\"\n    total_entries: int = 0\n    valid_entries: int = 0\n    invalid_entries: int = 0\n    last_rebuild: datetime = field(default_factory=datetime.utcnow)\n    \n    @property\n    def efficiency(self) -> float:\n        \"\"\"Percentage of valid entries in heap\"\"\"\n        if self.total_entries == 0:\n            return 1.0\n        return self.valid_entries / self.total_entries\n    \n    @property\n    def should_rebuild(self) -> bool:\n        \"\"\"Rebuild if efficiency drops below 50% and heap has 100+ entries\"\"\"\n        return (self.efficiency < 0.5 and self.total_entries >= 100)\n```\n\n### 3. Priority Queue Storage with Auto-Cleanup\n```python\nimport heapq\nimport threading\nfrom collections import defaultdict\nfrom typing import Set, Optional, Tuple\n\nclass PriorityTaskQueue:\n    def __init__(self, \n                 max_queue_size: Optional[int] = None,\n                 task_retention_seconds: int = 3600,\n                 cleanup_interval_seconds: int = 300):\n        \"\"\"\n        Args:\n            max_queue_size: Max pending tasks (None = unlimited)\n            task_retention_seconds: How long to keep completed/failed tasks (default 1hr)\n            cleanup_interval_seconds: How often to run cleanup (default 5min)\n        \"\"\"\n        self._lock = threading.RLock()\n        self._heap = []\n        self._tasks: Dict[str, Task] = {}\n        self._heap_task_ids: Set[str] = set()\n        self._counter = 0\n        self._max_queue_size = max_queue_size\n        self._task_retention = timedelta(seconds=task_retention_seconds)\n        self._cleanup_interval = timedelta(seconds=cleanup_interval_seconds)\n        self._last_cleanup = datetime.utcnow()\n        self._heap_health = HeapHealth()\n        \n    def enqueue(self, payload: Any, priority: TaskPriority = TaskPriority.MEDIUM,\n                max_retries: int = 3, retry_policy: Optional[Dict] = None) -> str:\n        \"\"\"Add task to queue, return task ID\"\"\"\n        with self._lock:\n            # Run cleanup opportunistically\n            self._maybe_cleanup()\n            \n            # Check queue size limit (only count PENDING)\n            pending_count = sum(1 for t in self._tasks.values() \n                              if t.status == TaskStatus.PENDING)\n            if self._max_queue_size and pending_count >= self._max_queue_size:\n                raise QueueFullError(f\"Queue at capacity: {self._max_queue_size}\")\n            \n            task = Task(\n                id=str(uuid.uuid4()),\n                payload=payload,\n                priority=priority,\n                status=TaskStatus.PENDING,\n                created_at=datetime.utcnow(),\n                updated_at=datetime.utcnow(),\n                max_retries=max_retries,\n                sequence=self._counter,\n                retry_policy=retry_policy\n            )\n            self._tasks[task.id] = task\n            self._add_to_heap(task)\n            return task.id\n    \n    def _add_to_heap(self, task: Task):\n        \"\"\"Add task to heap with health tracking\"\"\"\n        heapq.heappush(self._heap, (-task.priority.value, task.sequence, task.id))\n        self._heap_task_ids.add(task.id)\n        self._counter += 1\n        self._heap_health.total_entries += 1\n        self._heap_health.valid_entries += 1\n    \n    def dequeue(self, worker_id: Optional[str] = None) -> Optional[Task]:\n        \"\"\"Get highest priority pending task\"\"\"\n        with self._lock:\n            self._maybe_cleanup()\n            \n            found_valid = False\n            while self._heap:\n                _, _, task_id = heapq.heappop(self._heap)\n                self._heap_task_ids.discard(task_id)\n                self._heap_health.total_entries -= 1\n                \n                task = self._tasks.get(task_id)\n                \n                if not task or task.status != TaskStatus.PENDING:\n                    # Invalid entry, continue searching\n                    continue\n                \n                # Found valid task\n                found_valid = True\n                self._heap_health.valid_entries -= 1\n                task.status = TaskStatus.IN_PROGRESS\n                task.started_at = datetime.utcnow()\n                task.updated_at = datetime.utcnow()\n                task.worker_id = worker_id\n                \n                # Check if heap needs rebuilding\n                if self._heap_health.should_rebuild:\n                    self._rebuild_heap()\n                \n                return task\n            \n            # Heap exhausted\n            if not found_valid and self._heap_health.total_entries > 0:\n                # All remaining entries are invalid, rebuild\n                self._rebuild_heap()\n            \n            return None\n    \n    def _rebuild_heap(self):\n        \"\"\"Rebuild heap with only valid pending tasks\"\"\"\n        with self._lock:\n            valid_tasks = [t for t in self._tasks.values() \n                          if t.status == TaskStatus.PENDING]\n            \n            self._heap.clear()\n            self._heap_task_ids.clear()\n            \n            for task in valid_tasks:\n                heapq.heappush(self._heap, \n                             (-task.priority.value, task.sequence, task.id))\n                self._heap_task_ids.add(task.id)\n            \n            self._heap_health = HeapHealth(\n                total_entries=len(self._heap),\n                valid_entries=len(self._heap),\n                invalid_entries=0,\n                last_rebuild=datetime.utcnow()\n            )\n    \n    def _maybe_cleanup(self):\n        \"\"\"Run cleanup if enough time has passed\"\"\"\n        now = datetime.utcnow()\n        if now - self._last_cleanup > self._cleanup_interval:\n            self._cleanup_old_tasks()\n            self._last_cleanup = now\n    \n    def _cleanup_old_tasks(self):\n        \"\"\"Remove old terminal tasks to prevent unbounded memory growth\"\"\"\n        with self._lock:\n            now = datetime.utcnow()\n            cutoff = now - self._task_retention\n            \n            to_delete = []\n            for task_id, task in self._tasks.items():\n                if task.is_terminal() and task.updated_at < cutoff:\n                    to_delete.append(task_id)\n            \n            for task_id in to_delete:\n                del self._tasks[task_id]\n                # Note: task might still be in heap, but will be skipped during dequeue\n    \n    def get_task(self, task_id: str) -> Optional[Task]:\n        \"\"\"Retrieve task by ID (returns reference for internal use)\"\"\"\n        with self._lock:\n            return self._tasks.get(task_id)\n    \n    def update_status(self, task_id: str, status: TaskStatus, \n                     error_message: Optional[str] = None) -> Tuple[bool, bool]:\n        \"\"\"\n        Update task status with state validation.\n        Returns: (success, was_retried)\n        \"\"\"\n        with self._lock:\n            task = self._tasks.get(task_id)\n            if not task:\n                raise TaskNotFoundError(f\"Task {task_id} not found\")\n            \n            if not self._is_valid_transition(task.status, status):\n                raise InvalidStateTransitionError(\n                    f\"Cannot transition from {task.status.value} to {status.value}\"\n                )\n            \n            task.status = status\n            task.updated_at = datetime.utcnow()\n            \n            if status == TaskStatus.COMPLETED:\n                task.completed_at = datetime.utcnow()\n                return (True, False)\n            \n            elif status == TaskStatus.FAILED:\n                task.error_message = error_message\n                task.completed_at = datetime.utcnow()\n                task.retry_count += 1\n                \n                # Check if should retry (automatic based on max_retries)\n                if task.retry_count < task.max_retries:\n                    # Reset for retry\n                    task.status = TaskStatus.PENDING\n                    task.started_at = None\n                    task.completed_at = None\n                    task.worker_id = None\n                    \n                    # Add back to heap if not already present\n                    if task_id not in self._heap_task_ids:\n                        self._add_to_heap(task)\n                    \n                    return (True, True)\n                return (True, False)\n            \n            elif status == TaskStatus.CANCELLED:\n                task.completed_at = datetime.utcnow()\n                return (True, False)\n            \n            return (True, False)\n    \n    def _is_valid_transition(self, from_status: TaskStatus, \n                            to_status: TaskStatus) -> bool:\n        \"\"\"Validate state machine transitions\"\"\"\n        valid_transitions = {\n            TaskStatus.PENDING: {TaskStatus.IN_PROGRESS, TaskStatus.CANCELLED},\n            TaskStatus.IN_PROGRESS: {TaskStatus.COMPLETED, TaskStatus.FAILED, \n                                    TaskStatus.CANCELLED},\n            TaskStatus.FAILED: set(),\n            TaskStatus.COMPLETED: set(),\n            TaskStatus.CANCELLED: set(),\n        }\n        return to_status in valid_transitions.get(from_status, set())\n    \n    def cancel_task(self, task_id: str) -> bool:\n        \"\"\"Cancel a pending task\"\"\"\n        with self._lock:\n            task = self._tasks.get(task_id)\n            if not task:\n                return False\n            if task.status == TaskStatus.PENDING:\n                try:\n                    self.update_status(task_id, TaskStatus.CANCELLED)\n                    return True\n                except (TaskNotFoundError, InvalidStateTransitionError):\n                    return False\n            return False\n    \n    def requeue_task(self, task_id: str, reset_retries: bool = False) -> bool:\n        \"\"\"\n        Manually requeue a task (for worker failures or manual retry).\n        Only works for IN_PROGRESS tasks.\n        \"\"\"\n        with self._lock:\n            task = self._tasks.get(task_id)\n            if not task or task.status != TaskStatus.IN_PROGRESS:\n                return False\n            \n            task.status = TaskStatus.PENDING\n            task.started_at = None\n            task.worker_id = None\n            task.updated_at = datetime.utcnow()\n            \n            if reset_retries:\n                task.retry_count = 0\n                task.error_message = None\n            \n            if task_id not in self._heap_task_ids:\n                self._add_to_heap(task)\n            \n            return True\n    \n    def get_queue_stats(self) -> dict:\n        \"\"\"Get comprehensive queue statistics\"\"\"\n        with self._lock:\n            status_counts = defaultdict(int)\n            priority_counts = defaultdict(int)\n            \n            for task in self._tasks.values():\n                status_counts[task.status.value] += 1\n                if task.status == TaskStatus.PENDING:\n                    priority_counts[task.priority.name] += 1\n            \n            return {\n                \"total_tasks\": len(self._tasks),\n                \"pending\": status_counts[TaskStatus.PENDING.value],\n                \"in_progress\": status_counts[TaskStatus.IN_PROGRESS.value],\n                \"completed\": status_counts[TaskStatus.COMPLETED.value],\n                \"failed\": status_counts[TaskStatus.FAILED.value],\n                \"cancelled\": status_counts[TaskStatus.CANCELLED.value],\n                \"pending_by_priority\": dict(priority_counts),\n                \"heap_size\": len(self._heap),\n                \"heap_efficiency\": self._heap_health.efficiency,\n                \"last_cleanup\": self._last_cleanup.isoformat(),\n                \"last_heap_rebuild\": self._heap_health.last_rebuild.isoformat()\n            }\n    \n    def force_cleanup(self) -> dict:\n        \"\"\"Manually trigger cleanup and return results\"\"\"\n        with self._lock:\n            before_count = len(self._tasks)\n            self._cleanup_old_tasks()\n            after_count = len(self._tasks)\n            \n            before_heap = len(self._heap)\n            self._rebuild_heap()\n            after_heap = len(self._heap)\n            \n            return {\n                \"tasks_removed\": before_count - after_count,\n                \"heap_entries_removed\": before_heap - after_heap,\n                \"tasks_remaining\": after_count,\n                \"heap_size\": after_heap\n            }\n\n# Custom exceptions\nclass QueueFullError(Exception):\n    pass\n\nclass TaskNotFoundError(Exception):\n    pass\n\nclass InvalidStateTransitionError(Exception):\n    pass\n```\n\n### 4. Task Queue Manager Interface\n```python\nclass TaskQueueManager:\n    \"\"\"High-level interface for task queue operations\"\"\"\n    \n    def __init__(self, \n                 max_queue_size: Optional[int] = None,\n                 task_retention_seconds: int = 3600,\n                 cleanup_interval_seconds: int = 300):\n        \"\"\"\n        Args:\n            max_queue_size: Max pending tasks (None = unlimited)\n            task_retention_seconds: Keep terminal tasks for this long (default 1hr)\n            cleanup_interval_seconds: Run cleanup every N seconds (default 5min)\n        \"\"\"\n        self.queue = PriorityTaskQueue(\n            max_queue_size=max_queue_size,\n            task_retention_seconds=task_retention_seconds,\n            cleanup_interval_seconds=cleanup_interval_seconds\n        )\n    \n    def submit_task(self, \n                   payload: Any, \n                   priority: str = \"medium\",\n                   max_retries: int = 3,\n                   retry_policy: Optional[Dict] = None) -> dict:\n        \"\"\"\n        Submit a new task.\n        \n        Args:\n            payload: Task data\n            priority: \"low\", \"medium\", \"high\", or \"critical\"\n            max_retries: Max automatic retries (0 = no retry)\n            retry_policy: Optional metadata for worker-side retry logic\n                         e.g., {\"backoff\": \"exponential\", \"max_delay\": 300}\n        \"\"\"\n        try:\n            priority_enum = TaskPriority[priority.upper()]\n        except KeyError:\n            raise ValueError(f\"Invalid priority: {priority}. \"\n                           f\"Valid: {[p.name.lower() for p in TaskPriority]}\")\n        \n        if max_retries < 0:\n            raise ValueError(\"max_retries must be non-negative\")\n        \n        try:\n            task_id = self.queue.enqueue(payload, priority_enum, max_retries, \n                                        retry_policy)\n            return {\n                \"task_id\": task_id, \n                \"status\": \"pending\",\n                \"priority\": priority\n            }\n        except QueueFullError as e:\n            return {\"error\": str(e), \"status\": \"rejected\"}\n    \n    def get_next_task(self, worker_id: Optional[str] = None) -> Optional[dict]:\n        \"\"\"\n        Worker polls for next task.\n        Returns None if queue is empty.\n        \"\"\"\n        task = self.queue.dequeue(worker_id=worker_id)\n        if task:\n            return {\n                \"task_id\": task.id,\n                \"payload\": task.payload,\n                \"priority\": task.priority.name,\n                \"retry_count\": task.retry_count,\n                \"max_retries\": task.max_retries,\n                \"retry_policy\": task.retry_policy\n            }\n        return None\n    \n    def complete_task(self, task_id: str, success: bool = True, \n                     error: Optional[str] = None) -> dict:\n        \"\"\"\n        Mark task as completed or failed.\n        Automatic retry happens based on max_retries.\n        \"\"\"\n        try:\n            status = TaskStatus.COMPLETED if success else TaskStatus.FAILED\n            success_flag, was_retried = self.queue.update_status(\n                task_id, status, error\n            )\n            \n            return {\n                \"task_id\": task_id,\n                \"status\": status.value,\n                \"retried\": was_retried\n            }\n        except (TaskNotFoundError, InvalidStateTransitionError) as e:\n            return {\"error\": str(e)}\n    \n    def get_task_status(self, task_id: str) -> Optional[dict]:\n        \"\"\"Get detailed task status\"\"\"\n        task = self.queue.get_task(task_id)\n        if not task:\n            return None\n        \n        return {\n            \"task_id\": task.id,\n            \"status\": task.status.value,\n            \"priority\": task.priority.name,\n            \"created_at\": task.created_at.isoformat(),\n            \"started_at\": task.started_at.isoformat() if task.started_at else None,\n            \"completed_at\": task.completed_at.isoformat() if task.completed_at else None,\n            \"error_message\": task.error_message,\n            \"retry_count\": task.retry_count,\n            \"max_retries\": task.max_retries,\n            \"worker_id\": task.worker_id,\n            \"age_seconds\": task.age_seconds(),\n            \"time_in_progress\": task.time_in_progress_seconds()\n        }\n    \n    def cancel_task(self, task_id: str) -> dict:\n        \"\"\"Cancel a pending task\"\"\"\n        success = self.queue.cancel_task(task_id)\n        return {\n            \"task_id\": task_id,\n            \"cancelled\": success,\n            \"message\": \"Task cancelled\" if success \n                      else \"Task not pending or not found\"\n        }\n    \n    def requeue_task(self, task_id: str, reset_retries: bool = False) -> dict:\n        \"\"\"\n        Manually requeue an in-progress task.\n        Useful for worker failure recovery.\n        \"\"\"\n        success = self.queue.requeue_task(task_id, reset_retries)\n        return {\n            \"task_id\": task_id,\n            \"requeued\": success,\n            \"reset_retries\": reset_retries,\n            \"message\": \"Task requeued\" if success \n                      else \"Task not in-progress or not found\"\n        }\n    \n    def get_statistics(self) -> dict:\n        \"\"\"Get comprehensive queue statistics\"\"\"\n        return self.queue.get_queue_stats()\n    \n    def force_maintenance(self) -> dict:\n        \"\"\"\n        Manually trigger cleanup and heap rebuild.\n        Useful for testing or emergency maintenance.\n        \"\"\"\n        return self.queue.force_cleanup()\n```\n\n### 5. Health Monitor & Supervisor Utilities\n```python\nclass TaskSupervisor:\n    \"\"\"Monitor and recover stuck tasks\"\"\"\n    \n    def __init__(self, manager: TaskQueueManager, \n                 stuck_threshold_seconds: int = 300):\n        self.manager = manager\n        self.stuck_threshold = stuck_threshold_seconds\n    \n    def check_stuck_tasks(self) -> list[dict]:\n        \"\"\"Find tasks stuck in IN_PROGRESS state\"\"\"\n        stats = self.manager.get_statistics()\n        stuck_tasks = []\n        \n        # Would need to iterate tasks - simplified here\n        # In production, maintain a separate index of in-progress tasks\n        \n        return stuck_tasks\n    \n    def requeue_stuck_tasks(self) -> dict:\n        \"\"\"Automatically requeue stuck tasks\"\"\"\n        stuck = self.check_stuck_tasks()\n        requeued = []\n        \n        for task_info in stuck:\n            result = self.manager.requeue_task(task_info['task_id'])\n            if result['requeued']:\n                requeued.append(task_info['task_id'])\n        \n        return {\n            \"stuck_tasks_found\": len(stuck),\n            \"tasks_requeued\": len(requeued),\n            \"task_ids\": requeued\n        }\n```\n\n## Usage Examples\n\n### Basic Worker (Automatic Retry)\n```python\n# Initialize with bounded memory\nmanager = TaskQueueManager(\n    max_queue_size=10000,\n    task_retention_seconds=3600,  # Keep completed tasks for 1 hour\n    cleanup_interval_seconds=300   # Cleanup every 5 minutes\n)\n\n# Submit tasks with automatic retry\ntask1 = manager.submit_task(\n    {\"action\": \"send_email\", \"to\": \"user@example.com\"}, \n    priority=\"high\",\n    max_retries=3  # Will retry up to 3 times automatically\n)\n\n# Simple worker loop - retry is automatic\nworker_id = \"worker-1\"\nwhile True:\n    task = manager.get_next_task(worker_id=worker_id)\n    if task:\n        try:\n            result = process(task['payload'])\n            manager.complete_task(task['task_id'], success=True)\n        except Exception as e:\n            # Automatic retry based on max_retries\n            manager.complete_task(task['task_id'], success=False, error=str(e))\n    else:\n        time.sleep(1)\n```\n\n### Advanced Worker with Retry Policy Metadata\n```python\n# Submit task with retry policy hints for worker\ntask = manager.submit_task(\n    {\"action\": \"api_call\", \"url\": \"https://api.example.com\"},\n    priority=\"medium\",\n    max_retries=5,\n    retry_policy={\n        \"backoff\": \"exponential\",\n        \"base_delay\": 2,\n        \"max_delay\": 60,\n        \"retryable_errors\": [\"timeout\", \"rate_limit\"]\n    }\n)\n\n# Worker interprets retry_policy for smart delays\ndef smart_worker():\n    while True:\n        task = manager.get_next_task(worker_id=\"smart-worker\")\n        if not task:\n            time.sleep(1)\n            continue\n        \n        try:\n            result = process(task['payload'])\n            manager.complete_task(task['task_id'], success=True)\n        except Exception as e:\n            # Mark as failed (automatic retry happens in queue)\n            manager.complete_task(task['task_id'], success=False, error=str(e))\n            \n            # Worker can implement smart delay before next poll\n            if task.get('retry_policy'):\n                policy = task['retry_policy']\n                if policy.get('backoff') == 'exponential':\n                    delay = min(\n                        policy['base_delay'] ** task['retry_count'],\n                        policy['max_delay']\n                    )\n                    time.sleep(delay)\n```\n\n### Monitoring & Maintenance\n```python\n# Check queue health\nstats = manager.get_statistics()\nprint(f\"Heap efficiency: {stats['heap_efficiency']:.2%}\")\nprint(f\"Pending tasks: {stats['pending']}\")\nprint(f\"Tasks in progress: {stats['in_progress']}\")\n\n# Force maintenance if needed\nif stats['heap_efficiency'] < 0.3:\n    result = manager.force_maintenance()\n    print(f\"Cleaned up {result['tasks_removed']} old tasks\")\n    print(f\"Removed {result['heap_entries_removed']} stale heap entries\")\n\n# Supervisor for stuck task recovery\nsupervisor = TaskSupervisor(manager, stuck_threshold_seconds=300)\nrecovery = supervisor.requeue_stuck_tasks()\nprint(f\"Requeued {recovery['tasks_requeued']} stuck tasks\")\n```\n\n## Rationale\n\n### 1. **Simplified Retry Philosophy**\n- **Removed** `allow_retry` parameter - added complexity without clear benefit\n- **Automatic retry** based on `max_retries` is simple and covers 95% of cases\n- **Worker flexibility** maintained through `retry_policy` metadata (hints, not control)\n- **Manual override** still possible via `requeue_task()` for special cases\n- **Result**: Simpler API, clearer semantics, less cognitive load\n\n### 2. **Bounded Memory via Automatic Cleanup**\n- **Problem**: Previous design accumulated terminal tasks forever\n- **Solution**: Automatic cleanup of old completed/failed/cancelled tasks\n- **Configurable retention**: Keep tasks for N seconds (default 1 hour)\n- **Periodic execution**: Cleanup runs every M seconds (default 5 minutes)\n- **Opportunistic**: Also runs during enqueue/dequeue for zero-overhead\n- **Result**: Bounded memory growth, predictable resource usage\n\n### 3. **Heap Health Monitoring & Auto-Rebuild**\n- **Problem**: Lazy deletion causes heap bloat with cancelled tasks\n- **Solution**: Track heap efficiency (valid/total entries)\n- **Automatic rebuild**: Trigger when efficiency < 50% and heap > 100 entries\n- **Graceful degradation**: System works even with bloated heap, just slower\n- **Manual override**: `force_maintenance()` for emergency cleanup\n- **Result**: Self-healing system, maintains O(log n) performance\n\n### 4. **Enhanced Observability**\n- Added `age_seconds()` and `time_in_progress_seconds()` to Task\n- Heap efficiency metrics in statistics\n- Last cleanup/rebuild timestamps\n- **Result**: Easy to diagnose performance issues, monitor health\n\n### 5. **Retry Policy as Metadata**\n- Workers receive `retry_policy` dict with task\n- Queue doesn't interpret it - just passes it along\n- Workers can implement smart delays, conditional retry, etc.\n- **Result**: Flexibility without complicating queue internals\n\n## What I Changed\n\n### Removed `allow_retry` Parameter\n- Simplified `complete_task()` signature\n- Retry is now purely based on `max_retries` counter\n- Workers who need custom logic use `retry_policy` metadata + manual `requeue_task()`\n- **Why**: The hybrid approach added API complexity. Most users want simple automatic retry.\n\n### Added Automatic Memory Management\n- `task_retention_seconds`: Configurable TTL for terminal tasks\n- `cleanup_interval_seconds`: How often to run cleanup\n- `_cleanup_old_tasks()`: Removes tasks past retention period\n- `_maybe_cleanup()`: Opportunistic cleanup on enqueue/dequeue\n- **Why**: Prevents unbounded memory growth in long-running systems\n\n### Added Heap Health Tracking\n- `HeapHealth` dataclass tracks valid/invalid entries\n- Automatic rebuild when efficiency drops below 50%\n- Manual `force_maintenance()` for emergency cleanup\n- **Why**: Lazy deletion is correct but can degrade performance; this fixes it\n\n### Simplified State Transitions\n- Removed separate retry logic from `update_status()`\n- Retry happens inline when marking FAILED\n- Returns `(success, was_retried)` tuple\n- **Why**: Clearer flow, easier to reason about\n\n### Added Task Helper Methods\n- `is_terminal()`: Check if task is done\n- `age_seconds()`: Task age for monitoring\n- `time_in_progress_seconds()`: Execution time tracking\n- **Why**: Common queries shouldn't require datetime math everywhere\n\n## What I Kept\n\n- **Core heap architecture**: Efficient, proven design\n- **RLock for thread safety**: Essential for concurrent workers\n- **Lazy deletion strategy**: Still correct, now with health monitoring\n- **State machine validation**: Prevents invalid transitions\n- **Worker ID tracking**: Useful for debugging\n- **Manual requeue**: Critical for supervisor pattern\n- **Comprehensive statistics**: Good observability foundation\n- **Sequence numbers**: Stable FIFO within priority\n\n## Open Questions\n\n### Performance Under Load\n- How does cleanup impact throughput under heavy load?\n- Should cleanup run in a background thread instead of opportunistically?\n- What's the optimal cleanup interval for different workloads?\n\n### Persistence Strategy\n- Migration path to Redis/PostgreSQL for durability?\n- Should we maintain API compatibility when adding persistence?\n- How to handle queue initialization from persistent storage?\n\n### Monitoring Integration\n- Should we add built-in Prometheus metrics?\n- Event hooks for external monitoring systems?\n- Structured logging for task lifecycle events?\n\n### Advanced Scheduling\n- Should we support scheduled/delayed tasks (execute_after timestamp)?\n- Task dependencies (task B runs after task A completes)?\n- Task groups for batch operations?\n\n## Convergence Status\n\n**ITERATING** - Design is production-ready for basic use cases but needs validation on:\n1. Whether automatic cleanup intervals work for your workload\n2. If simplified retry model (no `allow_retry`) meets requirements\n3. Trade-offs between cleanup overhead and memory bounds\n\n## Prompt for Collaborator\n\nPROMPT_FOR_CRITIC:\n\nI've simplified the retry model and added automatic memory management. Key decisions:\n\n1. **Removed `allow_retry` parameter**: Retry is now purely automatic based on `max_retries`. Workers who need custom logic can use `retry_policy` metadata (the queue just passes it along) or manual `requeue_task()`. Is this simpler model sufficient, or do you see use cases where workers truly need per-failure retry control at the API level?\n\n2. **Automatic cleanup**: Tasks are removed after `task_retention_seconds` (default 1 hour). Cleanup runs every 5 minutes opportunistically. Does this solve the memory growth concern? Are the defaults reasonable, or should we expose more tuning knobs?\n\n3. **Heap auto-rebuild**: Triggers when efficiency < 50% and size > 100. This prevents lazy deletion from degrading performance. Are these thresholds reasonable, or should they be configurable?\n\n4. **What did I over-simplify?** Did removing `allow_retry` lose important functionality? Should cleanup be more sophisticated (per-status retention policies)?"
      },
      "agent_b": {
        "content": "## Design\n\n# Priority Task Queue System with Bounded Memory, Configurable Policies & Comprehensive Monitoring\n\n## Architecture Overview\n\nA production-ready priority task queue system with in-memory storage, intelligent memory management, flexible cleanup policies, and enterprise-grade observability. Key improvements: configurable cleanup thresholds, per-status retention policies, safe concurrent cleanup, enhanced error recovery, and comprehensive metrics.\n\n## Core Components\n\n### 1. Task Model\n```python\nfrom enum import Enum\nfrom dataclasses import dataclass, field\nfrom typing import Optional, Any, Dict\nfrom datetime import datetime, timedelta\nimport uuid\n\nclass TaskStatus(Enum):\n    PENDING = \"pending\"\n    IN_PROGRESS = \"in_progress\"\n    COMPLETED = \"completed\"\n    FAILED = \"failed\"\n    CANCELLED = \"cancelled\"\n\nclass TaskPriority(Enum):\n    LOW = 1\n    MEDIUM = 2\n    HIGH = 3\n    CRITICAL = 4\n\n@dataclass\nclass Task:\n    id: str\n    payload: Any\n    priority: TaskPriority\n    status: TaskStatus\n    created_at: datetime\n    updated_at: datetime\n    started_at: Optional[datetime] = None\n    completed_at: Optional[datetime] = None\n    error_message: Optional[str] = None\n    retry_count: int = 0\n    max_retries: int = 3\n    sequence: int = 0\n    worker_id: Optional[str] = None\n    retry_policy: Optional[Dict[str, Any]] = None\n    \n    def is_terminal(self) -> bool:\n        \"\"\"Check if task is in a terminal state\"\"\"\n        return self.status in {TaskStatus.COMPLETED, TaskStatus.FAILED, \n                               TaskStatus.CANCELLED}\n    \n    def age_seconds(self) -> float:\n        \"\"\"Get task age in seconds\"\"\"\n        return (datetime.utcnow() - self.created_at).total_seconds()\n    \n    def time_in_progress_seconds(self) -> Optional[float]:\n        \"\"\"Get time spent in progress (None if not started)\"\"\"\n        if not self.started_at:\n            return None\n        end_time = self.completed_at or datetime.utcnow()\n        return (end_time - self.started_at).total_seconds()\n    \n    def time_since_completion_seconds(self) -> Optional[float]:\n        \"\"\"Get time since task entered terminal state (for cleanup logic)\"\"\"\n        if not self.completed_at:\n            return None\n        return (datetime.utcnow() - self.completed_at).total_seconds()\n```\n\n### 2. Cleanup Configuration\n```python\n@dataclass\nclass CleanupPolicy:\n    \"\"\"Fine-grained control over task retention\"\"\"\n    # Per-status retention policies (None = keep forever)\n    completed_retention_seconds: Optional[int] = 3600  # 1 hour\n    failed_retention_seconds: Optional[int] = 7200     # 2 hours (keep failures longer)\n    cancelled_retention_seconds: Optional[int] = 1800  # 30 minutes\n    \n    # Cleanup execution settings\n    cleanup_interval_seconds: int = 300  # 5 minutes\n    max_tasks_per_cleanup: int = 1000    # Rate limit cleanup to avoid blocking\n    \n    # Safety limits\n    min_terminal_tasks_before_cleanup: int = 100  # Don't cleanup if < 100 terminal tasks\n    \n    def get_retention_for_status(self, status: TaskStatus) -> Optional[int]:\n        \"\"\"Get retention seconds for a given status (None = keep forever)\"\"\"\n        if status == TaskStatus.COMPLETED:\n            return self.completed_retention_seconds\n        elif status == TaskStatus.FAILED:\n            return self.failed_retention_seconds\n        elif status == TaskStatus.CANCELLED:\n            return self.cancelled_retention_seconds\n        return None  # PENDING and IN_PROGRESS never cleaned by age\n\n@dataclass\nclass HeapRebuildPolicy:\n    \"\"\"Control when heap rebuilding occurs\"\"\"\n    min_efficiency: float = 0.5        # Rebuild when efficiency drops below 50%\n    min_total_entries: int = 100        # Only rebuild if heap has 100+ entries\n    max_rebuild_interval_seconds: int = 3600  # Force rebuild every hour regardless\n    \n    def should_rebuild(self, health: 'HeapHealth') -> bool:\n        \"\"\"Determine if heap should be rebuilt\"\"\"\n        # Efficiency-based rebuild\n        if (health.efficiency < self.min_efficiency and \n            health.total_entries >= self.min_total_entries):\n            return True\n        \n        # Time-based forced rebuild\n        time_since_rebuild = (datetime.utcnow() - health.last_rebuild).total_seconds()\n        if time_since_rebuild >= self.max_rebuild_interval_seconds:\n            return True\n        \n        return False\n\n@dataclass\nclass HeapHealth:\n    \"\"\"Track heap efficiency for automatic maintenance\"\"\"\n    total_entries: int = 0\n    valid_entries: int = 0\n    invalid_entries: int = 0\n    last_rebuild: datetime = field(default_factory=datetime.utcnow)\n    rebuild_count: int = 0\n    \n    @property\n    def efficiency(self) -> float:\n        \"\"\"Percentage of valid entries in heap\"\"\"\n        if self.total_entries == 0:\n            return 1.0\n        return self.valid_entries / self.total_entries\n```\n\n### 3. Priority Queue Storage with Smart Cleanup\n```python\nimport heapq\nimport threading\nfrom collections import defaultdict\nfrom typing import Set, Optional, Tuple, Dict, List\n\nclass PriorityTaskQueue:\n    def __init__(self, \n                 max_queue_size: Optional[int] = None,\n                 cleanup_policy: Optional[CleanupPolicy] = None,\n                 heap_rebuild_policy: Optional[HeapRebuildPolicy] = None):\n        \"\"\"\n        Args:\n            max_queue_size: Max pending tasks (None = unlimited)\n            cleanup_policy: Task retention and cleanup settings\n            heap_rebuild_policy: Heap maintenance thresholds\n        \"\"\"\n        self._lock = threading.RLock()\n        self._heap: List[Tuple[int, int, str]] = []\n        self._tasks: Dict[str, Task] = {}\n        self._heap_task_ids: Set[str] = set()\n        self._counter = 0\n        self._max_queue_size = max_queue_size\n        \n        self._cleanup_policy = cleanup_policy or CleanupPolicy()\n        self._heap_policy = heap_rebuild_policy or HeapRebuildPolicy()\n        \n        self._last_cleanup = datetime.utcnow()\n        self._heap_health = HeapHealth()\n        \n        # Metrics tracking\n        self._metrics = {\n            'total_enqueued': 0,\n            'total_dequeued': 0,\n            'total_completed': 0,\n            'total_failed': 0,\n            'total_cancelled': 0,\n            'total_retried': 0,\n            'total_cleaned': 0,\n            'cleanup_runs': 0,\n            'heap_rebuilds': 0,\n        }\n    \n    def enqueue(self, payload: Any, priority: TaskPriority = TaskPriority.MEDIUM,\n                max_retries: int = 3, retry_policy: Optional[Dict] = None) -> str:\n        \"\"\"Add task to queue, return task ID\"\"\"\n        with self._lock:\n            # Run cleanup opportunistically\n            self._maybe_cleanup()\n            \n            # Check queue size limit (only count PENDING)\n            pending_count = sum(1 for t in self._tasks.values() \n                              if t.status == TaskStatus.PENDING)\n            if self._max_queue_size and pending_count >= self._max_queue_size:\n                raise QueueFullError(f\"Queue at capacity: {self._max_queue_size}\")\n            \n            task = Task(\n                id=str(uuid.uuid4()),\n                payload=payload,\n                priority=priority,\n                status=TaskStatus.PENDING,\n                created_at=datetime.utcnow(),\n                updated_at=datetime.utcnow(),\n                max_retries=max_retries,\n                sequence=self._counter,\n                retry_policy=retry_policy\n            )\n            self._tasks[task.id] = task\n            self._add_to_heap(task)\n            self._metrics['total_enqueued'] += 1\n            return task.id\n    \n    def _add_to_heap(self, task: Task):\n        \"\"\"Add task to heap with health tracking\"\"\"\n        heapq.heappush(self._heap, (-task.priority.value, task.sequence, task.id))\n        self._heap_task_ids.add(task.id)\n        self._counter += 1\n        self._heap_health.total_entries += 1\n        self._heap_health.valid_entries += 1\n    \n    def dequeue(self, worker_id: Optional[str] = None) -> Optional[Task]:\n        \"\"\"Get highest priority pending task\"\"\"\n        with self._lock:\n            self._maybe_cleanup()\n            \n            while self._heap:\n                _, _, task_id = heapq.heappop(self._heap)\n                self._heap_task_ids.discard(task_id)\n                self._heap_health.total_entries -= 1\n                \n                task = self._tasks.get(task_id)\n                \n                if not task or task.status != TaskStatus.PENDING:\n                    # Invalid entry, mark and continue searching\n                    self._heap_health.invalid_entries += 1\n                    continue\n                \n                # Found valid task\n                self._heap_health.valid_entries -= 1\n                task.status = TaskStatus.IN_PROGRESS\n                task.started_at = datetime.utcnow()\n                task.updated_at = datetime.utcnow()\n                task.worker_id = worker_id\n                self._metrics['total_dequeued'] += 1\n                \n                # Check if heap needs rebuilding\n                if self._heap_policy.should_rebuild(self._heap_health):\n                    self._rebuild_heap()\n                \n                return task\n            \n            # Heap exhausted - rebuild if we have invalid entries\n            if self._heap_health.invalid_entries > 0:\n                self._rebuild_heap()\n            \n            return None\n    \n    def _rebuild_heap(self):\n        \"\"\"Rebuild heap with only valid pending tasks\"\"\"\n        with self._lock:\n            valid_tasks = [t for t in self._tasks.values() \n                          if t.status == TaskStatus.PENDING]\n            \n            self._heap.clear()\n            self._heap_task_ids.clear()\n            \n            for task in valid_tasks:\n                heapq.heappush(self._heap, \n                             (-task.priority.value, task.sequence, task.id))\n                self._heap_task_ids.add(task.id)\n            \n            self._heap_health = HeapHealth(\n                total_entries=len(self._heap),\n                valid_entries=len(self._heap),\n                invalid_entries=0,\n                last_rebuild=datetime.utcnow(),\n                rebuild_count=self._heap_health.rebuild_count + 1\n            )\n            self._metrics['heap_rebuilds'] += 1\n    \n    def _maybe_cleanup(self):\n        \"\"\"Run cleanup if enough time has passed\"\"\"\n        now = datetime.utcnow()\n        interval = timedelta(seconds=self._cleanup_policy.cleanup_interval_seconds)\n        \n        if now - self._last_cleanup > interval:\n            self._cleanup_old_tasks()\n            self._last_cleanup = now\n    \n    def _cleanup_old_tasks(self):\n        \"\"\"Remove old terminal tasks based on per-status retention policies\"\"\"\n        with self._lock:\n            now = datetime.utcnow()\n            \n            # Count terminal tasks to check safety threshold\n            terminal_count = sum(1 for t in self._tasks.values() if t.is_terminal())\n            \n            if terminal_count < self._cleanup_policy.min_terminal_tasks_before_cleanup:\n                return  # Not enough tasks to warrant cleanup\n            \n            to_delete = []\n            \n            for task_id, task in self._tasks.items():\n                if not task.is_terminal():\n                    continue\n                \n                # Get retention policy for this task's status\n                retention_seconds = self._cleanup_policy.get_retention_for_status(task.status)\n                \n                if retention_seconds is None:\n                    continue  # This status is kept forever\n                \n                # Check if task has exceeded retention period\n                time_since_completion = task.time_since_completion_seconds()\n                if time_since_completion and time_since_completion >= retention_seconds:\n                    to_delete.append(task_id)\n                \n                # Rate limit cleanup to avoid blocking\n                if len(to_delete) >= self._cleanup_policy.max_tasks_per_cleanup:\n                    break\n            \n            # Perform deletion\n            for task_id in to_delete:\n                del self._tasks[task_id]\n                self._metrics['total_cleaned'] += 1\n            \n            self._metrics['cleanup_runs'] += 1\n    \n    def get_task(self, task_id: str) -> Optional[Task]:\n        \"\"\"Retrieve task by ID (returns copy for safety)\"\"\"\n        with self._lock:\n            task = self._tasks.get(task_id)\n            return task  # In production, consider returning a copy for safety\n    \n    def update_status(self, task_id: str, status: TaskStatus, \n                     error_message: Optional[str] = None) -> Tuple[bool, bool]:\n        \"\"\"\n        Update task status with state validation.\n        Returns: (success, was_retried)\n        \"\"\"\n        with self._lock:\n            task = self._tasks.get(task_id)\n            if not task:\n                raise TaskNotFoundError(f\"Task {task_id} not found\")\n            \n            if not self._is_valid_transition(task.status, status):\n                raise InvalidStateTransitionError(\n                    f\"Cannot transition from {task.status.value} to {status.value}\"\n                )\n            \n            old_status = task.status\n            task.status = status\n            task.updated_at = datetime.utcnow()\n            \n            if status == TaskStatus.COMPLETED:\n                task.completed_at = datetime.utcnow()\n                self._metrics['total_completed'] += 1\n                return (True, False)\n            \n            elif status == TaskStatus.FAILED:\n                task.error_message = error_message\n                task.completed_at = datetime.utcnow()\n                task.retry_count += 1\n                \n                # Check if should retry (automatic based on max_retries)\n                if task.retry_count < task.max_retries:\n                    # Reset for retry\n                    task.status = TaskStatus.PENDING\n                    task.started_at = None\n                    task.completed_at = None\n                    task.worker_id = None\n                    \n                    # Add back to heap if not already present\n                    if task_id not in self._heap_task_ids:\n                        self._add_to_heap(task)\n                    \n                    self._metrics['total_retried'] += 1\n                    return (True, True)\n                \n                # Exhausted retries - stays FAILED\n                self._metrics['total_failed'] += 1\n                return (True, False)\n            \n            elif status == TaskStatus.CANCELLED:\n                task.completed_at = datetime.utcnow()\n                self._metrics['total_cancelled'] += 1\n                return (True, False)\n            \n            return (True, False)\n    \n    def _is_valid_transition(self, from_status: TaskStatus, \n                            to_status: TaskStatus) -> bool:\n        \"\"\"Validate state machine transitions\"\"\"\n        valid_transitions = {\n            TaskStatus.PENDING: {TaskStatus.IN_PROGRESS, TaskStatus.CANCELLED},\n            TaskStatus.IN_PROGRESS: {TaskStatus.COMPLETED, TaskStatus.FAILED, \n                                    TaskStatus.CANCELLED},\n            TaskStatus.FAILED: set(),\n            TaskStatus.COMPLETED: set(),\n            TaskStatus.CANCELLED: set(),\n        }\n        return to_status in valid_transitions.get(from_status, set())\n    \n    def cancel_task(self, task_id: str) -> bool:\n        \"\"\"Cancel a pending task\"\"\"\n        with self._lock:\n            task = self._tasks.get(task_id)\n            if not task:\n                return False\n            if task.status == TaskStatus.PENDING:\n                try:\n                    self.update_status(task_id, TaskStatus.CANCELLED)\n                    return True\n                except (TaskNotFoundError, InvalidStateTransitionError):\n                    return False\n            return False\n    \n    def requeue_task(self, task_id: str, reset_retries: bool = False) -> bool:\n        \"\"\"\n        Manually requeue a task (for worker failures or manual retry).\n        Only works for IN_PROGRESS tasks.\n        \"\"\"\n        with self._lock:\n            task = self._tasks.get(task_id)\n            if not task or task.status != TaskStatus.IN_PROGRESS:\n                return False\n            \n            task.status = TaskStatus.PENDING\n            task.started_at = None\n            task.worker_id = None\n            task.updated_at = datetime.utcnow()\n            \n            if reset_retries:\n                task.retry_count = 0\n                task.error_message = None\n            \n            if task_id not in self._heap_task_ids:\n                self._add_to_heap(task)\n            \n            return True\n    \n    def get_queue_stats(self) -> dict:\n        \"\"\"Get comprehensive queue statistics\"\"\"\n        with self._lock:\n            status_counts = defaultdict(int)\n            priority_counts = defaultdict(int)\n            \n            for task in self._tasks.values():\n                status_counts[task.status.value] += 1\n                if task.status == TaskStatus.PENDING:\n                    priority_counts[task.priority.name] += 1\n            \n            return {\n                \"total_tasks\": len(self._tasks),\n                \"pending\": status_counts[TaskStatus.PENDING.value],\n                \"in_progress\": status_counts[TaskStatus.IN_PROGRESS.value],\n                \"completed\": status_counts[TaskStatus.COMPLETED.value],\n                \"failed\": status_counts[TaskStatus.FAILED.value],\n                \"cancelled\": status_counts[TaskStatus.CANCELLED.value],\n                \"pending_by_priority\": dict(priority_counts),\n                \"heap_size\": len(self._heap),\n                \"heap_efficiency\": self._heap_health.efficiency,\n                \"heap_invalid_entries\": self._heap_health.invalid_entries,\n                \"last_cleanup\": self._last_cleanup.isoformat(),\n                \"last_heap_rebuild\": self._heap_health.last_rebuild.isoformat(),\n                \"lifetime_metrics\": dict(self._metrics)\n            }\n    \n    def force_cleanup(self, cleanup_all_terminal: bool = False) -> dict:\n        \"\"\"\n        Manually trigger cleanup and return results.\n        \n        Args:\n            cleanup_all_terminal: If True, remove ALL terminal tasks regardless of age\n        \"\"\"\n        with self._lock:\n            before_count = len(self._tasks)\n            \n            if cleanup_all_terminal:\n                # Emergency cleanup - remove all terminal tasks\n                to_delete = [tid for tid, task in self._tasks.items() \n                           if task.is_terminal()]\n                for task_id in to_delete:\n                    del self._tasks[task_id]\n            else:\n                # Normal cleanup respecting retention policies\n                self._cleanup_old_tasks()\n            \n            after_count = len(self._tasks)\n            \n            before_heap = len(self._heap)\n            self._rebuild_heap()\n            after_heap = len(self._heap)\n            \n            return {\n                \"tasks_removed\": before_count - after_count,\n                \"heap_entries_removed\": before_heap - after_heap,\n                \"tasks_remaining\": after_count,\n                \"heap_size\": after_heap,\n                \"heap_efficiency\": self._heap_health.efficiency,\n                \"all_terminal_cleaned\": cleanup_all_terminal\n            }\n\n# Custom exceptions\nclass QueueFullError(Exception):\n    pass\n\nclass TaskNotFoundError(Exception):\n    pass\n\nclass InvalidStateTransitionError(Exception):\n    pass\n```\n\n### 4. Task Queue Manager Interface\n```python\nclass TaskQueueManager:\n    \"\"\"High-level interface for task queue operations\"\"\"\n    \n    def __init__(self, \n                 max_queue_size: Optional[int] = None,\n                 cleanup_policy: Optional[CleanupPolicy] = None,\n                 heap_rebuild_policy: Optional[HeapRebuildPolicy] = None):\n        \"\"\"\n        Args:\n            max_queue_size: Max pending tasks (None = unlimited)\n            cleanup_policy: Task retention and cleanup configuration\n            heap_rebuild_policy: Heap maintenance thresholds\n        \"\"\"\n        self.queue = PriorityTaskQueue(\n            max_queue_size=max_queue_size,\n            cleanup_policy=cleanup_policy,\n            heap_rebuild_policy=heap_rebuild_policy\n        )\n    \n    def submit_task(self, \n                   payload: Any, \n                   priority: str = \"medium\",\n                   max_retries: int = 3,\n                   retry_policy: Optional[Dict] = None) -> dict:\n        \"\"\"\n        Submit a new task.\n        \n        Args:\n            payload: Task data\n            priority: \"low\", \"medium\", \"high\", or \"critical\"\n            max_retries: Max automatic retries (0 = no retry)\n            retry_policy: Optional metadata for worker-side retry logic\n        \"\"\"\n        try:\n            priority_enum = TaskPriority[priority.upper()]\n        except KeyError:\n            raise ValueError(f\"Invalid priority: {priority}. \"\n                           f\"Valid: {[p.name.lower() for p in TaskPriority]}\")\n        \n        if max_retries < 0:\n            raise ValueError(\"max_retries must be non-negative\")\n        \n        try:\n            task_id = self.queue.enqueue(payload, priority_enum, max_retries, \n                                        retry_policy)\n            return {\n                \"task_id\": task_id, \n                \"status\": \"pending\",\n                \"priority\": priority\n            }\n        except QueueFullError as e:\n            return {\"error\": str(e), \"status\": \"rejected\"}\n    \n    def get_next_task(self, worker_id: Optional[str] = None) -> Optional[dict]:\n        \"\"\"\n        Worker polls for next task.\n        Returns None if queue is empty.\n        \"\"\"\n        task = self.queue.dequeue(worker_id=worker_id)\n        if task:\n            return {\n                \"task_id\": task.id,\n                \"payload\": task.payload,\n                \"priority\": task.priority.name,\n                \"retry_count\": task.retry_count,\n                \"max_retries\": task.max_retries,\n                \"retry_policy\": task.retry_policy\n            }\n        return None\n    \n    def complete_task(self, task_id: str, success: bool = True, \n                     error: Optional[str] = None) -> dict:\n        \"\"\"\n        Mark task as completed or failed.\n        Automatic retry happens based on max_retries.\n        \"\"\"\n        try:\n            status = TaskStatus.COMPLETED if success else TaskStatus.FAILED\n            success_flag, was_retried = self.queue.update_status(\n                task_id, status, error\n            )\n            \n            return {\n                \"task_id\": task_id,\n                \"status\": status.value if not was_retried else \"retrying\",\n                \"retried\": was_retried\n            }\n        except (TaskNotFoundError, InvalidStateTransitionError) as e:\n            return {\"error\": str(e)}\n    \n    def get_task_status(self, task_id: str) -> Optional[dict]:\n        \"\"\"Get detailed task status\"\"\"\n        task = self.queue.get_task(task_id)\n        if not task:\n            return None\n        \n        return {\n            \"task_id\": task.id,\n            \"status\": task.status.value,\n            \"priority\": task.priority.name,\n            \"created_at\": task.created_at.isoformat(),\n            \"started_at\": task.started_at.isoformat() if task.started_at else None,\n            \"completed_at\": task.completed_at.isoformat() if task.completed_at else None,\n            \"error_message\": task.error_message,\n            \"retry_count\": task.retry_count,\n            \"max_retries\": task.max_retries,\n            \"worker_id\": task.worker_id,\n            \"age_seconds\": task.age_seconds(),\n            \"time_in_progress\": task.time_in_progress_seconds()\n        }\n    \n    def cancel_task(self, task_id: str) -> dict:\n        \"\"\"Cancel a pending task\"\"\"\n        success = self.queue.cancel_task(task_id)\n        return {\n            \"task_id\": task_id,\n            \"cancelled\": success,\n            \"message\": \"Task cancelled\" if success \n                      else \"Task not pending or not found\"\n        }\n    \n    def requeue_task(self, task_id: str, reset_retries: bool = False) -> dict:\n        \"\"\"\n        Manually requeue an in-progress task.\n        Useful for worker failure recovery.\n        \"\"\"\n        success = self.queue.requeue_task(task_id, reset_retries)\n        return {\n            \"task_id\": task_id,\n            \"requeued\": success,\n            \"reset_retries\": reset_retries,\n            \"message\": \"Task requeued\" if success \n                      else \"Task not in-progress or not found\"\n        }\n    \n    def get_statistics(self) -> dict:\n        \"\"\"Get comprehensive queue statistics\"\"\"\n        return self.queue.get_queue_stats()\n    \n    def force_maintenance(self, emergency: bool = False) -> dict:\n        \"\"\"\n        Manually trigger cleanup and heap rebuild.\n        \n        Args:\n            emergency: If True, removes ALL terminal tasks regardless of retention policy\n        \"\"\"\n        return self.queue.force_cleanup(cleanup_all_terminal=emergency)\n```\n\n### 5. Health Monitor & Supervisor Utilities\n```python\nfrom typing import List\n\nclass TaskSupervisor:\n    \"\"\"Monitor and recover stuck tasks\"\"\"\n    \n    def __init__(self, manager: TaskQueueManager, \n                 stuck_threshold_seconds: int = 300):\n        self.manager = manager\n        self.stuck_threshold = stuck_threshold_seconds\n    \n    def check_stuck_tasks(self) -> List[dict]:\n        \"\"\"Find tasks stuck in IN_PROGRESS state\"\"\"\n        with self.manager.queue._lock:\n            stuck_tasks = []\n            now = datetime.utcnow()\n            \n            for task in self.manager.queue._tasks.values():\n                if task.status != TaskStatus.IN_PROGRESS:\n                    continue\n                \n                time_in_progress = task.time_in_progress_seconds()\n                if time_in_progress and time_in_progress >= self.stuck_threshold:\n                    stuck_tasks.append({\n                        'task_id': task.id,\n                        'worker_id': task.worker_id,\n                        'priority': task.priority.name,\n                        'time_in_progress': time_in_progress,\n                        'started_at': task.started_at.isoformat()\n                    })\n            \n            return stuck_tasks\n    \n    def requeue_stuck_tasks(self, reset_retries: bool = False) -> dict:\n        \"\"\"Automatically requeue stuck tasks\"\"\"\n        stuck = self.check_stuck_tasks()\n        requeued = []\n        failed = []\n        \n        for task_info in stuck:\n            result = self.manager.requeue_task(\n                task_info['task_id'], \n                reset_retries=reset_retries\n            )\n            if result['requeued']:\n                requeued.append(task_info['task_id'])\n            else:\n                failed.append(task_info['task_id'])\n        \n        return {\n            \"stuck_tasks_found\": len(stuck),\n            \"tasks_requeued\": len(requeued),\n            \"tasks_failed_to_requeue\": len(failed),\n            \"requeued_task_ids\": requeued,\n            \"failed_task_ids\": failed\n        }\n```\n\n## Usage Examples\n\n### Basic Configuration\n```python\n# Simple setup with defaults\nmanager = TaskQueueManager(\n    max_queue_size=10000\n)\n\n# Advanced setup with custom policies\ncleanup_policy = CleanupPolicy(\n    completed_retention_seconds=3600,    # Keep completed 1hr\n    failed_retention_seconds=7200,       # Keep failed 2hr\n    cancelled_retention_seconds=1800,    # Keep cancelled 30min\n    cleanup_interval_seconds=300,        # Cleanup every 5min\n    max_tasks_per_cleanup=1000,          # Rate limit\n    min_terminal_tasks_before_cleanup=50 # Safety threshold\n)\n\nheap_policy = HeapRebuildPolicy(\n    min_efficiency=0.5,\n    min_total_entries=100,\n    max_rebuild_interval_seconds=3600\n)\n\nmanager = TaskQueueManager(\n    max_queue_size=10000,\n    cleanup_policy=cleanup_policy,\n    heap_rebuild_policy=heap_policy\n)\n```\n\n### Worker with Automatic Retry\n```python\n# Worker with automatic retry handling\nworker_id = \"worker-1\"\n\nwhile True:\n    task = manager.get_next_task(worker_id=worker_id)\n    \n    if task:\n        try:\n            result = process_task(task['payload'])\n            manager.complete_task(task['task_id'], success=True)\n        except Exception as e:\n            # Queue handles retry automatically based on max_retries\n            response = manager.complete_task(\n                task['task_id'], \n                success=False, \n                error=str(e)\n            )\n            \n            if response.get('retried'):\n                logger.info(f\"Task {task['task_id']} will be retried\")\n            else:\n                logger.error(f\"Task {task['task_id']} failed permanently\")\n    else:\n        time.sleep(1)\n```\n\n### Worker with Smart Retry Policy\n```python\nimport time\n\ndef smart_worker():\n    \"\"\"Worker that respects retry_policy metadata\"\"\"\n    worker_id = \"smart-worker-1\"\n    \n    while True:\n        task = manager.get_next_task(worker_id=worker_id)\n        \n        if not task:\n            time.sleep(1)\n            continue\n        \n        # Extract retry policy hints\n        retry_policy = task.get('retry_policy') or {}\n        retry_count = task['retry_count']\n        \n        try:\n            result = call_external_api(task['payload'])\n            manager.complete_task(task['task_id'], success=True)\n            \n        except RateLimitError as e:\n            # Use exponential backoff for rate limits\n            manager.complete_task(task['task_id'], success=False, error=str(e))\n            \n            if retry_policy.get('backoff') == 'exponential':\n                base_delay = retry_policy.get('base_delay', 2)\n                max_delay = retry_policy.get('max_delay', 60)\n                delay = min(base_delay ** retry_count, max_delay)\n                time.sleep(delay)\n        \n        except PermanentError as e:\n            # Some errors shouldn't be retried - mark failed\n            manager.complete_task(task['task_id'], success=False, error=str(e))\n```\n\n### Monitoring & Maintenance\n```python\n# Get comprehensive statistics\nstats = manager.get_statistics()\n\nprint(f\"Queue Health:\")\nprint(f\"  Pending: {stats['pending']}\")\nprint(f\"  In Progress: {stats['in_progress']}\")\nprint(f\"  Heap Efficiency: {stats['heap_efficiency']:.2%}\")\nprint(f\"  Invalid Heap Entries: {stats['heap_invalid_entries']}\")\n\nprint(f\"\\nLifetime Metrics:\")\nmetrics = stats['lifetime_metrics']\nprint(f\"  Total Enqueued: {metrics['total_enqueued']}\")\nprint(f\"  Total Completed: {metrics['total_completed']}\")\nprint(f\"  Total Failed: {metrics['total_failed']}\")\nprint(f\"  Total Retried: {metrics['total_retried']}\")\nprint(f\"  Total Cleaned: {metrics['total_cleaned']}\")\nprint(f\"  Cleanup Runs: {metrics['cleanup_runs']}\")\nprint(f\"  Heap Rebuilds: {metrics['heap_rebuilds']}\")\n\n# Normal maintenance\nif stats['heap_efficiency'] < 0.3:\n    result = manager.force_maintenance()\n    print(f\"Cleaned {result['tasks_removed']} tasks, \"\n          f\"removed {result['heap_entries_removed']} stale heap entries\")\n\n# Emergency cleanup (remove ALL terminal tasks)\nif stats['total_tasks'] > 1_000_000:\n    result = manager.force_maintenance(emergency=True)\n    print(f\"Emergency cleanup: removed {result['tasks_removed']} terminal tasks\")\n```\n\n### Supervisor for Stuck Task Recovery\n```python\n# Run supervisor periodically (e.g., every minute)\nsupervisor = TaskSupervisor(manager, stuck_threshold_seconds=300)\n\n# Check for stuck tasks\nstuck_tasks = supervisor.check_stuck_tasks()\nif stuck_tasks:\n    print(f\"Found {len(stuck_tasks)} stuck tasks:\")\n    for task in stuck_tasks:\n        print(f\"  {task['task_id']}: stuck for {task['time_in_progress']:.0f}s \"\n              f\"on worker {task['worker_id']}\")\n\n# Automatically recover stuck tasks\nrecovery = supervisor.requeue_stuck_tasks(reset_retries=False)\nprint(f\"Requeued {recovery['tasks_requeued']} stuck tasks\")\nif recovery['failed_task_ids']:\n    print(f\"Failed to requeue: {recovery['failed_task_ids']}\")\n```\n\n### Custom Retention Policy for Audit Requirements\n```python\n# Keep completed tasks for 7 days for audit, failed for 30 days\naudit_policy = CleanupPolicy(\n    completed_retention_seconds=7 * 24 * 3600,   # 7 days\n    failed_retention_seconds=30 * 24 * 3600,     # 30 days\n    cancelled_retention_seconds=24 * 3600,       # 1 day\n    cleanup_interval_seconds=3600,               # Hourly cleanup\n    max_tasks_per_cleanup=5000,\n    min_terminal_tasks_before_cleanup=1000\n)\n\nmanager = TaskQueueManager(\n    max_queue_size=50000,\n    cleanup_policy=audit_policy\n)\n```\n\n## What I Improved\n\n### 1. **Configurable Cleanup Thresholds**\n- Added `CleanupPolicy` dataclass with per-status retention\n- Failed tasks kept longer than completed (2hr vs 1hr) - failures need investigation\n- Rate-limited cleanup (`max_tasks_per_cleanup`) to prevent blocking\n- Safety threshold (`min_terminal_tasks_before_cleanup`) prevents wasteful cleanup\n- **Why**: Different task types have different retention needs; one-size-fits-all is insufficient\n\n### 2. **Configurable Heap Rebuild Policy**\n- Added `HeapRebuildPolicy` with efficiency threshold, size threshold, and max interval\n- Force rebuild every hour even if efficiency is good (prevents edge cases)\n- Made thresholds explicit and tunable rather than magic numbers\n- **Why**: Different workloads need different rebuild strategies; expose control\n\n### 3. **Per-Status Retention Policies**\n- `completed_retention_seconds`, `failed_retention_seconds`, `cancelled_retention_seconds`\n- Each status can have different TTL (or None to keep forever)\n- `get_retention_for_status()` encapsulates lookup logic\n- **Why**: Audit requirements often mandate longer failed task retention; completed tasks can be purged faster\n\n### 4. **Enhanced Task Model**\n- Added `time_since_completion_seconds()` for cleanup logic\n- Separates \"task age\" from \"terminal state age\" - critical for retention\n- **Why**: Cleanup should be based on when task *completed*, not when it was created\n\n### 5. **Comprehensive Metrics Tracking**\n- Lifetime counters: enqueued, dequeued, completed, failed, cancelled, retried, cleaned\n- Cleanup runs and heap rebuilds tracked\n- `heap_invalid_entries` exposed in stats\n- **Why**: Production systems need visibility into system behavior over time\n\n### 6. **Safe Concurrent Cleanup**\n- Rate-limited deletion prevents long lock holds\n- `max_tasks_per_cleanup` prevents cleanup from blocking workers\n- Safety check (`min_terminal_tasks_before_cleanup`) avoids overhead on small queues\n- **Why**: Cleanup shouldn't impact worker throughput\n\n### 7. **Emergency Maintenance Mode**\n- `force_maintenance(emergency=True)` removes ALL terminal tasks\n- Useful for memory pressure situations\n- Returns detailed metrics on what was cleaned\n- **Why**: Production systems need panic buttons\n\n### 8. **Enhanced Supervisor**\n- Returns detailed info on stuck tasks (worker_id, time stuck, etc.)\n- Separate failed/succeeded lists for requeue operations\n- Optional `reset_retries` flag for recovery scenarios\n- **Why**: Operators need actionable information, not just counts\n\n### 9. **Better Error Handling in complete_task**\n- Returns `status: \"retrying\"` when task is automatically retried\n- Distinguishes between \"failed and retrying\" vs \"failed permanently\"\n- **Why**: Workers should know if their failure triggered retry\n\n### 10. **Invalid Entry Tracking**\n- `heap_health.invalid_entries` incremented when skipping stale entries\n- Helps diagnose heap bloat issues\n- **Why**: Observability into lazy deletion behavior\n\n## What I Kept\n\n- **Simplified retry model**: Automatic retry based on `max_retries` is correct\n- **retry_policy as metadata**: Queue doesn't interpret it, just passes through - perfect separation\n- **Core heap architecture**: Efficient priority queue with lazy deletion\n- **RLock for thread safety**: Essential for concurrent workers\n- **State machine validation**: Prevents invalid transitions\n- **Worker ID tracking**: Critical for debugging stuck tasks\n- **Manual requeue**: Supervisor pattern requires this\n- **Sequence numbers**: FIFO within priority is important\n- **Task helper methods**: `is_terminal()`, `age_seconds()`, etc.\n\n## Remaining Concerns\n\n### 1. **Cleanup Lock Contention**\nThe opportunistic cleanup during `enqueue`/`dequeue` holds the lock while iterating tasks. For large task dictionaries (100k+ tasks), this could block workers.\n\n**Options**:\n- Move cleanup to background thread\n- Use lazy deletion for terminal tasks too (track separately)\n- Add write-ahead log for cleanup candidates\n\n### 2. **Memory Overhead of Metrics**\nLifetime metrics grow unbounded. In a system running for months, these counters could overflow.\n\n**Options**:\n- Use prometheus-style metrics (external aggregation)\n- Reset metrics periodically\n- Use sliding windows instead of lifetime counts\n\n### 3. **No Index for IN_PROGRESS Tasks**\nSupervisor has to iterate all tasks to find stuck ones. This is O(n) on total tasks.\n\n**Options**:\n- Maintain separate `_in_progress_tasks` dict\n- Index by worker_id for targeted lookups\n- Track task start times in a separate min-heap for efficient \"oldest in-progress\" queries\n\n### 4. **Copy vs Reference in get_task()**\nCurrently returns task reference, which allows external mutation. But making defensive copies has performance cost.\n\n**Options**:\n- Return immutable view object\n- Use frozen dataclass for external API\n- Document as internal-only and provide separate public API\n\n### 5. **No Circuit Breaker for Failed Tasks**\nIf a task type consistently fails (bad payload, external service down), it will retry indefinitely across queue restarts.\n\n**Options**:\n- Track failure patterns by payload type/signature\n- Implement backoff at queue level (delay before retry)\n- Add \"poison task\" detection (task fails X times = quarantine)\n\n## Convergence Status\n\n**ITERATING** - Design addresses the key concerns but needs validation on:\n\n1. Whether per-status retention meets your audit/compliance requirements\n2. If cleanup rate limiting (max_tasks_per_cleanup) is sufficient for your scale\n3. Trade-offs between cleanup overhead and memory bounds under high load\n4. Whether locked cleanup is acceptable or background thread is needed\n\n## Prompt for Collaborator",
        "prompt_for_other": "I've added per-status retention policies, configurable cleanup/rebuild thresholds, comprehensive metrics, and safer concurrent cleanup. Key questions:\n\n1. **Cleanup lock contention**: Cleanup runs under the main lock and iterates all tasks. For a queue with 100k+ tasks, this could block workers during cleanup. Should we move cleanup to a background thread, or is rate-limiting (`max_tasks_per_cleanup=1000`) sufficient?\n\n2. **Per-status retention**: I kept failed tasks for 2x longer than completed (2hr vs 1hr) assuming failures need investigation. Does this match your use case? Should we support per-priority retention too (keep CRITICAL tasks longer)?\n\n3. **Heap rebuild policy**: I added `max_rebuild_interval_seconds` to force periodic rebuilds even if efficiency looks good. Is this paranoia, or does it prevent edge cases I'm not seeing?\n\n4. **IN_PROGRESS task indexing**: Supervisor iterates all tasks to find stuck ones (O(n)). Should we maintain a separate index of in-progress tasks for O(1) lookups, or is periodic O(n) scan acceptable?\n\n5. **Did I over-engineer cleanup?** Is per-status retention + rate limiting + safety thresholds too complex? Would a simpler \"keep terminal tasks for N hours\" suffice?",
        "convergence_signal": "ITERATING",
        "raw_response": "## Design\n\n# Priority Task Queue System with Bounded Memory, Configurable Policies & Comprehensive Monitoring\n\n## Architecture Overview\n\nA production-ready priority task queue system with in-memory storage, intelligent memory management, flexible cleanup policies, and enterprise-grade observability. Key improvements: configurable cleanup thresholds, per-status retention policies, safe concurrent cleanup, enhanced error recovery, and comprehensive metrics.\n\n## Core Components\n\n### 1. Task Model\n```python\nfrom enum import Enum\nfrom dataclasses import dataclass, field\nfrom typing import Optional, Any, Dict\nfrom datetime import datetime, timedelta\nimport uuid\n\nclass TaskStatus(Enum):\n    PENDING = \"pending\"\n    IN_PROGRESS = \"in_progress\"\n    COMPLETED = \"completed\"\n    FAILED = \"failed\"\n    CANCELLED = \"cancelled\"\n\nclass TaskPriority(Enum):\n    LOW = 1\n    MEDIUM = 2\n    HIGH = 3\n    CRITICAL = 4\n\n@dataclass\nclass Task:\n    id: str\n    payload: Any\n    priority: TaskPriority\n    status: TaskStatus\n    created_at: datetime\n    updated_at: datetime\n    started_at: Optional[datetime] = None\n    completed_at: Optional[datetime] = None\n    error_message: Optional[str] = None\n    retry_count: int = 0\n    max_retries: int = 3\n    sequence: int = 0\n    worker_id: Optional[str] = None\n    retry_policy: Optional[Dict[str, Any]] = None\n    \n    def is_terminal(self) -> bool:\n        \"\"\"Check if task is in a terminal state\"\"\"\n        return self.status in {TaskStatus.COMPLETED, TaskStatus.FAILED, \n                               TaskStatus.CANCELLED}\n    \n    def age_seconds(self) -> float:\n        \"\"\"Get task age in seconds\"\"\"\n        return (datetime.utcnow() - self.created_at).total_seconds()\n    \n    def time_in_progress_seconds(self) -> Optional[float]:\n        \"\"\"Get time spent in progress (None if not started)\"\"\"\n        if not self.started_at:\n            return None\n        end_time = self.completed_at or datetime.utcnow()\n        return (end_time - self.started_at).total_seconds()\n    \n    def time_since_completion_seconds(self) -> Optional[float]:\n        \"\"\"Get time since task entered terminal state (for cleanup logic)\"\"\"\n        if not self.completed_at:\n            return None\n        return (datetime.utcnow() - self.completed_at).total_seconds()\n```\n\n### 2. Cleanup Configuration\n```python\n@dataclass\nclass CleanupPolicy:\n    \"\"\"Fine-grained control over task retention\"\"\"\n    # Per-status retention policies (None = keep forever)\n    completed_retention_seconds: Optional[int] = 3600  # 1 hour\n    failed_retention_seconds: Optional[int] = 7200     # 2 hours (keep failures longer)\n    cancelled_retention_seconds: Optional[int] = 1800  # 30 minutes\n    \n    # Cleanup execution settings\n    cleanup_interval_seconds: int = 300  # 5 minutes\n    max_tasks_per_cleanup: int = 1000    # Rate limit cleanup to avoid blocking\n    \n    # Safety limits\n    min_terminal_tasks_before_cleanup: int = 100  # Don't cleanup if < 100 terminal tasks\n    \n    def get_retention_for_status(self, status: TaskStatus) -> Optional[int]:\n        \"\"\"Get retention seconds for a given status (None = keep forever)\"\"\"\n        if status == TaskStatus.COMPLETED:\n            return self.completed_retention_seconds\n        elif status == TaskStatus.FAILED:\n            return self.failed_retention_seconds\n        elif status == TaskStatus.CANCELLED:\n            return self.cancelled_retention_seconds\n        return None  # PENDING and IN_PROGRESS never cleaned by age\n\n@dataclass\nclass HeapRebuildPolicy:\n    \"\"\"Control when heap rebuilding occurs\"\"\"\n    min_efficiency: float = 0.5        # Rebuild when efficiency drops below 50%\n    min_total_entries: int = 100        # Only rebuild if heap has 100+ entries\n    max_rebuild_interval_seconds: int = 3600  # Force rebuild every hour regardless\n    \n    def should_rebuild(self, health: 'HeapHealth') -> bool:\n        \"\"\"Determine if heap should be rebuilt\"\"\"\n        # Efficiency-based rebuild\n        if (health.efficiency < self.min_efficiency and \n            health.total_entries >= self.min_total_entries):\n            return True\n        \n        # Time-based forced rebuild\n        time_since_rebuild = (datetime.utcnow() - health.last_rebuild).total_seconds()\n        if time_since_rebuild >= self.max_rebuild_interval_seconds:\n            return True\n        \n        return False\n\n@dataclass\nclass HeapHealth:\n    \"\"\"Track heap efficiency for automatic maintenance\"\"\"\n    total_entries: int = 0\n    valid_entries: int = 0\n    invalid_entries: int = 0\n    last_rebuild: datetime = field(default_factory=datetime.utcnow)\n    rebuild_count: int = 0\n    \n    @property\n    def efficiency(self) -> float:\n        \"\"\"Percentage of valid entries in heap\"\"\"\n        if self.total_entries == 0:\n            return 1.0\n        return self.valid_entries / self.total_entries\n```\n\n### 3. Priority Queue Storage with Smart Cleanup\n```python\nimport heapq\nimport threading\nfrom collections import defaultdict\nfrom typing import Set, Optional, Tuple, Dict, List\n\nclass PriorityTaskQueue:\n    def __init__(self, \n                 max_queue_size: Optional[int] = None,\n                 cleanup_policy: Optional[CleanupPolicy] = None,\n                 heap_rebuild_policy: Optional[HeapRebuildPolicy] = None):\n        \"\"\"\n        Args:\n            max_queue_size: Max pending tasks (None = unlimited)\n            cleanup_policy: Task retention and cleanup settings\n            heap_rebuild_policy: Heap maintenance thresholds\n        \"\"\"\n        self._lock = threading.RLock()\n        self._heap: List[Tuple[int, int, str]] = []\n        self._tasks: Dict[str, Task] = {}\n        self._heap_task_ids: Set[str] = set()\n        self._counter = 0\n        self._max_queue_size = max_queue_size\n        \n        self._cleanup_policy = cleanup_policy or CleanupPolicy()\n        self._heap_policy = heap_rebuild_policy or HeapRebuildPolicy()\n        \n        self._last_cleanup = datetime.utcnow()\n        self._heap_health = HeapHealth()\n        \n        # Metrics tracking\n        self._metrics = {\n            'total_enqueued': 0,\n            'total_dequeued': 0,\n            'total_completed': 0,\n            'total_failed': 0,\n            'total_cancelled': 0,\n            'total_retried': 0,\n            'total_cleaned': 0,\n            'cleanup_runs': 0,\n            'heap_rebuilds': 0,\n        }\n    \n    def enqueue(self, payload: Any, priority: TaskPriority = TaskPriority.MEDIUM,\n                max_retries: int = 3, retry_policy: Optional[Dict] = None) -> str:\n        \"\"\"Add task to queue, return task ID\"\"\"\n        with self._lock:\n            # Run cleanup opportunistically\n            self._maybe_cleanup()\n            \n            # Check queue size limit (only count PENDING)\n            pending_count = sum(1 for t in self._tasks.values() \n                              if t.status == TaskStatus.PENDING)\n            if self._max_queue_size and pending_count >= self._max_queue_size:\n                raise QueueFullError(f\"Queue at capacity: {self._max_queue_size}\")\n            \n            task = Task(\n                id=str(uuid.uuid4()),\n                payload=payload,\n                priority=priority,\n                status=TaskStatus.PENDING,\n                created_at=datetime.utcnow(),\n                updated_at=datetime.utcnow(),\n                max_retries=max_retries,\n                sequence=self._counter,\n                retry_policy=retry_policy\n            )\n            self._tasks[task.id] = task\n            self._add_to_heap(task)\n            self._metrics['total_enqueued'] += 1\n            return task.id\n    \n    def _add_to_heap(self, task: Task):\n        \"\"\"Add task to heap with health tracking\"\"\"\n        heapq.heappush(self._heap, (-task.priority.value, task.sequence, task.id))\n        self._heap_task_ids.add(task.id)\n        self._counter += 1\n        self._heap_health.total_entries += 1\n        self._heap_health.valid_entries += 1\n    \n    def dequeue(self, worker_id: Optional[str] = None) -> Optional[Task]:\n        \"\"\"Get highest priority pending task\"\"\"\n        with self._lock:\n            self._maybe_cleanup()\n            \n            while self._heap:\n                _, _, task_id = heapq.heappop(self._heap)\n                self._heap_task_ids.discard(task_id)\n                self._heap_health.total_entries -= 1\n                \n                task = self._tasks.get(task_id)\n                \n                if not task or task.status != TaskStatus.PENDING:\n                    # Invalid entry, mark and continue searching\n                    self._heap_health.invalid_entries += 1\n                    continue\n                \n                # Found valid task\n                self._heap_health.valid_entries -= 1\n                task.status = TaskStatus.IN_PROGRESS\n                task.started_at = datetime.utcnow()\n                task.updated_at = datetime.utcnow()\n                task.worker_id = worker_id\n                self._metrics['total_dequeued'] += 1\n                \n                # Check if heap needs rebuilding\n                if self._heap_policy.should_rebuild(self._heap_health):\n                    self._rebuild_heap()\n                \n                return task\n            \n            # Heap exhausted - rebuild if we have invalid entries\n            if self._heap_health.invalid_entries > 0:\n                self._rebuild_heap()\n            \n            return None\n    \n    def _rebuild_heap(self):\n        \"\"\"Rebuild heap with only valid pending tasks\"\"\"\n        with self._lock:\n            valid_tasks = [t for t in self._tasks.values() \n                          if t.status == TaskStatus.PENDING]\n            \n            self._heap.clear()\n            self._heap_task_ids.clear()\n            \n            for task in valid_tasks:\n                heapq.heappush(self._heap, \n                             (-task.priority.value, task.sequence, task.id))\n                self._heap_task_ids.add(task.id)\n            \n            self._heap_health = HeapHealth(\n                total_entries=len(self._heap),\n                valid_entries=len(self._heap),\n                invalid_entries=0,\n                last_rebuild=datetime.utcnow(),\n                rebuild_count=self._heap_health.rebuild_count + 1\n            )\n            self._metrics['heap_rebuilds'] += 1\n    \n    def _maybe_cleanup(self):\n        \"\"\"Run cleanup if enough time has passed\"\"\"\n        now = datetime.utcnow()\n        interval = timedelta(seconds=self._cleanup_policy.cleanup_interval_seconds)\n        \n        if now - self._last_cleanup > interval:\n            self._cleanup_old_tasks()\n            self._last_cleanup = now\n    \n    def _cleanup_old_tasks(self):\n        \"\"\"Remove old terminal tasks based on per-status retention policies\"\"\"\n        with self._lock:\n            now = datetime.utcnow()\n            \n            # Count terminal tasks to check safety threshold\n            terminal_count = sum(1 for t in self._tasks.values() if t.is_terminal())\n            \n            if terminal_count < self._cleanup_policy.min_terminal_tasks_before_cleanup:\n                return  # Not enough tasks to warrant cleanup\n            \n            to_delete = []\n            \n            for task_id, task in self._tasks.items():\n                if not task.is_terminal():\n                    continue\n                \n                # Get retention policy for this task's status\n                retention_seconds = self._cleanup_policy.get_retention_for_status(task.status)\n                \n                if retention_seconds is None:\n                    continue  # This status is kept forever\n                \n                # Check if task has exceeded retention period\n                time_since_completion = task.time_since_completion_seconds()\n                if time_since_completion and time_since_completion >= retention_seconds:\n                    to_delete.append(task_id)\n                \n                # Rate limit cleanup to avoid blocking\n                if len(to_delete) >= self._cleanup_policy.max_tasks_per_cleanup:\n                    break\n            \n            # Perform deletion\n            for task_id in to_delete:\n                del self._tasks[task_id]\n                self._metrics['total_cleaned'] += 1\n            \n            self._metrics['cleanup_runs'] += 1\n    \n    def get_task(self, task_id: str) -> Optional[Task]:\n        \"\"\"Retrieve task by ID (returns copy for safety)\"\"\"\n        with self._lock:\n            task = self._tasks.get(task_id)\n            return task  # In production, consider returning a copy for safety\n    \n    def update_status(self, task_id: str, status: TaskStatus, \n                     error_message: Optional[str] = None) -> Tuple[bool, bool]:\n        \"\"\"\n        Update task status with state validation.\n        Returns: (success, was_retried)\n        \"\"\"\n        with self._lock:\n            task = self._tasks.get(task_id)\n            if not task:\n                raise TaskNotFoundError(f\"Task {task_id} not found\")\n            \n            if not self._is_valid_transition(task.status, status):\n                raise InvalidStateTransitionError(\n                    f\"Cannot transition from {task.status.value} to {status.value}\"\n                )\n            \n            old_status = task.status\n            task.status = status\n            task.updated_at = datetime.utcnow()\n            \n            if status == TaskStatus.COMPLETED:\n                task.completed_at = datetime.utcnow()\n                self._metrics['total_completed'] += 1\n                return (True, False)\n            \n            elif status == TaskStatus.FAILED:\n                task.error_message = error_message\n                task.completed_at = datetime.utcnow()\n                task.retry_count += 1\n                \n                # Check if should retry (automatic based on max_retries)\n                if task.retry_count < task.max_retries:\n                    # Reset for retry\n                    task.status = TaskStatus.PENDING\n                    task.started_at = None\n                    task.completed_at = None\n                    task.worker_id = None\n                    \n                    # Add back to heap if not already present\n                    if task_id not in self._heap_task_ids:\n                        self._add_to_heap(task)\n                    \n                    self._metrics['total_retried'] += 1\n                    return (True, True)\n                \n                # Exhausted retries - stays FAILED\n                self._metrics['total_failed'] += 1\n                return (True, False)\n            \n            elif status == TaskStatus.CANCELLED:\n                task.completed_at = datetime.utcnow()\n                self._metrics['total_cancelled'] += 1\n                return (True, False)\n            \n            return (True, False)\n    \n    def _is_valid_transition(self, from_status: TaskStatus, \n                            to_status: TaskStatus) -> bool:\n        \"\"\"Validate state machine transitions\"\"\"\n        valid_transitions = {\n            TaskStatus.PENDING: {TaskStatus.IN_PROGRESS, TaskStatus.CANCELLED},\n            TaskStatus.IN_PROGRESS: {TaskStatus.COMPLETED, TaskStatus.FAILED, \n                                    TaskStatus.CANCELLED},\n            TaskStatus.FAILED: set(),\n            TaskStatus.COMPLETED: set(),\n            TaskStatus.CANCELLED: set(),\n        }\n        return to_status in valid_transitions.get(from_status, set())\n    \n    def cancel_task(self, task_id: str) -> bool:\n        \"\"\"Cancel a pending task\"\"\"\n        with self._lock:\n            task = self._tasks.get(task_id)\n            if not task:\n                return False\n            if task.status == TaskStatus.PENDING:\n                try:\n                    self.update_status(task_id, TaskStatus.CANCELLED)\n                    return True\n                except (TaskNotFoundError, InvalidStateTransitionError):\n                    return False\n            return False\n    \n    def requeue_task(self, task_id: str, reset_retries: bool = False) -> bool:\n        \"\"\"\n        Manually requeue a task (for worker failures or manual retry).\n        Only works for IN_PROGRESS tasks.\n        \"\"\"\n        with self._lock:\n            task = self._tasks.get(task_id)\n            if not task or task.status != TaskStatus.IN_PROGRESS:\n                return False\n            \n            task.status = TaskStatus.PENDING\n            task.started_at = None\n            task.worker_id = None\n            task.updated_at = datetime.utcnow()\n            \n            if reset_retries:\n                task.retry_count = 0\n                task.error_message = None\n            \n            if task_id not in self._heap_task_ids:\n                self._add_to_heap(task)\n            \n            return True\n    \n    def get_queue_stats(self) -> dict:\n        \"\"\"Get comprehensive queue statistics\"\"\"\n        with self._lock:\n            status_counts = defaultdict(int)\n            priority_counts = defaultdict(int)\n            \n            for task in self._tasks.values():\n                status_counts[task.status.value] += 1\n                if task.status == TaskStatus.PENDING:\n                    priority_counts[task.priority.name] += 1\n            \n            return {\n                \"total_tasks\": len(self._tasks),\n                \"pending\": status_counts[TaskStatus.PENDING.value],\n                \"in_progress\": status_counts[TaskStatus.IN_PROGRESS.value],\n                \"completed\": status_counts[TaskStatus.COMPLETED.value],\n                \"failed\": status_counts[TaskStatus.FAILED.value],\n                \"cancelled\": status_counts[TaskStatus.CANCELLED.value],\n                \"pending_by_priority\": dict(priority_counts),\n                \"heap_size\": len(self._heap),\n                \"heap_efficiency\": self._heap_health.efficiency,\n                \"heap_invalid_entries\": self._heap_health.invalid_entries,\n                \"last_cleanup\": self._last_cleanup.isoformat(),\n                \"last_heap_rebuild\": self._heap_health.last_rebuild.isoformat(),\n                \"lifetime_metrics\": dict(self._metrics)\n            }\n    \n    def force_cleanup(self, cleanup_all_terminal: bool = False) -> dict:\n        \"\"\"\n        Manually trigger cleanup and return results.\n        \n        Args:\n            cleanup_all_terminal: If True, remove ALL terminal tasks regardless of age\n        \"\"\"\n        with self._lock:\n            before_count = len(self._tasks)\n            \n            if cleanup_all_terminal:\n                # Emergency cleanup - remove all terminal tasks\n                to_delete = [tid for tid, task in self._tasks.items() \n                           if task.is_terminal()]\n                for task_id in to_delete:\n                    del self._tasks[task_id]\n            else:\n                # Normal cleanup respecting retention policies\n                self._cleanup_old_tasks()\n            \n            after_count = len(self._tasks)\n            \n            before_heap = len(self._heap)\n            self._rebuild_heap()\n            after_heap = len(self._heap)\n            \n            return {\n                \"tasks_removed\": before_count - after_count,\n                \"heap_entries_removed\": before_heap - after_heap,\n                \"tasks_remaining\": after_count,\n                \"heap_size\": after_heap,\n                \"heap_efficiency\": self._heap_health.efficiency,\n                \"all_terminal_cleaned\": cleanup_all_terminal\n            }\n\n# Custom exceptions\nclass QueueFullError(Exception):\n    pass\n\nclass TaskNotFoundError(Exception):\n    pass\n\nclass InvalidStateTransitionError(Exception):\n    pass\n```\n\n### 4. Task Queue Manager Interface\n```python\nclass TaskQueueManager:\n    \"\"\"High-level interface for task queue operations\"\"\"\n    \n    def __init__(self, \n                 max_queue_size: Optional[int] = None,\n                 cleanup_policy: Optional[CleanupPolicy] = None,\n                 heap_rebuild_policy: Optional[HeapRebuildPolicy] = None):\n        \"\"\"\n        Args:\n            max_queue_size: Max pending tasks (None = unlimited)\n            cleanup_policy: Task retention and cleanup configuration\n            heap_rebuild_policy: Heap maintenance thresholds\n        \"\"\"\n        self.queue = PriorityTaskQueue(\n            max_queue_size=max_queue_size,\n            cleanup_policy=cleanup_policy,\n            heap_rebuild_policy=heap_rebuild_policy\n        )\n    \n    def submit_task(self, \n                   payload: Any, \n                   priority: str = \"medium\",\n                   max_retries: int = 3,\n                   retry_policy: Optional[Dict] = None) -> dict:\n        \"\"\"\n        Submit a new task.\n        \n        Args:\n            payload: Task data\n            priority: \"low\", \"medium\", \"high\", or \"critical\"\n            max_retries: Max automatic retries (0 = no retry)\n            retry_policy: Optional metadata for worker-side retry logic\n        \"\"\"\n        try:\n            priority_enum = TaskPriority[priority.upper()]\n        except KeyError:\n            raise ValueError(f\"Invalid priority: {priority}. \"\n                           f\"Valid: {[p.name.lower() for p in TaskPriority]}\")\n        \n        if max_retries < 0:\n            raise ValueError(\"max_retries must be non-negative\")\n        \n        try:\n            task_id = self.queue.enqueue(payload, priority_enum, max_retries, \n                                        retry_policy)\n            return {\n                \"task_id\": task_id, \n                \"status\": \"pending\",\n                \"priority\": priority\n            }\n        except QueueFullError as e:\n            return {\"error\": str(e), \"status\": \"rejected\"}\n    \n    def get_next_task(self, worker_id: Optional[str] = None) -> Optional[dict]:\n        \"\"\"\n        Worker polls for next task.\n        Returns None if queue is empty.\n        \"\"\"\n        task = self.queue.dequeue(worker_id=worker_id)\n        if task:\n            return {\n                \"task_id\": task.id,\n                \"payload\": task.payload,\n                \"priority\": task.priority.name,\n                \"retry_count\": task.retry_count,\n                \"max_retries\": task.max_retries,\n                \"retry_policy\": task.retry_policy\n            }\n        return None\n    \n    def complete_task(self, task_id: str, success: bool = True, \n                     error: Optional[str] = None) -> dict:\n        \"\"\"\n        Mark task as completed or failed.\n        Automatic retry happens based on max_retries.\n        \"\"\"\n        try:\n            status = TaskStatus.COMPLETED if success else TaskStatus.FAILED\n            success_flag, was_retried = self.queue.update_status(\n                task_id, status, error\n            )\n            \n            return {\n                \"task_id\": task_id,\n                \"status\": status.value if not was_retried else \"retrying\",\n                \"retried\": was_retried\n            }\n        except (TaskNotFoundError, InvalidStateTransitionError) as e:\n            return {\"error\": str(e)}\n    \n    def get_task_status(self, task_id: str) -> Optional[dict]:\n        \"\"\"Get detailed task status\"\"\"\n        task = self.queue.get_task(task_id)\n        if not task:\n            return None\n        \n        return {\n            \"task_id\": task.id,\n            \"status\": task.status.value,\n            \"priority\": task.priority.name,\n            \"created_at\": task.created_at.isoformat(),\n            \"started_at\": task.started_at.isoformat() if task.started_at else None,\n            \"completed_at\": task.completed_at.isoformat() if task.completed_at else None,\n            \"error_message\": task.error_message,\n            \"retry_count\": task.retry_count,\n            \"max_retries\": task.max_retries,\n            \"worker_id\": task.worker_id,\n            \"age_seconds\": task.age_seconds(),\n            \"time_in_progress\": task.time_in_progress_seconds()\n        }\n    \n    def cancel_task(self, task_id: str) -> dict:\n        \"\"\"Cancel a pending task\"\"\"\n        success = self.queue.cancel_task(task_id)\n        return {\n            \"task_id\": task_id,\n            \"cancelled\": success,\n            \"message\": \"Task cancelled\" if success \n                      else \"Task not pending or not found\"\n        }\n    \n    def requeue_task(self, task_id: str, reset_retries: bool = False) -> dict:\n        \"\"\"\n        Manually requeue an in-progress task.\n        Useful for worker failure recovery.\n        \"\"\"\n        success = self.queue.requeue_task(task_id, reset_retries)\n        return {\n            \"task_id\": task_id,\n            \"requeued\": success,\n            \"reset_retries\": reset_retries,\n            \"message\": \"Task requeued\" if success \n                      else \"Task not in-progress or not found\"\n        }\n    \n    def get_statistics(self) -> dict:\n        \"\"\"Get comprehensive queue statistics\"\"\"\n        return self.queue.get_queue_stats()\n    \n    def force_maintenance(self, emergency: bool = False) -> dict:\n        \"\"\"\n        Manually trigger cleanup and heap rebuild.\n        \n        Args:\n            emergency: If True, removes ALL terminal tasks regardless of retention policy\n        \"\"\"\n        return self.queue.force_cleanup(cleanup_all_terminal=emergency)\n```\n\n### 5. Health Monitor & Supervisor Utilities\n```python\nfrom typing import List\n\nclass TaskSupervisor:\n    \"\"\"Monitor and recover stuck tasks\"\"\"\n    \n    def __init__(self, manager: TaskQueueManager, \n                 stuck_threshold_seconds: int = 300):\n        self.manager = manager\n        self.stuck_threshold = stuck_threshold_seconds\n    \n    def check_stuck_tasks(self) -> List[dict]:\n        \"\"\"Find tasks stuck in IN_PROGRESS state\"\"\"\n        with self.manager.queue._lock:\n            stuck_tasks = []\n            now = datetime.utcnow()\n            \n            for task in self.manager.queue._tasks.values():\n                if task.status != TaskStatus.IN_PROGRESS:\n                    continue\n                \n                time_in_progress = task.time_in_progress_seconds()\n                if time_in_progress and time_in_progress >= self.stuck_threshold:\n                    stuck_tasks.append({\n                        'task_id': task.id,\n                        'worker_id': task.worker_id,\n                        'priority': task.priority.name,\n                        'time_in_progress': time_in_progress,\n                        'started_at': task.started_at.isoformat()\n                    })\n            \n            return stuck_tasks\n    \n    def requeue_stuck_tasks(self, reset_retries: bool = False) -> dict:\n        \"\"\"Automatically requeue stuck tasks\"\"\"\n        stuck = self.check_stuck_tasks()\n        requeued = []\n        failed = []\n        \n        for task_info in stuck:\n            result = self.manager.requeue_task(\n                task_info['task_id'], \n                reset_retries=reset_retries\n            )\n            if result['requeued']:\n                requeued.append(task_info['task_id'])\n            else:\n                failed.append(task_info['task_id'])\n        \n        return {\n            \"stuck_tasks_found\": len(stuck),\n            \"tasks_requeued\": len(requeued),\n            \"tasks_failed_to_requeue\": len(failed),\n            \"requeued_task_ids\": requeued,\n            \"failed_task_ids\": failed\n        }\n```\n\n## Usage Examples\n\n### Basic Configuration\n```python\n# Simple setup with defaults\nmanager = TaskQueueManager(\n    max_queue_size=10000\n)\n\n# Advanced setup with custom policies\ncleanup_policy = CleanupPolicy(\n    completed_retention_seconds=3600,    # Keep completed 1hr\n    failed_retention_seconds=7200,       # Keep failed 2hr\n    cancelled_retention_seconds=1800,    # Keep cancelled 30min\n    cleanup_interval_seconds=300,        # Cleanup every 5min\n    max_tasks_per_cleanup=1000,          # Rate limit\n    min_terminal_tasks_before_cleanup=50 # Safety threshold\n)\n\nheap_policy = HeapRebuildPolicy(\n    min_efficiency=0.5,\n    min_total_entries=100,\n    max_rebuild_interval_seconds=3600\n)\n\nmanager = TaskQueueManager(\n    max_queue_size=10000,\n    cleanup_policy=cleanup_policy,\n    heap_rebuild_policy=heap_policy\n)\n```\n\n### Worker with Automatic Retry\n```python\n# Worker with automatic retry handling\nworker_id = \"worker-1\"\n\nwhile True:\n    task = manager.get_next_task(worker_id=worker_id)\n    \n    if task:\n        try:\n            result = process_task(task['payload'])\n            manager.complete_task(task['task_id'], success=True)\n        except Exception as e:\n            # Queue handles retry automatically based on max_retries\n            response = manager.complete_task(\n                task['task_id'], \n                success=False, \n                error=str(e)\n            )\n            \n            if response.get('retried'):\n                logger.info(f\"Task {task['task_id']} will be retried\")\n            else:\n                logger.error(f\"Task {task['task_id']} failed permanently\")\n    else:\n        time.sleep(1)\n```\n\n### Worker with Smart Retry Policy\n```python\nimport time\n\ndef smart_worker():\n    \"\"\"Worker that respects retry_policy metadata\"\"\"\n    worker_id = \"smart-worker-1\"\n    \n    while True:\n        task = manager.get_next_task(worker_id=worker_id)\n        \n        if not task:\n            time.sleep(1)\n            continue\n        \n        # Extract retry policy hints\n        retry_policy = task.get('retry_policy') or {}\n        retry_count = task['retry_count']\n        \n        try:\n            result = call_external_api(task['payload'])\n            manager.complete_task(task['task_id'], success=True)\n            \n        except RateLimitError as e:\n            # Use exponential backoff for rate limits\n            manager.complete_task(task['task_id'], success=False, error=str(e))\n            \n            if retry_policy.get('backoff') == 'exponential':\n                base_delay = retry_policy.get('base_delay', 2)\n                max_delay = retry_policy.get('max_delay', 60)\n                delay = min(base_delay ** retry_count, max_delay)\n                time.sleep(delay)\n        \n        except PermanentError as e:\n            # Some errors shouldn't be retried - mark failed\n            manager.complete_task(task['task_id'], success=False, error=str(e))\n```\n\n### Monitoring & Maintenance\n```python\n# Get comprehensive statistics\nstats = manager.get_statistics()\n\nprint(f\"Queue Health:\")\nprint(f\"  Pending: {stats['pending']}\")\nprint(f\"  In Progress: {stats['in_progress']}\")\nprint(f\"  Heap Efficiency: {stats['heap_efficiency']:.2%}\")\nprint(f\"  Invalid Heap Entries: {stats['heap_invalid_entries']}\")\n\nprint(f\"\\nLifetime Metrics:\")\nmetrics = stats['lifetime_metrics']\nprint(f\"  Total Enqueued: {metrics['total_enqueued']}\")\nprint(f\"  Total Completed: {metrics['total_completed']}\")\nprint(f\"  Total Failed: {metrics['total_failed']}\")\nprint(f\"  Total Retried: {metrics['total_retried']}\")\nprint(f\"  Total Cleaned: {metrics['total_cleaned']}\")\nprint(f\"  Cleanup Runs: {metrics['cleanup_runs']}\")\nprint(f\"  Heap Rebuilds: {metrics['heap_rebuilds']}\")\n\n# Normal maintenance\nif stats['heap_efficiency'] < 0.3:\n    result = manager.force_maintenance()\n    print(f\"Cleaned {result['tasks_removed']} tasks, \"\n          f\"removed {result['heap_entries_removed']} stale heap entries\")\n\n# Emergency cleanup (remove ALL terminal tasks)\nif stats['total_tasks'] > 1_000_000:\n    result = manager.force_maintenance(emergency=True)\n    print(f\"Emergency cleanup: removed {result['tasks_removed']} terminal tasks\")\n```\n\n### Supervisor for Stuck Task Recovery\n```python\n# Run supervisor periodically (e.g., every minute)\nsupervisor = TaskSupervisor(manager, stuck_threshold_seconds=300)\n\n# Check for stuck tasks\nstuck_tasks = supervisor.check_stuck_tasks()\nif stuck_tasks:\n    print(f\"Found {len(stuck_tasks)} stuck tasks:\")\n    for task in stuck_tasks:\n        print(f\"  {task['task_id']}: stuck for {task['time_in_progress']:.0f}s \"\n              f\"on worker {task['worker_id']}\")\n\n# Automatically recover stuck tasks\nrecovery = supervisor.requeue_stuck_tasks(reset_retries=False)\nprint(f\"Requeued {recovery['tasks_requeued']} stuck tasks\")\nif recovery['failed_task_ids']:\n    print(f\"Failed to requeue: {recovery['failed_task_ids']}\")\n```\n\n### Custom Retention Policy for Audit Requirements\n```python\n# Keep completed tasks for 7 days for audit, failed for 30 days\naudit_policy = CleanupPolicy(\n    completed_retention_seconds=7 * 24 * 3600,   # 7 days\n    failed_retention_seconds=30 * 24 * 3600,     # 30 days\n    cancelled_retention_seconds=24 * 3600,       # 1 day\n    cleanup_interval_seconds=3600,               # Hourly cleanup\n    max_tasks_per_cleanup=5000,\n    min_terminal_tasks_before_cleanup=1000\n)\n\nmanager = TaskQueueManager(\n    max_queue_size=50000,\n    cleanup_policy=audit_policy\n)\n```\n\n## What I Improved\n\n### 1. **Configurable Cleanup Thresholds**\n- Added `CleanupPolicy` dataclass with per-status retention\n- Failed tasks kept longer than completed (2hr vs 1hr) - failures need investigation\n- Rate-limited cleanup (`max_tasks_per_cleanup`) to prevent blocking\n- Safety threshold (`min_terminal_tasks_before_cleanup`) prevents wasteful cleanup\n- **Why**: Different task types have different retention needs; one-size-fits-all is insufficient\n\n### 2. **Configurable Heap Rebuild Policy**\n- Added `HeapRebuildPolicy` with efficiency threshold, size threshold, and max interval\n- Force rebuild every hour even if efficiency is good (prevents edge cases)\n- Made thresholds explicit and tunable rather than magic numbers\n- **Why**: Different workloads need different rebuild strategies; expose control\n\n### 3. **Per-Status Retention Policies**\n- `completed_retention_seconds`, `failed_retention_seconds`, `cancelled_retention_seconds`\n- Each status can have different TTL (or None to keep forever)\n- `get_retention_for_status()` encapsulates lookup logic\n- **Why**: Audit requirements often mandate longer failed task retention; completed tasks can be purged faster\n\n### 4. **Enhanced Task Model**\n- Added `time_since_completion_seconds()` for cleanup logic\n- Separates \"task age\" from \"terminal state age\" - critical for retention\n- **Why**: Cleanup should be based on when task *completed*, not when it was created\n\n### 5. **Comprehensive Metrics Tracking**\n- Lifetime counters: enqueued, dequeued, completed, failed, cancelled, retried, cleaned\n- Cleanup runs and heap rebuilds tracked\n- `heap_invalid_entries` exposed in stats\n- **Why**: Production systems need visibility into system behavior over time\n\n### 6. **Safe Concurrent Cleanup**\n- Rate-limited deletion prevents long lock holds\n- `max_tasks_per_cleanup` prevents cleanup from blocking workers\n- Safety check (`min_terminal_tasks_before_cleanup`) avoids overhead on small queues\n- **Why**: Cleanup shouldn't impact worker throughput\n\n### 7. **Emergency Maintenance Mode**\n- `force_maintenance(emergency=True)` removes ALL terminal tasks\n- Useful for memory pressure situations\n- Returns detailed metrics on what was cleaned\n- **Why**: Production systems need panic buttons\n\n### 8. **Enhanced Supervisor**\n- Returns detailed info on stuck tasks (worker_id, time stuck, etc.)\n- Separate failed/succeeded lists for requeue operations\n- Optional `reset_retries` flag for recovery scenarios\n- **Why**: Operators need actionable information, not just counts\n\n### 9. **Better Error Handling in complete_task**\n- Returns `status: \"retrying\"` when task is automatically retried\n- Distinguishes between \"failed and retrying\" vs \"failed permanently\"\n- **Why**: Workers should know if their failure triggered retry\n\n### 10. **Invalid Entry Tracking**\n- `heap_health.invalid_entries` incremented when skipping stale entries\n- Helps diagnose heap bloat issues\n- **Why**: Observability into lazy deletion behavior\n\n## What I Kept\n\n- **Simplified retry model**: Automatic retry based on `max_retries` is correct\n- **retry_policy as metadata**: Queue doesn't interpret it, just passes through - perfect separation\n- **Core heap architecture**: Efficient priority queue with lazy deletion\n- **RLock for thread safety**: Essential for concurrent workers\n- **State machine validation**: Prevents invalid transitions\n- **Worker ID tracking**: Critical for debugging stuck tasks\n- **Manual requeue**: Supervisor pattern requires this\n- **Sequence numbers**: FIFO within priority is important\n- **Task helper methods**: `is_terminal()`, `age_seconds()`, etc.\n\n## Remaining Concerns\n\n### 1. **Cleanup Lock Contention**\nThe opportunistic cleanup during `enqueue`/`dequeue` holds the lock while iterating tasks. For large task dictionaries (100k+ tasks), this could block workers.\n\n**Options**:\n- Move cleanup to background thread\n- Use lazy deletion for terminal tasks too (track separately)\n- Add write-ahead log for cleanup candidates\n\n### 2. **Memory Overhead of Metrics**\nLifetime metrics grow unbounded. In a system running for months, these counters could overflow.\n\n**Options**:\n- Use prometheus-style metrics (external aggregation)\n- Reset metrics periodically\n- Use sliding windows instead of lifetime counts\n\n### 3. **No Index for IN_PROGRESS Tasks**\nSupervisor has to iterate all tasks to find stuck ones. This is O(n) on total tasks.\n\n**Options**:\n- Maintain separate `_in_progress_tasks` dict\n- Index by worker_id for targeted lookups\n- Track task start times in a separate min-heap for efficient \"oldest in-progress\" queries\n\n### 4. **Copy vs Reference in get_task()**\nCurrently returns task reference, which allows external mutation. But making defensive copies has performance cost.\n\n**Options**:\n- Return immutable view object\n- Use frozen dataclass for external API\n- Document as internal-only and provide separate public API\n\n### 5. **No Circuit Breaker for Failed Tasks**\nIf a task type consistently fails (bad payload, external service down), it will retry indefinitely across queue restarts.\n\n**Options**:\n- Track failure patterns by payload type/signature\n- Implement backoff at queue level (delay before retry)\n- Add \"poison task\" detection (task fails X times = quarantine)\n\n## Convergence Status\n\n**ITERATING** - Design addresses the key concerns but needs validation on:\n\n1. Whether per-status retention meets your audit/compliance requirements\n2. If cleanup rate limiting (max_tasks_per_cleanup) is sufficient for your scale\n3. Trade-offs between cleanup overhead and memory bounds under high load\n4. Whether locked cleanup is acceptable or background thread is needed\n\n## Prompt for Collaborator\n\nPROMPT_FOR_ARCHITECT:\n\nI've added per-status retention policies, configurable cleanup/rebuild thresholds, comprehensive metrics, and safer concurrent cleanup. Key questions:\n\n1. **Cleanup lock contention**: Cleanup runs under the main lock and iterates all tasks. For a queue with 100k+ tasks, this could block workers during cleanup. Should we move cleanup to a background thread, or is rate-limiting (`max_tasks_per_cleanup=1000`) sufficient?\n\n2. **Per-status retention**: I kept failed tasks for 2x longer than completed (2hr vs 1hr) assuming failures need investigation. Does this match your use case? Should we support per-priority retention too (keep CRITICAL tasks longer)?\n\n3. **Heap rebuild policy**: I added `max_rebuild_interval_seconds` to force periodic rebuilds even if efficiency looks good. Is this paranoia, or does it prevent edge cases I'm not seeing?\n\n4. **IN_PROGRESS task indexing**: Supervisor iterates all tasks to find stuck ones (O(n)). Should we maintain a separate index of in-progress tasks for O(1) lookups, or is periodic O(n) scan acceptable?\n\n5. **Did I over-engineer cleanup?** Is per-status retention + rate limiting + safety thresholds too complex? Would a simpler \"keep terminal tasks for N hours\" suffice?"
      }
    }
  ],
  "final_design": "",
  "status": "debating",
  "started_at": "2026-01-17T09:14:03.427099",
  "ended_at": "",
  "max_rounds": 2,
  "working_dir": ".",
  "current_round": 2,
  "round_times": [
    104.8952362537384,
    224.72197651863098
  ]
}