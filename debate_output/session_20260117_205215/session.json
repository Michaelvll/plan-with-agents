{
  "initial_prompt": "Design a visual AI agent workflow builder\n\nRequirements:\n- Drag-and-drop nodes for different agent types (researcher, coder, reviewer)\n- Connect nodes to show data flow between agents\n- Configure each node (model, temperature, system prompt)\n- Show real-time execution status and logs\n- Visualize agent communication/handoffs\n- Save and load workflow templates\n- React with a canvas library",
  "status": "debating",
  "rounds": 4,
  "started_at": "2026-01-17T20:52:15.016785",
  "ended_at": "2026-01-17T21:18:18.877015",
  "final_design": "## Design\n\n# Visual AI Agent Workflow Builder - Production-Ready Architecture v5\n\n## Core Architecture\n\n### System Overview\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     React Application Layer                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u2502\n\u2502  \u2502   Canvas     \u2502  \u2502  Properties  \u2502  \u2502   Toolbar    \u2502         \u2502\n\u2502  \u2502   (React     \u2502  \u2502    Panel     \u2502  \u2502   & Palette  \u2502         \u2502\n\u2502  \u2502    Flow)     \u2502  \u2502              \u2502  \u2502              \u2502         \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502           State Management (Zustand + Immer)                     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502              Execution Orchestration Layer                \u2502  \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u2502  \u2502\n\u2502  \u2502  \u2502 Adaptive   \u2502  \u2502  Resilient \u2502  \u2502 Checkpoint \u2502         \u2502  \u2502\n\u2502  \u2502  \u2502 Executor   \u2502  \u2502  Stream    \u2502  \u2502  Manager   \u2502         \u2502  \u2502\n\u2502  \u2502  \u2502            \u2502  \u2502  Manager   \u2502  \u2502            \u2502         \u2502  \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502              Data Flow & Storage Layer                    \u2502  \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u2502  \u2502\n\u2502  \u2502  \u2502 Composable \u2502  \u2502   Tiered   \u2502  \u2502 Effect Log \u2502         \u2502  \u2502\n\u2502  \u2502  \u2502 Expression \u2502  \u2502  Storage   \u2502  \u2502  (Append-  \u2502         \u2502  \u2502\n\u2502  \u2502  \u2502  System    \u2502  \u2502  Manager   \u2502  \u2502   Only)    \u2502         \u2502  \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n### Technology Stack\n- **Canvas**: React Flow v11+ with viewport culling\n- **State**: Zustand with immer middleware and persistence\n- **UI**: Radix UI primitives + Tailwind CSS\n- **Execution**: Adaptive executor with resilient streaming\n- **Storage**: Three-tier (Memory + IndexedDB + SessionStorage) with per-workflow policies\n- **Expressions**: Composable expression system with visual-text hybrid mode\n- **Side Effects**: Append-only log with sandboxed compensation handlers\n- **Workers**: Shared Worker pool with resource quotas\n\n## Resilient Stream Manager (Solves Page Refresh Problem)\n\n### Key Innovation: Automatic Checkpoint-Based Stream Resurrection\n\n```typescript\ninterface StreamManagerConfig {\n  maxConcurrentStreams: number;        // 50\n  streamTimeout: number;                // 5min\n  autoCheckpointInterval: number;       // 30s - checkpoint long-lived streams\n  checkpointThresholdAge: number;       // 60s - checkpoint if older than this\n  enableResurrection: boolean;          // Restore streams after page refresh\n  maxResurrectionAttempts: number;      // 3\n}\n\ninterface StreamCheckpoint {\n  streamId: string;\n  sourceNodeId: string;\n  executionId: string;\n  consumerCount: number;\n  createdAt: number;\n  lastCheckpointAt: number;\n  \n  // Resurrection data\n  materializationType: 'full' | 'partial' | 'regenerate';\n  materializedData?: any;               // For 'full' or 'partial'\n  partialOffset?: number;               // Where partial stopped\n  regenerationConfig?: {                // For 'regenerate'\n    nodeConfig: any;\n    inputs: Record<string, any>;\n  };\n  \n  // State\n  status: 'active' | 'checkpointed' | 'resurrected' | 'expired';\n  resurrectionAttempts: number;\n}\n\nclass ResilientStreamManager {\n  private activeStreams: Map<string, ActiveStreamEntry> = new Map();\n  private checkpoints: Map<string, StreamCheckpoint> = new Map();\n  private storage: HybridStorageManager;\n  private config: StreamManagerConfig;\n  \n  constructor(storage: HybridStorageManager, config: StreamManagerConfig) {\n    this.storage = storage;\n    this.config = config;\n    \n    // Restore checkpoints from previous session\n    if (config.enableResurrection) {\n      this.restoreCheckpointsFromStorage();\n    }\n    \n    this.startAutoCheckpointing();\n    this.startTimeoutMonitor();\n  }\n  \n  async registerStream(\n    sourceNodeId: string,\n    executionId: string,\n    stream: ReadableStream,\n    consumerCount: number,\n    options: {\n      estimatedSize: number;\n      materializationType?: 'full' | 'partial' | 'regenerate';\n      regenerationConfig?: any;\n    }\n  ): Promise<string> {\n    \n    if (this.activeStreams.size >= this.config.maxConcurrentStreams) {\n      throw new Error(\n        `Max concurrent streams reached (${this.config.maxConcurrentStreams})`\n      );\n    }\n    \n    const streamId = crypto.randomUUID();\n    \n    // Create teed streams\n    const teedStreams = this.createMultiTee(stream, consumerCount);\n    \n    // Create checkpoint\n    const checkpoint: StreamCheckpoint = {\n      streamId,\n      sourceNodeId,\n      executionId,\n      consumerCount,\n      createdAt: Date.now(),\n      lastCheckpointAt: Date.now(),\n      materializationType: options.materializationType ?? 'full',\n      regenerationConfig: options.regenerationConfig,\n      status: 'active',\n      resurrectionAttempts: 0\n    };\n    \n    this.checkpoints.set(streamId, checkpoint);\n    \n    this.activeStreams.set(streamId, {\n      checkpoint,\n      streams: teedStreams,\n      readers: new Set(),\n      materializedChunks: options.materializationType !== 'regenerate' ? [] : undefined\n    });\n    \n    return streamId;\n  }\n  \n  async getStream(streamId: string, consumerIndex: number): Promise<ReadableStream> {\n    const active = this.activeStreams.get(streamId);\n    \n    if (active) {\n      // Stream is live\n      active.checkpoint.lastCheckpointAt = Date.now();\n      return active.streams[consumerIndex];\n    }\n    \n    // Try to resurrect from checkpoint\n    if (this.config.enableResurrection) {\n      const resurrected = await this.resurrectStream(streamId, consumerIndex);\n      if (resurrected) return resurrected;\n    }\n    \n    throw new Error(`Stream not found and could not be resurrected: ${streamId}`);\n  }\n  \n  private async resurrectStream(\n    streamId: string, \n    consumerIndex: number\n  ): Promise<ReadableStream | null> {\n    \n    const checkpoint = this.checkpoints.get(streamId);\n    if (!checkpoint) return null;\n    \n    if (checkpoint.resurrectionAttempts >= this.config.maxResurrectionAttempts) {\n      console.error(`Max resurrection attempts reached for stream ${streamId}`);\n      return null;\n    }\n    \n    checkpoint.resurrectionAttempts++;\n    \n    try {\n      switch (checkpoint.materializationType) {\n        case 'full':\n          return await this.resurrectFromFullMaterialization(checkpoint);\n          \n        case 'partial':\n          return await this.resurrectFromPartialMaterialization(checkpoint);\n          \n        case 'regenerate':\n          return await this.resurrectViaRegeneration(checkpoint);\n          \n        default:\n          throw new Error(`Unknown materialization type: ${checkpoint.materializationType}`);\n      }\n    } catch (error: any) {\n      console.error(`Stream resurrection failed: ${error.message}`);\n      return null;\n    }\n  }\n  \n  private async resurrectFromFullMaterialization(\n    checkpoint: StreamCheckpoint\n  ): Promise<ReadableStream> {\n    \n    // Load materialized data from storage\n    const storageKey = `stream-checkpoint-${checkpoint.streamId}`;\n    const materialized = await this.storage.retrieve(storageKey);\n    \n    // Convert back to stream\n    const stream = new ReadableStream({\n      start(controller) {\n        if (Array.isArray(materialized)) {\n          for (const chunk of materialized) {\n            controller.enqueue(chunk);\n          }\n        } else {\n          controller.enqueue(materialized);\n        }\n        controller.close();\n      }\n    });\n    \n    checkpoint.status = 'resurrected';\n    \n    return stream;\n  }\n  \n  private async resurrectFromPartialMaterialization(\n    checkpoint: StreamCheckpoint\n  ): Promise<ReadableStream> {\n    \n    // Load partial data\n    const storageKey = `stream-checkpoint-${checkpoint.streamId}`;\n    const partialData = await this.storage.retrieve(storageKey);\n    \n    // Return stream that first emits partial data, then signals \"incomplete\"\n    const stream = new ReadableStream({\n      start(controller) {\n        if (Array.isArray(partialData)) {\n          for (const chunk of partialData) {\n            controller.enqueue(chunk);\n          }\n        }\n        \n        // Signal incomplete\n        controller.enqueue({\n          $incomplete: true,\n          offset: checkpoint.partialOffset,\n          message: 'Stream was interrupted. Partial data only.'\n        });\n        \n        controller.close();\n      }\n    });\n    \n    checkpoint.status = 'resurrected';\n    \n    return stream;\n  }\n  \n  private async resurrectViaRegeneration(\n    checkpoint: StreamCheckpoint\n  ): Promise<ReadableStream> {\n    \n    if (!checkpoint.regenerationConfig) {\n      throw new Error('No regeneration config available');\n    }\n    \n    // Re-execute the node to regenerate the stream\n    // This requires access to the executor (injected via callback)\n    const regenerated = await this.executeNodeForRegeneration(\n      checkpoint.sourceNodeId,\n      checkpoint.regenerationConfig.nodeConfig,\n      checkpoint.regenerationConfig.inputs\n    );\n    \n    checkpoint.status = 'resurrected';\n    \n    return regenerated;\n  }\n  \n  private async executeNodeForRegeneration(\n    nodeId: string,\n    nodeConfig: any,\n    inputs: Record<string, any>\n  ): Promise<ReadableStream> {\n    \n    // This is called by injecting an executor callback during initialization\n    // For now, throw error to indicate implementation needed\n    throw new Error(\n      'Regeneration requires executor callback. ' +\n      'Set ResilientStreamManager.regenerationExecutor = (node, inputs) => stream'\n    );\n  }\n  \n  private startAutoCheckpointing(): void {\n    setInterval(() => {\n      this.checkpointLongLivedStreams();\n    }, this.config.autoCheckpointInterval);\n  }\n  \n  private async checkpointLongLivedStreams(): Promise<void> {\n    const now = Date.now();\n    const threshold = this.config.checkpointThresholdAge;\n    \n    for (const [streamId, entry] of this.activeStreams.entries()) {\n      const age = now - entry.checkpoint.createdAt;\n      \n      if (age > threshold && entry.checkpoint.status === 'active') {\n        await this.checkpointStream(streamId);\n      }\n    }\n  }\n  \n  private async checkpointStream(streamId: string): Promise<void> {\n    const entry = this.activeStreams.get(streamId);\n    if (!entry) return;\n    \n    const checkpoint = entry.checkpoint;\n    \n    switch (checkpoint.materializationType) {\n      case 'full':\n        // Materialize all consumed chunks so far\n        if (entry.materializedChunks && entry.materializedChunks.length > 0) {\n          const storageKey = `stream-checkpoint-${streamId}`;\n          checkpoint.materializedData = [...entry.materializedChunks];\n          \n          await this.storage.store(storageKey, checkpoint.materializedData, {\n            temporary: false,\n            pinned: true,\n            nodeId: checkpoint.sourceNodeId,\n            dataType: 'materialized'\n          });\n          \n          checkpoint.status = 'checkpointed';\n          checkpoint.lastCheckpointAt = Date.now();\n        }\n        break;\n        \n      case 'partial':\n        // Only keep last N chunks\n        if (entry.materializedChunks) {\n          const keepCount = 10;\n          const partial = entry.materializedChunks.slice(-keepCount);\n          \n          const storageKey = `stream-checkpoint-${streamId}`;\n          await this.storage.store(storageKey, partial, {\n            temporary: false,\n            pinned: true,\n            nodeId: checkpoint.sourceNodeId,\n            dataType: 'materialized'\n          });\n          \n          checkpoint.partialOffset = entry.materializedChunks.length - keepCount;\n          checkpoint.status = 'checkpointed';\n          checkpoint.lastCheckpointAt = Date.now();\n        }\n        break;\n        \n      case 'regenerate':\n        // No materialization needed - regeneration config already stored\n        checkpoint.status = 'checkpointed';\n        checkpoint.lastCheckpointAt = Date.now();\n        break;\n    }\n    \n    // Persist checkpoint metadata to SessionStorage\n    await this.persistCheckpoint(checkpoint);\n  }\n  \n  private async persistCheckpoint(checkpoint: StreamCheckpoint): Promise<void> {\n    const key = `stream-checkpoint-meta-${checkpoint.streamId}`;\n    sessionStorage.setItem(key, JSON.stringify(checkpoint));\n  }\n  \n  private async restoreCheckpointsFromStorage(): Promise<void> {\n    const keys = Object.keys(sessionStorage);\n    \n    for (const key of keys) {\n      if (key.startsWith('stream-checkpoint-meta-')) {\n        const checkpointData = sessionStorage.getItem(key);\n        if (checkpointData) {\n          const checkpoint: StreamCheckpoint = JSON.parse(checkpointData);\n          this.checkpoints.set(checkpoint.streamId, checkpoint);\n        }\n      }\n    }\n  }\n  \n  private createMultiTee(stream: ReadableStream, count: number): ReadableStream[] {\n    if (count === 1) return [stream];\n    if (count === 2) return stream.tee();\n    \n    const streams: ReadableStream[] = [];\n    let remaining = stream;\n    \n    for (let i = 0; i < count - 1; i++) {\n      const [stream1, stream2] = remaining.tee();\n      streams.push(stream1);\n      remaining = stream2;\n    }\n    streams.push(remaining);\n    \n    return streams;\n  }\n  \n  async acquireReader(\n    streamId: string, \n    consumerIndex: number\n  ): Promise<ReadableStreamDefaultReader> {\n    const stream = await this.getStream(streamId, consumerIndex);\n    const reader = stream.getReader();\n    \n    const entry = this.activeStreams.get(streamId);\n    if (entry) {\n      entry.readers.add(reader);\n      \n      // Wrap reader to capture chunks for checkpointing\n      if (entry.materializedChunks) {\n        return this.wrapReaderForCheckpointing(reader, entry.materializedChunks);\n      }\n    }\n    \n    return reader;\n  }\n  \n  private wrapReaderForCheckpointing(\n    reader: ReadableStreamDefaultReader,\n    chunksBuffer: any[]\n  ): ReadableStreamDefaultReader {\n    \n    const originalRead = reader.read.bind(reader);\n    \n    reader.read = async () => {\n      const result = await originalRead();\n      \n      if (!result.done && result.value !== undefined) {\n        chunksBuffer.push(result.value);\n      }\n      \n      return result;\n    };\n    \n    return reader;\n  }\n  \n  async releaseReader(\n    streamId: string, \n    reader: ReadableStreamDefaultReader\n  ): Promise<void> {\n    const entry = this.activeStreams.get(streamId);\n    if (!entry) return;\n    \n    try {\n      reader.releaseLock();\n    } catch {\n      // Already released\n    }\n    \n    entry.readers.delete(reader);\n    \n    if (entry.readers.size === 0) {\n      await this.cleanup(streamId, 'completed');\n    }\n  }\n  \n  private async cleanup(\n    streamId: string, \n    reason: 'completed' | 'error' | 'timeout'\n  ): Promise<void> {\n    const entry = this.activeStreams.get(streamId);\n    if (!entry) return;\n    \n    // Final checkpoint before cleanup\n    if (reason === 'completed' && entry.checkpoint.materializationType !== 'regenerate') {\n      await this.checkpointStream(streamId);\n    }\n    \n    entry.checkpoint.status = 'expired';\n    \n    for (const stream of entry.streams) {\n      try {\n        const reader = stream.getReader();\n        await reader.cancel(`Cleanup: ${reason}`);\n        reader.releaseLock();\n      } catch {\n        // Ignore\n      }\n    }\n    \n    this.activeStreams.delete(streamId);\n  }\n  \n  private startTimeoutMonitor(): void {\n    setInterval(() => {\n      const now = Date.now();\n      const timeout = this.config.streamTimeout;\n      \n      for (const [streamId, entry] of this.activeStreams.entries()) {\n        if (now - entry.checkpoint.lastCheckpointAt > timeout) {\n          console.warn(`Stream timeout: ${streamId}`);\n          this.cleanup(streamId, 'timeout');\n        }\n      }\n    }, 60000);\n  }\n  \n  getCheckpoint(streamId: string): StreamCheckpoint | null {\n    return this.checkpoints.get(streamId) ?? null;\n  }\n  \n  listActiveStreams(): StreamCheckpoint[] {\n    return Array.from(this.activeStreams.values())\n      .map(entry => entry.checkpoint);\n  }\n  \n  // Public property for injecting regeneration logic\n  regenerationExecutor?: (\n    nodeId: string, \n    nodeConfig: any, \n    inputs: Record<string, any>\n  ) => Promise<ReadableStream>;\n}\n\ninterface ActiveStreamEntry {\n  checkpoint: StreamCheckpoint;\n  streams: ReadableStream[];\n  readers: Set<ReadableStreamDefaultReader>;\n  materializedChunks?: any[];  // For 'full' or 'partial' checkpointing\n}\n```\n\n## Enhanced Tiered Storage with Per-Workflow Policies\n\n### Key Innovation: Workflow-Scoped Storage Configuration\n\n```typescript\ninterface WorkflowStoragePolicy {\n  workflowId: string;\n  \n  // Tier capacities (per workflow)\n  memoryCacheMaxBytes: number;          // Default: 50MB per workflow\n  indexedDBMaxBytes: number;            // Default: 500MB per workflow\n  \n  // Overflow behavior\n  overflowPolicy: 'evict-lru' | 'evict-oldest' | 'fail' | 'compress' | 'external';\n  \n  // Eviction preferences\n  evictionPreferences: {\n    protectRecent: boolean;             // Don't evict < 5s old\n    protectFrequent: boolean;           // Prefer low-access items\n    protectPinned: boolean;             // Never evict pinned\n  };\n  \n  // Auto-cleanup\n  autoCleanupAge: number;               // 24h\n  enableAutoCleanup: boolean;\n}\n\nclass TieredStorageManager {\n  private memoryCache: Map<string, CacheEntry> = new Map();\n  private memoryCacheSize: number = 0;\n  private indexedDB: IDBDatabase;\n  private indexedDBSize: number = 0;\n  \n  // Per-workflow policies\n  private workflowPolicies: Map<string, WorkflowStoragePolicy> = new Map();\n  private globalPolicy: WorkflowStoragePolicy;\n  \n  // Artifact metadata\n  private artifactIndex: Map<string, ArtifactMetadata> = new Map();\n  \n  // External blobs\n  private externalBlobs: Map<string, string> = new Map();\n  \n  // Session-level temporary storage (survives refresh)\n  private sessionStorage: Storage = window.sessionStorage;\n  \n  constructor(globalPolicy: WorkflowStoragePolicy) {\n    this.globalPolicy = globalPolicy;\n    this.initIndexedDB();\n    this.restoreFromSession();\n  }\n  \n  setWorkflowPolicy(workflowId: string, policy: WorkflowStoragePolicy): void {\n    this.workflowPolicies.set(workflowId, policy);\n  }\n  \n  getPolicy(workflowId?: string): WorkflowStoragePolicy {\n    if (workflowId) {\n      return this.workflowPolicies.get(workflowId) ?? this.globalPolicy;\n    }\n    return this.globalPolicy;\n  }\n  \n  async store(\n    key: string, \n    data: any, \n    hints: StorageHints = {}\n  ): Promise<void> {\n    \n    const policy = this.getPolicy(hints.workflowId);\n    const serialized = JSON.stringify(data);\n    const sizeBytes = new TextEncoder().encode(serialized).length;\n    \n    // Create metadata\n    const metadata: ArtifactMetadata = {\n      key,\n      sizeBytes,\n      tier: 'determining',\n      createdAt: Date.now(),\n      lastAccessedAt: Date.now(),\n      accessCount: 0,\n      temporary: hints.temporary ?? true,\n      pinned: hints.pinned ?? false,\n      nodeId: hints.nodeId,\n      executionId: hints.executionId,\n      workflowId: hints.workflowId,\n      dataType: hints.dataType ?? 'json'\n    };\n    \n    this.artifactIndex.set(key, metadata);\n    \n    // Check if we should use session storage (for critical workflow state)\n    if (hints.useSessionStorage) {\n      this.sessionStorage.setItem(key, serialized);\n      metadata.tier = 'session';\n      return;\n    }\n    \n    // Tier decision\n    if (sizeBytes < 1024 * 1024) {\n      if (await this.tryStoreInMemory(key, data, sizeBytes, policy)) {\n        metadata.tier = 'memory';\n        return;\n      }\n    }\n    \n    await this.storeInIndexedDB(key, serialized, sizeBytes, policy);\n    metadata.tier = 'indexeddb';\n  }\n  \n  private async tryStoreInMemory(\n    key: string, \n    data: any, \n    sizeBytes: number,\n    policy: WorkflowStoragePolicy\n  ): Promise<boolean> {\n    \n    if (this.memoryCacheSize + sizeBytes <= policy.memoryCacheMaxBytes) {\n      this.memoryCache.set(key, {\n        data,\n        sizeBytes,\n        storedAt: Date.now()\n      });\n      this.memoryCacheSize += sizeBytes;\n      return true;\n    }\n    \n    if (await this.evictFromMemory(sizeBytes, policy)) {\n      this.memoryCache.set(key, {\n        data,\n        sizeBytes,\n        storedAt: Date.now()\n      });\n      this.memoryCacheSize += sizeBytes;\n      return true;\n    }\n    \n    return false;\n  }\n  \n  private async evictFromMemory(\n    requiredBytes: number, \n    policy: WorkflowStoragePolicy\n  ): Promise<boolean> {\n    \n    const candidates = Array.from(this.artifactIndex.values())\n      .filter(m => \n        m.tier === 'memory' &&\n        (!policy.evictionPreferences.protectPinned || !m.pinned) &&\n        (!policy.evictionPreferences.protectRecent || \n         Date.now() - m.createdAt > 5000)\n      );\n    \n    // Sort by policy\n    candidates.sort((a, b) => {\n      if (policy.evictionPreferences.protectFrequent) {\n        if (a.accessCount !== b.accessCount) {\n          return a.accessCount - b.accessCount;\n        }\n      }\n      \n      if (policy.overflowPolicy === 'evict-oldest') {\n        return a.createdAt - b.createdAt;\n      } else {\n        return a.lastAccessedAt - b.lastAccessedAt;\n      }\n    });\n    \n    let freedBytes = 0;\n    const toEvict: string[] = [];\n    \n    for (const metadata of candidates) {\n      toEvict.push(metadata.key);\n      freedBytes += metadata.sizeBytes;\n      \n      if (freedBytes >= requiredBytes) break;\n    }\n    \n    if (freedBytes < requiredBytes) return false;\n    \n    for (const key of toEvict) {\n      const entry = this.memoryCache.get(key)!;\n      await this.storeInIndexedDB(key, JSON.stringify(entry.data), entry.sizeBytes, policy);\n      \n      this.memoryCache.delete(key);\n      this.memoryCacheSize -= entry.sizeBytes;\n      \n      const metadata = this.artifactIndex.get(key);\n      if (metadata) {\n        metadata.tier = 'indexeddb';\n      }\n    }\n    \n    return true;\n  }\n  \n  private async storeInIndexedDB(\n    key: string, \n    serialized: string, \n    sizeBytes: number,\n    policy: WorkflowStoragePolicy\n  ): Promise<void> {\n    \n    if (this.indexedDBSize + sizeBytes > policy.indexedDBMaxBytes) {\n      await this.handleIndexedDBOverflow(key, serialized, sizeBytes, policy);\n      return;\n    }\n    \n    const shouldCompress = sizeBytes > 1024 * 1024;\n    const toStore = shouldCompress \n      ? await this.compress(serialized)\n      : serialized;\n    \n    const actualSize = shouldCompress \n      ? new TextEncoder().encode(toStore).length \n      : sizeBytes;\n    \n    const tx = this.indexedDB.transaction('artifacts', 'readwrite');\n    await tx.objectStore('artifacts').put({\n      key,\n      data: toStore,\n      compressed: shouldCompress,\n      sizeBytes: actualSize,\n      storedAt: Date.now()\n    });\n    \n    this.indexedDBSize += actualSize;\n  }\n  \n  private async handleIndexedDBOverflow(\n    key: string, \n    serialized: string, \n    sizeBytes: number,\n    policy: WorkflowStoragePolicy\n  ): Promise<void> {\n    \n    switch (policy.overflowPolicy) {\n      case 'evict-lru':\n      case 'evict-oldest':\n        await this.evictFromIndexedDB(sizeBytes, policy);\n        await this.storeInIndexedDB(key, serialized, sizeBytes, policy);\n        break;\n        \n      case 'fail':\n        throw new StorageFullError(\n          `Storage full for workflow: ${policy.workflowId}`,\n          this.getStorageStats()\n        );\n        \n      case 'compress':\n        const compressed = await this.compress(serialized);\n        const compressedSize = new TextEncoder().encode(compressed).length;\n        \n        if (this.indexedDBSize + compressedSize > policy.indexedDBMaxBytes) {\n          await this.evictFromIndexedDB(compressedSize, policy);\n        }\n        \n        const tx = this.indexedDB.transaction('artifacts', 'readwrite');\n        await tx.objectStore('artifacts').put({\n          key,\n          data: compressed,\n          compressed: true,\n          sizeBytes: compressedSize,\n          storedAt: Date.now()\n        });\n        \n        this.indexedDBSize += compressedSize;\n        break;\n        \n      case 'external':\n        const blob = new Blob([await this.compress(serialized)]);\n        const blobUrl = URL.createObjectURL(blob);\n        \n        this.externalBlobs.set(key, blobUrl);\n        \n        const tx2 = this.indexedDB.transaction('blobRefs', 'readwrite');\n        await tx2.objectStore('blobRefs').put({\n          key,\n          blobUrl,\n          sizeBytes,\n          storedAt: Date.now()\n        });\n        \n        const metadata = this.artifactIndex.get(key);\n        if (metadata) {\n          metadata.tier = 'external';\n        }\n        break;\n    }\n  }\n  \n  private async evictFromIndexedDB(\n    requiredBytes: number,\n    policy: WorkflowStoragePolicy\n  ): Promise<void> {\n    \n    const candidates = Array.from(this.artifactIndex.values())\n      .filter(m => \n        m.tier === 'indexeddb' &&\n        (!policy.evictionPreferences.protectPinned || !m.pinned) &&\n        m.workflowId === policy.workflowId  // Only evict from same workflow\n      );\n    \n    candidates.sort((a, b) => {\n      if (policy.evictionPreferences.protectFrequent) {\n        if (a.accessCount !== b.accessCount) {\n          return a.accessCount - b.accessCount;\n        }\n      }\n      \n      if (policy.overflowPolicy === 'evict-oldest') {\n        return a.createdAt - b.createdAt;\n      } else {\n        return a.lastAccessedAt - b.lastAccessedAt;\n      }\n    });\n    \n    let freedBytes = 0;\n    const toDelete: string[] = [];\n    \n    for (const metadata of candidates) {\n      toDelete.push(metadata.key);\n      freedBytes += metadata.sizeBytes;\n      \n      if (freedBytes >= requiredBytes) break;\n    }\n    \n    if (toDelete.length === 0) {\n      throw new Error('Cannot evict: all items protected or wrong workflow');\n    }\n    \n    const txDelete = this.indexedDB.transaction('artifacts', 'readwrite');\n    const storeDelete = txDelete.objectStore('artifacts');\n    \n    for (const key of toDelete) {\n      await storeDelete.delete(key);\n      const metadata = this.artifactIndex.get(key);\n      if (metadata) {\n        this.indexedDBSize -= metadata.sizeBytes;\n      }\n      this.artifactIndex.delete(key);\n    }\n  }\n  \n  async retrieve(key: string): Promise<any> {\n    const metadata = this.artifactIndex.get(key);\n    if (!metadata) {\n      throw new Error(`Artifact not found: ${key}`);\n    }\n    \n    metadata.accessCount++;\n    metadata.lastAccessedAt = Date.now();\n    \n    switch (metadata.tier) {\n      case 'memory':\n        return this.memoryCache.get(key)?.data;\n        \n      case 'indexeddb':\n        return await this.retrieveFromIndexedDB(key);\n        \n      case 'session':\n        const sessionData = this.sessionStorage.getItem(key);\n        return sessionData ? JSON.parse(sessionData) : null;\n        \n      case 'external':\n        return await this.retrieveFromExternalBlob(key);\n        \n      default:\n        throw new Error(`Unknown tier: ${metadata.tier}`);\n    }\n  }\n  \n  private async retrieveFromIndexedDB(key: string): Promise<any> {\n    const tx = this.indexedDB.transaction('artifacts', 'readonly');\n    const record = await tx.objectStore('artifacts').get(key);\n    \n    if (!record) {\n      throw new Error(`Artifact not in IndexedDB: ${key}`);\n    }\n    \n    const serialized = record.compressed\n      ? await this.decompress(record.data)\n      : record.data;\n    \n    return JSON.parse(serialized);\n  }\n  \n  private async retrieveFromExternalBlob(key: string): Promise<any> {\n    const blobUrl = this.externalBlobs.get(key);\n    if (!blobUrl) {\n      throw new Error(`External blob not found: ${key}`);\n    }\n    \n    const response = await fetch(blobUrl);\n    const compressed = await response.text();\n    const serialized = await this.decompress(compressed);\n    return JSON.parse(serialized);\n  }\n  \n  async pin(key: string): Promise<void> {\n    const metadata = this.artifactIndex.get(key);\n    if (metadata) {\n      metadata.pinned = true;\n    }\n  }\n  \n  async unpin(key: string): Promise<void> {\n    const metadata = this.artifactIndex.get(key);\n    if (metadata) {\n      metadata.pinned = false;\n    }\n  }\n  \n  private async compress(data: string): Promise<string> {\n    const stream = new Blob([data]).stream();\n    const compressed = stream.pipeThrough(new CompressionStream('gzip'));\n    const buffer = await new Response(compressed).arrayBuffer();\n    \n    const uint8 = new Uint8Array(buffer);\n    return btoa(String.fromCharCode(...uint8));\n  }\n  \n  private async decompress(data: string): Promise<string> {\n    const binary = atob(data);\n    const uint8 = new Uint8Array(binary.length);\n    for (let i = 0; i < binary.length; i++) {\n      uint8[i] = binary.charCodeAt(i);\n    }\n    \n    const stream = new Blob([uint8]).stream();\n    const decompressed = stream.pipeThrough(new DecompressionStream('gzip'));\n    return await new Response(decompressed).text();\n  }\n  \n  private async initIndexedDB(): Promise<void> {\n    return new Promise((resolve, reject) => {\n      const request = indexedDB.open('WorkflowStorage', 4);\n      \n      request.onerror = () => reject(request.error);\n      request.onsuccess = () => {\n        this.indexedDB = request.result;\n        this.calculateIndexedDBSize();\n        resolve();\n      };\n      \n      request.onupgradeneeded = (event) => {\n        const db = (event.target as IDBOpenDBRequest).result;\n        \n        if (!db.objectStoreNames.contains('artifacts')) {\n          const store = db.createObjectStore('artifacts', { keyPath: 'key' });\n          store.createIndex('storedAt', 'storedAt', { unique: false });\n          store.createIndex('workflowId', 'workflowId', { unique: false });\n        }\n        \n        if (!db.objectStoreNames.contains('blobRefs')) {\n          db.createObjectStore('blobRefs', { keyPath: 'key' });\n        }\n      };\n    });\n  }\n  \n  private async calculateIndexedDBSize(): Promise<void> {\n    const tx = this.indexedDB.transaction('artifacts', 'readonly');\n    const store = tx.objectStore('artifacts');\n    let cursor = await store.openCursor();\n    \n    let totalSize = 0;\n    while (cursor) {\n      totalSize += cursor.value.sizeBytes || 0;\n      cursor = await cursor.continue();\n    }\n    \n    this.indexedDBSize = totalSize;\n  }\n  \n  private restoreFromSession(): void {\n    // Restore critical workflow state from session storage\n    const keys = Object.keys(this.sessionStorage);\n    \n    for (const key of keys) {\n      if (key.startsWith('workflow-')) {\n        const metadata: ArtifactMetadata = {\n          key,\n          sizeBytes: this.sessionStorage.getItem(key)!.length,\n          tier: 'session',\n          createdAt: Date.now(),\n          lastAccessedAt: Date.now(),\n          accessCount: 0,\n          temporary: false,\n          pinned: true,\n          dataType: 'json'\n        };\n        \n        this.artifactIndex.set(key, metadata);\n      }\n    }\n  }\n  \n  getStorageStats(workflowId?: string): StorageStats {\n    const stats = {\n      memory: { count: 0, bytes: this.memoryCacheSize },\n      indexeddb: { count: 0, bytes: this.indexedDBSize },\n      session: { count: 0, bytes: 0 },\n      external: { count: 0, bytes: 0 },\n      total: { count: this.artifactIndex.size, bytes: 0 }\n    };\n    \n    for (const metadata of this.artifactIndex.values()) {\n      if (workflowId && metadata.workflowId !== workflowId) continue;\n      \n      stats[metadata.tier as keyof typeof stats].count++;\n      stats.total.bytes += metadata.sizeBytes;\n    }\n    \n    return stats;\n  }\n}\n\ninterface CacheEntry {\n  data: any;\n  sizeBytes: number;\n  storedAt: number;\n}\n\ninterface StorageHints {\n  temporary?: boolean;\n  pinned?: boolean;\n  nodeId?: string;\n  executionId?: string;\n  workflowId?: string;\n  dataType?: 'stream-ref' | 'materialized' | 'blob' | 'json';\n  useSessionStorage?: boolean;\n}\n\ninterface ArtifactMetadata {\n  key: string;\n  sizeBytes: number;\n  tier: 'memory' | 'indexeddb' | 'session' | 'external' | 'determining';\n  createdAt: number;\n  lastAccessedAt: number;\n  accessCount: number;\n  temporary: boolean;\n  pinned: boolean;\n  nodeId?: string;\n  executionId?: string;\n  workflowId?: string;\n  dataType: 'stream-ref' | 'materialized' | 'blob' | 'json';\n}\n\ninterface StorageStats {\n  memory: { count: number; bytes: number };\n  indexeddb: { count: number; bytes: number };\n  session: { count: number; bytes: number };\n  external: { count: number; bytes: number };\n  total: { count: number; bytes: number };\n}\n\nclass StorageFullError extends Error {\n  constructor(message: string, public stats: StorageStats) {\n    super(message);\n    this.name = 'StorageFullError';\n  }\n}\n```\n\n## Visual-Text Hybrid Expression Editor\n\n### Key Innovation: Rich Text Editor with Inline Block Components\n\n```typescript\ninterface HybridExpression {\n  mode: 'hybrid';\n  content: EditorContent[];  // Prosemirror-style content\n  rawText: string;           // Plain text with markers (for serialization)\n}\n\ntype EditorContent = TextNode | BlockNode;\n\ninterface TextNode {\n  type: 'text';\n  text: string;\n}\n\ninterface BlockNode {\n  type: 'block';\n  blockType: 'field' | 'filter' | 'map' | 'aggregate' | 'transform';\n  config: Record<string, any>;\n  displayText: string;  // Human-readable representation\n}\n\nclass HybridExpressionEditor {\n  private engine: ComposableExpressionEngine;\n  \n  constructor() {\n    this.engine = new ComposableExpressionEngine();\n  }\n  \n  parseFromText(text: string): HybridExpression {\n    const content: EditorContent[] = [];\n    const blockMarkerRegex = /\\{\\{block:([^:}]+):([^}]+)\\}\\}/g;\n    \n    let lastIndex = 0;\n    const matches = text.matchAll(blockMarkerRegex);\n    \n    for (const match of matches) {\n      // Add text before block\n      if (match.index! > lastIndex) {\n        const textPart = text.slice(lastIndex, match.index);\n        if (textPart) {\n          content.push({ type: 'text', text: textPart });\n        }\n      }\n      \n      // Parse block\n      const [_, blockType, configStr] = match;\n      const config = this.parseBlockConfig(blockType, configStr);\n      const displayText = this.generateDisplayText(blockType, config);\n      \n      content.push({\n        type: 'block',\n        blockType: blockType as any,\n        config,\n        displayText\n      });\n      \n      lastIndex = match.index! + match[0].length;\n    }\n    \n    // Add remaining text\n    if (lastIndex < text.length) {\n      content.push({ type: 'text', text: text.slice(lastIndex) });\n    }\n    \n    return {\n      mode: 'hybrid',\n      content,\n      rawText: text\n    };\n  }\n  \n  serializeToText(expression: HybridExpression): string {\n    return expression.content.map(node => {\n      if (node.type === 'text') {\n        return node.text;\n      } else {\n        const configStr = this.serializeBlockConfig(node.blockType, node.config);\n        return `{{block:${node.blockType}:${configStr}}}`;\n      }\n    }).join('');\n  }\n  \n  private parseBlockConfig(type: string, configStr: string): Record<string, any> {\n    const pairs = configStr.split(':');\n    \n    switch (type) {\n      case 'field':\n        return { path: pairs[0] };\n      case 'filter':\n        return { condition: pairs[0] };\n      case 'aggregate':\n        return { function: pairs[0], path: pairs[1] || '' };\n      case 'map':\n        return { expression: pairs[0] };\n      case 'transform':\n        return { operation: pairs[0] };\n      default:\n        return {};\n    }\n  }\n  \n  private serializeBlockConfig(type: string, config: Record<string, any>): string {\n    switch (type) {\n      case 'field':\n        return config.path;\n      case 'filter':\n        return config.condition;\n      case 'aggregate':\n        return `${config.function}:${config.path}`;\n      case 'map':\n        return config.expression;\n      case 'transform':\n        return config.operation;\n      default:\n        return '';\n    }\n  }\n  \n  private generateDisplayText(type: string, config: Record<string, any>): string {\n    switch (type) {\n      case 'field':\n        return `$.${config.path}`;\n      case 'filter':\n        return `[${config.condition}]`;\n      case 'aggregate':\n        return `${config.function}(${config.path})`;\n      case 'map':\n        return `map(${config.expression})`;\n      case 'transform':\n        return config.operation;\n      default:\n        return 'block';\n    }\n  }\n  \n  insertBlock(\n    expression: HybridExpression, \n    cursorPosition: number,\n    blockType: string,\n    config: Record<string, any>\n  ): HybridExpression {\n    \n    const displayText = this.generateDisplayText(blockType, config);\n    const blockNode: BlockNode = {\n      type: 'block',\n      blockType: blockType as any,\n      config,\n      displayText\n    };\n    \n    // Find position in content array\n    let currentPos = 0;\n    let insertIndex = 0;\n    \n    for (let i = 0; i < expression.content.length; i++) {\n      const node = expression.content[i];\n      const nodeLength = node.type === 'text' \n        ? node.text.length \n        : node.displayText.length;\n      \n      if (currentPos + nodeLength >= cursorPosition) {\n        insertIndex = i + 1;\n        break;\n      }\n      \n      currentPos += nodeLength;\n    }\n    \n    const newContent = [\n      ...expression.content.slice(0, insertIndex),\n      blockNode,\n      ...expression.content.slice(insertIndex)\n    ];\n    \n    return {\n      mode: 'hybrid',\n      content: newContent,\n      rawText: this.serializeToText({ ...expression, content: newContent })\n    };\n  }\n  \n  removeBlock(expression: HybridExpression, blockIndex: number): HybridExpression {\n    const newContent = expression.content.filter((_, i) => i !== blockIndex);\n    \n    return {\n      mode: 'hybrid',\n      content: newContent,\n      rawText: this.serializeToText({ ...expression, content: newContent })\n    };\n  }\n  \n  updateBlock(\n    expression: HybridExpression, \n    blockIndex: number,\n    newConfig: Record<string, any>\n  ): HybridExpression {\n    \n    const node = expression.content[blockIndex];\n    if (node.type !== 'block') {\n      throw new Error('Node is not a block');\n    }\n    \n    const updatedNode: BlockNode = {\n      ...node,\n      config: newConfig,\n      displayText: this.generateDisplayText(node.blockType, newConfig)\n    };\n    \n    const newContent = [\n      ...expression.content.slice(0, blockIndex),\n      updatedNode,\n      ...expression.content.slice(blockIndex + 1)\n    ];\n    \n    return {\n      mode: 'hybrid',\n      content: newContent,\n      rawText: this.serializeToText({ ...expression, content: newContent })\n    };\n  }\n}\n\n// React Component\nconst HybridExpressionEditorUI: React.FC<{\n  value: HybridExpression;\n  onChange: (value: HybridExpression) => void;\n}> = ({ value, onChange }) => {\n  \n  const editor = useMemo(() => new HybridExpressionEditor(), []);\n  const [cursorPosition, setCursorPosition] = useState(0);\n  const [selectedBlockIndex, setSelectedBlockIndex] = useState<number | null>(null);\n  const editorRef = useRef<HTMLDivElement>(null);\n  \n  const handleInsertBlock = (blockType: string) => {\n    const defaultConfig = getDefaultBlockConfig(blockType);\n    const updated = editor.insertBlock(value, cursorPosition, blockType, defaultConfig);\n    onChange(updated);\n  };\n  \n  const handleRemoveBlock = (blockIndex: number) => {\n    const updated = editor.removeBlock(value, blockIndex);\n    onChange(updated);\n    setSelectedBlockIndex(null);\n  };\n  \n  const handleUpdateBlock = (blockIndex: number, newConfig: Record<string, any>) => {\n    const updated = editor.updateBlock(value, blockIndex, newConfig);\n    onChange(updated);\n  };\n  \n  const handleTextChange = (newText: string) => {\n    const parsed = editor.parseFromText(newText);\n    onChange(parsed);\n  };\n  \n  return (\n    <div className=\"hybrid-expression-editor\">\n      {/* Block Palette */}\n      <div className=\"block-palette\">\n        <button onClick={() => handleInsertBlock('field')}>\n          <span className=\"icon\">\ud83d\udcc4</span> Field\n        </button>\n        <button onClick={() => handleInsertBlock('filter')}>\n          <span className=\"icon\">\ud83d\udd0d</span> Filter\n        </button>\n        <button onClick={() => handleInsertBlock('aggregate')}>\n          <span className=\"icon\">\u03a3</span> Aggregate\n        </button>\n        <button onClick={() => handleInsertBlock('map')}>\n          <span className=\"icon\">\ud83d\uddfa\ufe0f</span> Map\n        </button>\n        <button onClick={() => handleInsertBlock('transform')}>\n          <span className=\"icon\">\u2699\ufe0f</span> Transform\n        </button>\n      </div>\n      \n      {/* Rich Text Editor */}\n      <div \n        ref={editorRef}\n        className=\"editor-content\"\n        contentEditable\n        suppressContentEditableWarning\n        onInput={(e) => {\n          const text = e.currentTarget.textContent || '';\n          handleTextChange(text);\n        }}\n        onSelect={() => {\n          const selection = window.getSelection();\n          if (selection) {\n            setCursorPosition(selection.anchorOffset);\n          }\n        }}\n      >\n        {value.content.map((node, index) => {\n          if (node.type === 'text') {\n            return <span key={index}>{node.text}</span>;\n          } else {\n            return (\n              <BlockComponent\n                key={index}\n                node={node}\n                selected={selectedBlockIndex === index}\n                onSelect={() => setSelectedBlockIndex(index)}\n                onRemove={() => handleRemoveBlock(index)}\n                onUpdate={(config) => handleUpdateBlock(index, config)}\n              />\n            );\n          }\n        })}\n      </div>\n      \n      {/* Block Config Panel (when block selected) */}\n      {selectedBlockIndex !== null && value.content[selectedBlockIndex].type === 'block' && (\n        <BlockConfigPanel\n          blockNode={value.content[selectedBlockIndex] as BlockNode}\n          onUpdate={(config) => handleUpdateBlock(selectedBlockIndex, config)}\n          onClose={() => setSelectedBlockIndex(null)}\n        />\n      )}\n      \n      {/* Raw Text View (toggle) */}\n      <details className=\"raw-text-view\">\n        <summary>View Raw Text</summary>\n        <textarea \n          value={value.rawText}\n          onChange={(e) => handleTextChange(e.target.value)}\n          className=\"raw-text-editor\"\n        />\n      </details>\n    </div>\n  );\n};\n\nconst BlockComponent: React.FC<{\n  node: BlockNode;\n  selected: boolean;\n  onSelect: () => void;\n  onRemove: () => void;\n  onUpdate: (config: Record<string, any>) => void;\n}> = ({ node, selected, onSelect, onRemove, onUpdate }) => {\n  \n  const getBlockIcon = (type: string) => {\n    switch (type) {\n      case 'field': return '\ud83d\udcc4';\n      case 'filter': return '\ud83d\udd0d';\n      case 'aggregate': return '\u03a3';\n      case 'map': return '\ud83d\uddfa\ufe0f';\n      case 'transform': return '\u2699\ufe0f';\n      default: return '\ud83e\udde9';\n    }\n  };\n  \n  return (\n    <span \n      className={`expression-block ${selected ? 'selected' : ''}`}\n      onClick={onSelect}\n      contentEditable={false}\n    >\n      <span className=\"block-icon\">{getBlockIcon(node.blockType)}</span>\n      <span className=\"block-text\">{node.displayText}</span>\n      <button className=\"block-remove\" onClick={onRemove}>\u00d7</button>\n    </span>\n  );\n};\n\nconst BlockConfigPanel: React.FC<{\n  blockNode: BlockNode;\n  onUpdate: (config: Record<string, any>) => void;\n  onClose: () => void;\n}> = ({ blockNode, onUpdate, onClose }) => {\n  \n  const [config, setConfig] = useState(blockNode.config);\n  \n  const handleSave = () => {\n    onUpdate(config);\n    onClose();\n  };\n  \n  return (\n    <div className=\"block-config-panel\">\n      <div className=\"panel-header\">\n        <h4>Configure {blockNode.blockType}</h4>\n        <button onClick={onClose}>\u00d7</button>\n      </div>\n      \n      <div className=\"panel-body\">\n        {blockNode.blockType === 'field' && (\n          <label>\n            Path:\n            <input \n              type=\"text\"\n              value={config.path || ''}\n              onChange={(e) => setConfig({ ...config, path: e.target.value })}\n            />\n          </label>\n        )}\n        \n        {blockNode.blockType === 'filter' && (\n          <label>\n            Condition:\n            <input \n              type=\"text\"\n              value={config.condition || ''}\n              onChange={(e) => setConfig({ ...config, condition: e.target.value })}\n              placeholder=\"e.g., age > 18\"\n            />\n          </label>\n        )}\n        \n        {blockNode.blockType === 'aggregate' && (\n          <>\n            <label>\n              Function:\n              <select \n                value={config.function || 'sum'}\n                onChange={(e) => setConfig({ ...config, function: e.target.value })}\n              >\n                <option value=\"sum\">Sum</option>\n                <option value=\"avg\">Average</option>\n                <option value=\"count\">Count</option>\n                <option value=\"min\">Min</option>\n                <option value=\"max\">Max</option>\n              </select>\n            </label>\n            <label>\n              Path:\n              <input \n                type=\"text\"\n                value={config.path || ''}\n                onChange={(e) => setConfig({ ...config, path: e.target.value })}\n              />\n            </label>\n          </>\n        )}\n        \n        {blockNode.blockType === 'map' && (\n          <label>\n            Expression:\n            <input \n              type=\"text\"\n              value={config.expression || ''}\n              onChange={(e) => setConfig({ ...config, expression: e.target.value })}\n              placeholder=\"e.g., name & ' ' & email\"\n            />\n          </label>\n        )}\n        \n        {blockNode.blockType === 'transform' && (\n          <label>\n            Operation:\n            <select \n              value={config.operation || 'uppercase'}\n              onChange={(e) => setConfig({ ...config, operation: e.target.value })}\n            >\n              <option value=\"uppercase\">Uppercase</option>\n              <option value=\"lowercase\">Lowercase</option>\n              <option value=\"trim\">Trim</option>\n              <option value=\"reverse\">Reverse</option>\n            </select>\n          </label>\n        )}\n      </div>\n      \n      <div className=\"panel-footer\">\n        <button onClick={handleSave}>Save</button>\n        <button onClick={onClose}>Cancel</button>\n      </div>\n    </div>\n  );\n};\n\nfunction getDefaultBlockConfig(blockType: string): Record<string, any> {\n  switch (blockType) {\n    case 'field':\n      return { path: '' };\n    case 'filter':\n      return { condition: '' };\n    case 'aggregate':\n      return { function: 'sum', path: '' };\n    case 'map':\n      return { expression: '' };\n    case 'transform':\n      return { operation: 'uppercase' };\n    default:\n      return {};\n  }\n}\n```\n\n## Sandboxed Compensation Handlers with Trust Levels\n\n### Key Innovation: CSP-Based Sandboxing + Trust Verification\n\n```typescript\ntype TrustLevel = 'system' | 'verified' | 'user' | 'untrusted';\n\ninterface CompensationHandlerConfig {\n  id: string;\n  name: string;\n  trustLevel: TrustLevel;\n  author?: string;\n  verified?: boolean;\n  \n  handlerType: 'builtin' | 'http-api' | 'webhook' | 'custom';\n  \n  matches: {\n    operation?: string[];\n    description?: string[];\n    service?: string[];\n  };\n  \n  compensation: \n    | { type: 'http-api'; config: HttpApiConfig }\n    | { type: 'webhook'; config: WebhookConfig }\n    | { type: 'custom'; workerUrl: string }  // Sandboxed Web Worker\n    | { type: 'manual'; steps: string[] };\n}\n\ninterface HttpApiConfig {\n  method: 'GET' | 'POST' | 'DELETE' | 'PUT';\n  urlTemplate: string;\n  allowedDomains: string[];  // Whitelist of domains this handler can call\n  headers: Record<string, string>;\n  bodyTemplate: string;\n  auth?: {\n    type: 'bearer' | 'basic' | 'api-key';\n    tokenPath: string;\n  };\n}\n\ninterface WebhookConfig {\n  url: string;\n  allowedDomains: string[];\n  method: 'POST' | 'PUT';\n  payloadTemplate: string;\n}\n\nclass SandboxedCompensationHandlerRegistry {\n  private handlers: Map<string, CompensationHandler> = new Map();\n  private configs: Map<string, CompensationHandlerConfig> = new Map();\n  private trustedDomains: Set<string> = new Set(['api.stripe.com', 'hooks.slack.com']);\n  \n  // User approval tracking\n  private approvedHandlers: Set<string> = new Set();\n  \n  constructor() {\n    this.loadApprovedHandlers();\n  }\n  \n  async registerFromConfig(\n    config: CompensationHandlerConfig,\n    requireApproval: boolean = true\n  ): Promise<boolean> {\n    \n    // Check trust level\n    if (requireApproval && config.trustLevel === 'untrusted') {\n      const approved = await this.requestUserApproval(config);\n      if (!approved) {\n        return false;\n      }\n      this.approvedHandlers.add(config.id);\n      this.persistApprovedHandlers();\n    }\n    \n    // Validate config\n    const validation = this.validateConfig(config);\n    if (!validation.valid) {\n      throw new Error(`Invalid handler config: ${validation.error}`);\n    }\n    \n    this.configs.set(config.id, config);\n    \n    const handler = await this.createHandlerFromConfig(config);\n    this.handlers.set(config.id, handler);\n    \n    return true;\n  }\n  \n  private validateConfig(config: CompensationHandlerConfig): { valid: boolean; error?: string } {\n    // Validate HTTP API config\n    if (config.compensation.type === 'http-api') {\n      const httpConfig = config.compensation.config;\n      \n      // Check URL against allowed domains\n      const url = new URL(httpConfig.urlTemplate.replace(/\\{\\{[^}]+\\}\\}/g, 'placeholder'));\n      \n      if (!httpConfig.allowedDomains.includes(url.hostname)) {\n        return {\n          valid: false,\n          error: `Domain ${url.hostname} not in allowedDomains list`\n        };\n      }\n      \n      // For untrusted handlers, require domain to be explicitly trusted\n      if (config.trustLevel === 'untrusted' && !this.trustedDomains.has(url.hostname)) {\n        return {\n          valid: false,\n          error: `Domain ${url.hostname} not in trusted domains list`\n        };\n      }\n    }\n    \n    // Validate webhook config\n    if (config.compensation.type === 'webhook') {\n      const webhookConfig = config.compensation.config;\n      const url = new URL(webhookConfig.url);\n      \n      if (!webhookConfig.allowedDomains.includes(url.hostname)) {\n        return {\n          valid: false,\n          error: `Webhook domain ${url.hostname} not in allowedDomains list`\n        };\n      }\n    }\n    \n    // Validate custom handler\n    if (config.compensation.type === 'custom') {\n      // Custom handlers must use data: URLs or trusted origins\n      const workerUrl = config.compensation.workerUrl;\n      \n      if (!workerUrl.startsWith('data:') && !workerUrl.startsWith('blob:')) {\n        return {\n          valid: false,\n          error: 'Custom handlers must use data: or blob: URLs for security'\n        };\n      }\n    }\n    \n    return { valid: true };\n  }\n  \n  private async requestUserApproval(\n    config: CompensationHandlerConfig\n  ): Promise<boolean> {\n    \n    return new Promise((resolve) => {\n      // Show modal to user\n      const modal = document.createElement('div');\n      modal.className = 'approval-modal';\n      modal.innerHTML = `\n        <div class=\"modal-content\">\n          <h3>\u26a0\ufe0f Handler Approval Required</h3>\n          <p>The handler \"${config.name}\" wants to perform compensations.</p>\n          \n          <div class=\"handler-details\">\n            <p><strong>Trust Level:</strong> ${config.trustLevel}</p>\n            <p><strong>Author:</strong> ${config.author || 'Unknown'}</p>\n            <p><strong>Type:</strong> ${config.compensation.type}</p>\n            \n            ${config.compensation.type === 'http-api' ? `\n              <p><strong>Will call:</strong> ${config.compensation.config.urlTemplate}</p>\n              <p><strong>Allowed domains:</strong> ${config.compensation.config.allowedDomains.join(', ')}</p>\n            ` : ''}\n            \n            ${config.compensation.type === 'webhook' ? `\n              <p><strong>Webhook URL:</strong> ${config.compensation.config.url}</p>\n            ` : ''}\n          </div>\n          \n          <p class=\"warning\">This handler will be able to make HTTP requests on your behalf. Only approve if you trust the source.</p>\n          \n          <div class=\"modal-actions\">\n            <button id=\"approve-btn\">Approve</button>\n            <button id=\"deny-btn\">Deny</button>\n          </div>\n        </div>\n      `;\n      \n      document.body.appendChild(modal);\n      \n      modal.querySelector('#approve-btn')?.addEventListener('click', () => {\n        document.body.removeChild(modal);\n        resolve(true);\n      });\n      \n      modal.querySelector('#deny-btn')?.addEventListener('click', () => {\n        document.body.removeChild(modal);\n        resolve(false);\n      });\n    });\n  }\n  \n  private async createHandlerFromConfig(\n    config: CompensationHandlerConfig\n  ): Promise<CompensationHandler> {\n    \n    return {\n      name: config.name,\n      \n      canHandle: (entry: SideEffectEntry) => {\n        const { matches } = config;\n        \n        if (matches.operation && !matches.operation.includes(entry.operation)) {\n          return false;\n        }\n        \n        if (matches.description) {\n          const descMatch = matches.description.some(pattern => \n            new RegExp(pattern).test(entry.description)\n          );\n          if (!descMatch) return false;\n        }\n        \n        if (matches.service) {\n          const descriptor = entry.compensation as any;\n          if (!matches.service.includes(descriptor.service)) {\n            return false;\n          }\n        }\n        \n        return true;\n      },\n      \n      compensate: async (entry: SideEffectEntry) => {\n        switch (config.compensation.type) {\n          case 'http-api':\n            return this.compensateViaHttpApi(entry, config.compensation.config, config.trustLevel);\n            \n          case 'webhook':\n            return this.compensateViaWebhook(entry, config.compensation.config, config.trustLevel);\n            \n          case 'custom':\n            return this.compensateViaCustomWorker(entry, config.compensation.workerUrl);\n            \n          case 'manual':\n            return {\n              success: false,\n              requiresUserAction: true,\n              manualSteps: config.compensation.steps\n            };\n            \n          default:\n            throw new Error(`Unknown compensation type`);\n        }\n      }\n    };\n  }\n  \n  private async compensateViaHttpApi(\n    entry: SideEffectEntry,\n    config: HttpApiConfig,\n    trustLevel: TrustLevel\n  ): Promise<CompensationResult> {\n    \n    const descriptor = entry.compensation as any;\n    \n    // Resolve URL\n    const url = this.resolveTemplate(config.urlTemplate, {\n      ...descriptor,\n      effectId: entry.id\n    });\n    \n    // Security check: Verify URL domain\n    const urlObj = new URL(url);\n    if (!config.allowedDomains.includes(urlObj.hostname)) {\n      return {\n        success: false,\n        error: `Security: Domain ${urlObj.hostname} not allowed`,\n        requiresUserAction: true,\n        manualSteps: ['Manually compensate this effect', `URL attempted: ${url}`]\n      };\n    }\n    \n    // Build request\n    const headers = { ...config.headers };\n    \n    if (config.auth) {\n      const token = this.extractValue(descriptor, config.auth.tokenPath);\n      switch (config.auth.type) {\n        case 'bearer':\n          headers['Authorization'] = `Bearer ${token}`;\n          break;\n        case 'api-key':\n          headers['Authorization'] = token;\n          break;\n      }\n    }\n    \n    const body = config.bodyTemplate\n      ? this.resolveTemplate(config.bodyTemplate, descriptor)\n      : undefined;\n    \n    try {\n      const response = await fetch(url, {\n        method: config.method,\n        headers,\n        body: body ? JSON.stringify(JSON.parse(body)) : undefined\n      });\n      \n      if (!response.ok) {\n        throw new Error(`HTTP ${response.status}: ${response.statusText}`);\n      }\n      \n      return {\n        success: true,\n        message: `Compensated via ${config.method} ${url}`\n      };\n      \n    } catch (error: any) {\n      return {\n        success: false,\n        error: error.message,\n        requiresUserAction: true,\n        manualSteps: [\n          `Failed to compensate via API: ${error.message}`,\n          `Operation: ${entry.description}`,\n          'Please manually revert'\n        ]\n      };\n    }\n  }\n  \n  private async compensateViaWebhook(\n    entry: SideEffectEntry,\n    config: WebhookConfig,\n    trustLevel: TrustLevel\n  ): Promise<CompensationResult> {\n    \n    const descriptor = entry.compensation as any;\n    \n    // Security check\n    const urlObj = new URL(config.url);\n    if (!config.allowedDomains.includes(urlObj.hostname)) {\n      return {\n        success: false,\n        error: `Security: Webhook domain ${urlObj.hostname} not allowed`\n      };\n    }\n    \n    const payload = this.resolveTemplate(config.payloadTemplate, {\n      ...descriptor,\n      effectId: entry.id,\n      effectDescription: entry.description\n    });\n    \n    try {\n      const response = await fetch(config.url, {\n        method: config.method,\n        headers: { 'Content-Type': 'application/json' },\n        body: payload\n      });\n      \n      if (!response.ok) {\n        throw new Error(`Webhook failed: ${response.statusText}`);\n      }\n      \n      return {\n        success: true,\n        message: `Webhook triggered: ${config.url}`\n      };\n      \n    } catch (error: any) {\n      return {\n        success: false,\n        error: error.message\n      };\n    }\n  }\n  \n  private async compensateViaCustomWorker(\n    entry: SideEffectEntry,\n    workerUrl: string\n  ): Promise<CompensationResult> {\n    \n    return new Promise((resolve) => {\n      const worker = new Worker(workerUrl);\n      \n      const timeout = setTimeout(() => {\n        worker.terminate();\n        resolve({\n          success: false,\n          error: 'Custom handler timeout'\n        });\n      }, 10000);\n      \n      worker.onmessage = (event) => {\n        clearTimeout(timeout);\n        worker.terminate();\n        resolve(event.data);\n      };\n      \n      worker.onerror = (error) => {\n        clearTimeout(timeout);\n        worker.terminate();\n        resolve({\n          success: false,\n          error: `Worker error: ${error.message}`\n        });\n      };\n      \n      worker.postMessage({\n        entry,\n        descriptor: entry.compensation\n      });\n    });\n  }\n  \n  private resolveTemplate(template: string, data: any): string {\n    return template.replace(/\\{\\{([^}]+)\\}\\}/g, (_, path) => {\n      return this.extractValue(data, path) ?? '';\n    });\n  }\n  \n  private extractValue(obj: any, path: string): any {\n    const parts = path.split('.');\n    let result = obj;\n    for (const part of parts) {\n      result = result?.[part];\n    }\n    return result;\n  }\n  \n  private loadApprovedHandlers(): void {\n    const stored = localStorage.getItem('approvedHandlers');\n    if (stored) {\n      this.approvedHandlers = new Set(JSON.parse(stored));\n    }\n  }\n  \n  private persistApprovedHandlers(): void {\n    localStorage.setItem('approvedHandlers', JSON.stringify([...this.approvedHandlers]));\n  }\n  \n  serializeConfigs(): CompensationHandlerConfig[] {\n    return Array.from(this.configs.values());\n  }\n  \n  loadConfigs(configs: CompensationHandlerConfig[]): void {\n    for (const config of configs) {\n      // Check if already approved\n      const requireApproval = !this.approvedHandlers.has(config.id);\n      this.registerFromConfig(config, requireApproval);\n    }\n  }\n  \n  unregister(id: string): void {\n    this.handlers.delete(id);\n    this.configs.delete(id);\n    this.approvedHandlers.delete(id);\n    this.persistApprovedHandlers();\n  }\n  \n  findHandler(entry: SideEffectEntry): CompensationHandler | null {\n    for (const handler of this.handlers.values()) {\n      if (handler.canHandle(entry)) {\n        return handler;\n      }\n    }\n    return null;\n  }\n}\n\ninterface CompensationHandler {\n  name: string;\n  compensate(entry: SideEffectEntry): Promise<CompensationResult>;\n  canHandle(entry: SideEffectEntry): boolean;\n}\n\ninterface SideEffectEntry {\n  id: string;\n  nodeId: string;\n  executionId: string;\n  timestamp: number;\n  operation: string;\n  description: string;\n  compensation: any;\n  status: string;\n}\n\ninterface CompensationResult {\n  success: boolean;\n  error?: string;\n  message?: string;\n  manualSteps?: string[];\n  requiresUserAction?: boolean;\n}\n```\n\n## Adaptive Performance Metrics with IndexedDB Persistence\n\n### Key Innovation: Long-Term Analysis + Sampling Strategy\n\n```typescript\ninterface MetricsConfig {\n  enablePersistence: boolean;        // Store to IndexedDB\n  samplingRate: number;              // 0.1 = 10% of measurements\n  retentionDays: number;             // 7 days\n  enableRecommendations: boolean;\n}\n\ninterface StreamingMetrics {\n  decisions: {\n    teeCount: number;\n    materializeCount: number;\n    batchCount: number;\n  };\n  \n  performance: {\n    avgTeeMemory: number;\n    avgMaterializeSize: number;\n    avgTeeTime: number;\n    avgMaterializeTime: number;\n  };\n  \n  errors: {\n    teeFailures: number;\n    materializeFailures: number;\n    storageFullErrors: number;\n  };\n  \n  recommendations: {\n    suggestedTeeThreshold: number;\n    suggestedMaterializeThreshold: number;\n    suggestedOverflowPolicy: string;\n  };\n}\n\ninterface Measurement {\n  id: string;\n  timestamp: number;\n  strategy: 'tee' | 'materialize';\n  sizeBytes: number;\n  durationMs: number;\n  memoryUsed: number;\n  workflowId: string;\n  nodeId: string;\n}\n\nclass AdaptivePerformanceMonitor {\n  private metrics: StreamingMetrics;\n  private recentMeasurements: Measurement[] = [];\n  private db: IDBDatabase | null = null;\n  private config: MetricsConfig;\n  \n  constructor(config: MetricsConfig) {\n    this.config = config;\n    this.metrics = this.initMetrics();\n    \n    if (config.enablePersistence) {\n      this.initDatabase();\n    }\n  }\n  \n  recordDecision(\n    strategy: 'tee' | 'materialize' | 'batch',\n    sizeBytes: number,\n    durationMs: number,\n    memoryUsed: number,\n    context: {\n      workflowId: string;\n      nodeId: string;\n    }\n  ): void {\n    \n    switch (strategy) {\n      case 'tee':\n        this.metrics.decisions.teeCount++;\n        break;\n      case 'materialize':\n        this.metrics.decisions.materializeCount++;\n        break;\n      case 'batch':\n        this.metrics.decisions.batchCount++;\n        break;\n    }\n    \n    if (strategy === 'tee' || strategy === 'materialize') {\n      // Apply sampling\n      if (Math.random() < this.config.samplingRate) {\n        const measurement: Measurement = {\n          id: crypto.randomUUID(),\n          timestamp: Date.now(),\n          strategy,\n          sizeBytes,\n          durationMs,\n          memoryUsed,\n          workflowId: context.workflowId,\n          nodeId: context.nodeId\n        };\n        \n        this.recentMeasurements.push(measurement);\n        \n        // Keep last 100 in memory\n        if (this.recentMeasurements.length > 100) {\n          this.recentMeasurements.shift();\n        }\n        \n        // Persist to IndexedDB\n        if (this.config.enablePersistence && this.db) {\n          this.persistMeasurement(measurement);\n        }\n      }\n      \n      this.updateAverages();\n      \n      if (this.config.enableRecommendations) {\n        this.generateRecommendations();\n      }\n    }\n  }\n  \n  recordError(type: 'tee' | 'materialize' | 'storage-full'): void {\n    switch (type) {\n      case 'tee':\n        this.metrics.errors.teeFailures++;\n        break;\n      case 'materialize':\n        this.metrics.errors.materializeFailures++;\n        break;\n      case 'storage-full':\n        this.metrics.errors.storageFullErrors++;\n        break;\n    }\n  }\n  \n  private updateAverages(): void {\n    const tees = this.recentMeasurements.filter(m => m.strategy === 'tee');\n    const materializes = this.recentMeasurements.filter(m => m.strategy === 'materialize');\n    \n    if (tees.length > 0) {\n      this.metrics.performance.avgTeeMemory = \n        tees.reduce((sum, m) => sum + m.memoryUsed, 0) / tees.length;\n      this.metrics.performance.avgTeeTime = \n        tees.reduce((sum, m) => sum + m.durationMs, 0) / tees.length;\n    }\n    \n    if (materializes.length > 0) {\n      this.metrics.performance.avgMaterializeSize = \n        materializes.reduce((sum, m) => sum + m.sizeBytes, 0) / materializes.length;\n      this.metrics.performance.avgMaterializeTime = \n        materializes.reduce((sum, m) => sum + m.durationMs, 0) / materializes.length;\n    }\n  }\n  \n  private generateRecommendations(): void {\n    // Tee threshold\n    if (this.metrics.performance.avgTeeMemory > 10 * 1024 * 1024) {\n      this.metrics.recommendations.suggestedTeeThreshold = 3 * 1024 * 1024;\n    } else {\n      this.metrics.recommendations.suggestedTeeThreshold = 5 * 1024 * 1024;\n    }\n    \n    // Materialize threshold\n    if (this.metrics.performance.avgMaterializeTime < 100) {\n      this.metrics.recommendations.suggestedMaterializeThreshold = 100 * 1024 * 1024;\n    } else {\n      this.metrics.recommendations.suggestedMaterializeThreshold = 50 * 1024 * 1024;\n    }\n    \n    // Overflow policy\n    if (this.metrics.errors.storageFullErrors > 5) {\n      this.metrics.recommendations.suggestedOverflowPolicy = 'evict-lru';\n    } else {\n      this.metrics.recommendations.suggestedOverflowPolicy = 'compress';\n    }\n  }\n  \n  async getHistoricalMetrics(\n    workflowId?: string,\n    startTime?: number,\n    endTime?: number\n  ): Promise<Measurement[]> {\n    \n    if (!this.config.enablePersistence || !this.db) {\n      return this.recentMeasurements;\n    }\n    \n    return new Promise((resolve, reject) => {\n      const tx = this.db!.transaction('measurements', 'readonly');\n      const store = tx.objectStore('measurements');\n      const index = store.index('timestamp');\n      \n      const range = IDBKeyRange.bound(\n        startTime || 0,\n        endTime || Date.now()\n      );\n      \n      const results: Measurement[] = [];\n      const request = index.openCursor(range);\n      \n      request.onsuccess = (event) => {\n        const cursor = (event.target as IDBRequest).result;\n        if (cursor) {\n          const measurement: Measurement = cursor.value;\n          \n          if (!workflowId || measurement.workflowId === workflowId) {\n            results.push(measurement);\n          }\n          \n          cursor.continue();\n        } else {\n          resolve(results);\n        }\n      };\n      \n      request.onerror = () => reject(request.error);\n    });\n  }\n  \n  async generateReport(workflowId?: string): Promise<PerformanceReport> {\n    const measurements = await this.getHistoricalMetrics(workflowId);\n    \n    const tees = measurements.filter(m => m.strategy === 'tee');\n    const materializes = measurements.filter(m => m.strategy === 'materialize');\n    \n    return {\n      totalMeasurements: measurements.length,\n      timeRange: {\n        start: Math.min(...measurements.map(m => m.timestamp)),\n        end: Math.max(...measurements.map(m => m.timestamp))\n      },\n      strategies: {\n        tee: {\n          count: tees.length,\n          avgMemory: tees.reduce((sum, m) => sum + m.memoryUsed, 0) / tees.length,\n          avgDuration: tees.reduce((sum, m) => sum + m.durationMs, 0) / tees.length,\n          avgSize: tees.reduce((sum, m) => sum + m.sizeBytes, 0) / tees.length\n        },\n        materialize: {\n          count: materializes.length,\n          avgMemory: materializes.reduce((sum, m) => sum + m.memoryUsed, 0) / materializes.length,\n          avgDuration: materializes.reduce((sum, m) => sum + m.durationMs, 0) / materializes.length,\n          avgSize: materializes.reduce((sum, m) => sum + m.sizeBytes, 0) / materializes.length\n        }\n      },\n      recommendations: this.metrics.recommendations\n    };\n  }\n  \n  getMetrics(): StreamingMetrics {\n    return { ...this.metrics };\n  }\n  \n  getMeasurements(): Measurement[] {\n    return [...this.recentMeasurements];\n  }\n  \n  private async initDatabase(): Promise<void> {\n    return new Promise((resolve, reject) => {\n      const request = indexedDB.open('PerformanceMetrics', 2);\n      \n      request.onerror = () => reject(request.error);\n      request.onsuccess = () => {\n        this.db = request.result;\n        this.cleanupOldMeasurements();\n        resolve();\n      };\n      \n      request.onupgradeneeded = (event) => {\n        const db = (event.target as IDBOpenDBRequest).result;\n        \n        if (!db.objectStoreNames.contains('measurements')) {\n          const store = db.createObjectStore('measurements', { keyPath: 'id' });\n          store.createIndex('timestamp', 'timestamp', { unique: false });\n          store.createIndex('workflowId', 'workflowId', { unique: false });\n          store.createIndex('strategy', 'strategy', { unique: false });\n        }\n      };\n    });\n  }\n  \n  private async persistMeasurement(measurement: Measurement): Promise<void> {\n    if (!this.db) return;\n    \n    const tx = this.db.transaction('measurements', 'readwrite');\n    await tx.objectStore('measurements').add(measurement);\n  }\n  \n  private async cleanupOldMeasurements(): Promise<void> {\n    if (!this.db) return;\n    \n    const cutoff = Date.now() - (this.config.retentionDays * 24 * 60 * 60 * 1000);\n    \n    const tx = this.db.transaction('measurements', 'readwrite');\n    const store = tx.objectStore('measurements');\n    const index = store.index('timestamp');\n    \n    const range = IDBKeyRange.upperBound(cutoff);\n    const request = index.openCursor(range);\n    \n    request.onsuccess = (event) => {\n      const cursor = (event.target as IDBRequest).result;\n      if (cursor) {\n        cursor.delete();\n        cursor.continue();\n      }\n    };\n  }\n  \n  private initMetrics(): StreamingMetrics {\n    return {\n      decisions: {\n        teeCount: 0,\n        materializeCount: 0,\n        batchCount: 0\n      },\n      performance: {\n        avgTeeMemory: 0,\n        avgMaterializeSize: 0,\n        avgTeeTime: 0,\n        avgMaterializeTime: 0\n      },\n      errors: {\n        teeFailures: 0,\n        materializeFailures: 0,\n        storageFullErrors: 0\n      },\n      recommendations: {\n        suggestedTeeThreshold: 5 * 1024 * 1024,\n        suggestedMaterializeThreshold: 50 * 1024 * 1024,\n        suggestedOverflowPolicy: 'evict-lru'\n      }\n    };\n  }\n}\n\ninterface PerformanceReport {\n  totalMeasurements: number;\n  timeRange: {\n    start: number;\n    end: number;\n  };\n  strategies: {\n    tee: {\n      count: number;\n      avgMemory: number;\n      avgDuration: number;\n      avgSize: number;\n    };\n    materialize: {\n      count: number;\n      avgMemory: number;\n      avgDuration: number;\n      avgSize: number;\n    };\n  };\n  recommendations: StreamingMetrics['recommendations'];\n}\n```\n\n---"
}