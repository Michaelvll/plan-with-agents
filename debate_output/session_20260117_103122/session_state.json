{
  "initial_prompt": "Design a notification service with email and push notifications",
  "rounds": [
    {
      "round_number": 1,
      "agent_a": {
        "content": "## Design\n\n# Notification Service Architecture\n\n## System Overview\nA scalable, plugin-based notification service supporting email and push notifications with robust delivery guarantees, retry logic, and audit trails.\n\n## Architecture Components\n\n### 1. Core Components\n\n**NotificationService (Orchestrator)**\n```typescript\ninterface NotificationService {\n  send(request: NotificationRequest): Promise<NotificationResult>;\n  sendBatch(requests: NotificationRequest[]): Promise<NotificationResult[]>;\n  getStatus(notificationId: string): Promise<NotificationStatus>;\n  cancelScheduled(notificationId: string): Promise<void>;\n}\n```\n\n**Channel Providers (Strategy Pattern)**\n```typescript\ninterface ChannelProvider {\n  readonly channelType: ChannelType;\n  send(payload: ChannelPayload): Promise<SendResult>;\n  validateRecipient(recipient: string): boolean;\n  estimateCost(payload: ChannelPayload): number;\n}\n\n// Implementations\nclass EmailProvider implements ChannelProvider\nclass PushProvider implements ChannelProvider\n```\n\n**Queue Manager**\n```typescript\ninterface QueueManager {\n  enqueue(message: QueuedNotification): Promise<string>;\n  dequeue(batchSize: number): Promise<QueuedNotification[]>;\n  requeueWithBackoff(id: string, error: Error): Promise<void>;\n  markComplete(id: string): Promise<void>;\n}\n```\n\n**Retry Handler**\n```typescript\ninterface RetryHandler {\n  shouldRetry(attempt: number, error: Error): boolean;\n  calculateBackoff(attempt: number): number; // milliseconds\n  maxAttempts: number;\n}\n```\n\n### 2. Data Models\n\n```typescript\nenum ChannelType {\n  EMAIL = 'email',\n  PUSH = 'push'\n}\n\nenum NotificationPriority {\n  LOW = 'low',\n  NORMAL = 'normal',\n  HIGH = 'high',\n  URGENT = 'urgent'\n}\n\nenum NotificationStatus {\n  PENDING = 'pending',\n  QUEUED = 'queued',\n  SENDING = 'sending',\n  SENT = 'sent',\n  DELIVERED = 'delivered',\n  FAILED = 'failed',\n  CANCELLED = 'cancelled'\n}\n\ninterface NotificationRequest {\n  id?: string; // Auto-generated if not provided\n  channel: ChannelType;\n  recipient: Recipient;\n  content: NotificationContent;\n  priority: NotificationPriority;\n  metadata?: Record<string, any>;\n  scheduledFor?: Date;\n  expiresAt?: Date;\n  idempotencyKey?: string;\n}\n\ninterface Recipient {\n  // Email channel\n  email?: string;\n  \n  // Push channel\n  deviceTokens?: string[];\n  userId?: string; // To lookup device tokens\n  \n  // Personalization\n  firstName?: string;\n  lastName?: string;\n  locale?: string;\n  timezone?: string;\n}\n\ninterface NotificationContent {\n  // Email-specific\n  subject?: string;\n  htmlBody?: string;\n  textBody?: string;\n  attachments?: Attachment[];\n  \n  // Push-specific\n  title?: string;\n  body: string;\n  icon?: string;\n  badge?: number;\n  sound?: string;\n  data?: Record<string, any>;\n  \n  // Common\n  templateId?: string;\n  templateVariables?: Record<string, any>;\n}\n\ninterface Attachment {\n  filename: string;\n  contentType: string;\n  content: Buffer | string; // Base64 encoded\n  size: number;\n}\n\ninterface NotificationResult {\n  notificationId: string;\n  status: NotificationStatus;\n  channel: ChannelType;\n  sentAt?: Date;\n  deliveredAt?: Date;\n  error?: NotificationError;\n  providerResponse?: any;\n}\n\ninterface NotificationError {\n  code: string;\n  message: string;\n  retryable: boolean;\n  originalError?: any;\n}\n```\n\n### 3. Database Schema\n\n```sql\n-- Main notification records\nCREATE TABLE notifications (\n  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n  channel VARCHAR(20) NOT NULL,\n  recipient JSONB NOT NULL,\n  content JSONB NOT NULL,\n  priority VARCHAR(20) NOT NULL,\n  status VARCHAR(20) NOT NULL,\n  metadata JSONB,\n  scheduled_for TIMESTAMP WITH TIME ZONE,\n  expires_at TIMESTAMP WITH TIME ZONE,\n  idempotency_key VARCHAR(255) UNIQUE,\n  \n  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  sent_at TIMESTAMP WITH TIME ZONE,\n  delivered_at TIMESTAMP WITH TIME ZONE,\n  \n  attempt_count INTEGER DEFAULT 0,\n  last_error JSONB,\n  provider_response JSONB,\n  \n  INDEX idx_status (status),\n  INDEX idx_scheduled (scheduled_for) WHERE status = 'pending',\n  INDEX idx_idempotency (idempotency_key)\n);\n\n-- Audit trail for state transitions\nCREATE TABLE notification_events (\n  id BIGSERIAL PRIMARY KEY,\n  notification_id UUID NOT NULL REFERENCES notifications(id),\n  event_type VARCHAR(50) NOT NULL,\n  from_status VARCHAR(20),\n  to_status VARCHAR(20),\n  metadata JSONB,\n  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  \n  INDEX idx_notification (notification_id, created_at DESC)\n);\n\n-- User device tokens for push notifications\nCREATE TABLE device_tokens (\n  id BIGSERIAL PRIMARY KEY,\n  user_id VARCHAR(255) NOT NULL,\n  token VARCHAR(500) NOT NULL UNIQUE,\n  platform VARCHAR(20) NOT NULL, -- 'ios', 'android', 'web'\n  is_active BOOLEAN DEFAULT true,\n  last_used_at TIMESTAMP WITH TIME ZONE,\n  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  \n  INDEX idx_user (user_id, is_active)\n);\n\n-- Template storage\nCREATE TABLE notification_templates (\n  id VARCHAR(100) PRIMARY KEY,\n  channel VARCHAR(20) NOT NULL,\n  name VARCHAR(255) NOT NULL,\n  template_data JSONB NOT NULL,\n  version INTEGER NOT NULL,\n  is_active BOOLEAN DEFAULT true,\n  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n);\n```\n\n### 4. Service Workflow\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Client Request  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 NotificationService \u2502\n\u2502  - Validate         \u2502\n\u2502  - Check idempotency\u2502\n\u2502  - Assign ID        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Template Renderer  \u2502 (if templateId provided)\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Queue Manager     \u2502\n\u2502  - Priority queue   \u2502\n\u2502  - Schedule future  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Worker Process     \u2502\n\u2502  - Dequeue batch    \u2502\n\u2502  - Route to channel \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Channel Provider   \u2502\n\u2502  - EmailProvider    \u2502\n\u2502  - PushProvider     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  External Service   \u2502\n\u2502  - SendGrid/SES     \u2502\n\u2502  - FCM/APNs         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Result Handler     \u2502\n\u2502  - Update status    \u2502\n\u2502  - Log event        \u2502\n\u2502  - Retry on failure \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n### 5. Error Handling Strategy\n\n**Error Categories:**\n```typescript\nenum ErrorCategory {\n  VALIDATION = 'validation',      // Invalid input, don't retry\n  RATE_LIMIT = 'rate_limit',      // Retry with backoff\n  TEMPORARY = 'temporary',         // Network issues, retry\n  PERMANENT = 'permanent',         // Invalid recipient, don't retry\n  PROVIDER = 'provider',           // External service issue\n  INTERNAL = 'internal'            // Our system issue\n}\n\nclass NotificationError extends Error {\n  constructor(\n    public category: ErrorCategory,\n    public code: string,\n    message: string,\n    public retryable: boolean,\n    public originalError?: Error\n  ) {\n    super(message);\n  }\n}\n```\n\n**Retry Policy:**\n```typescript\nclass ExponentialBackoffRetry implements RetryHandler {\n  maxAttempts = 5;\n  baseDelay = 1000; // 1 second\n  maxDelay = 300000; // 5 minutes\n  \n  shouldRetry(attempt: number, error: Error): boolean {\n    if (attempt >= this.maxAttempts) return false;\n    if (!(error instanceof NotificationError)) return false;\n    return error.retryable;\n  }\n  \n  calculateBackoff(attempt: number): number {\n    const exponential = this.baseDelay * Math.pow(2, attempt);\n    const jitter = Math.random() * 1000;\n    return Math.min(exponential + jitter, this.maxDelay);\n  }\n}\n```\n\n**Circuit Breaker:**\n```typescript\nclass ProviderCircuitBreaker {\n  private failureCount = 0;\n  private lastFailureTime?: Date;\n  private state: 'closed' | 'open' | 'half-open' = 'closed';\n  \n  constructor(\n    private threshold: number = 5,\n    private timeout: number = 60000 // 1 minute\n  ) {}\n  \n  async execute<T>(fn: () => Promise<T>): Promise<T> {\n    if (this.state === 'open') {\n      if (Date.now() - this.lastFailureTime!.getTime() > this.timeout) {\n        this.state = 'half-open';\n      } else {\n        throw new NotificationError(\n          ErrorCategory.PROVIDER,\n          'CIRCUIT_OPEN',\n          'Provider circuit breaker is open',\n          true\n        );\n      }\n    }\n    \n    try {\n      const result = await fn();\n      this.onSuccess();\n      return result;\n    } catch (error) {\n      this.onFailure();\n      throw error;\n    }\n  }\n  \n  private onSuccess() {\n    this.failureCount = 0;\n    this.state = 'closed';\n  }\n  \n  private onFailure() {\n    this.failureCount++;\n    this.lastFailureTime = new Date();\n    if (this.failureCount >= this.threshold) {\n      this.state = 'open';\n    }\n  }\n}\n```\n\n### 6. Provider Implementations\n\n**Email Provider (SendGrid Example):**\n```typescript\nclass SendGridEmailProvider implements ChannelProvider {\n  readonly channelType = ChannelType.EMAIL;\n  private circuitBreaker: ProviderCircuitBreaker;\n  \n  constructor(private apiKey: string) {\n    this.circuitBreaker = new ProviderCircuitBreaker();\n  }\n  \n  async send(payload: ChannelPayload): Promise<SendResult> {\n    return this.circuitBreaker.execute(async () => {\n      const { recipient, content } = payload;\n      \n      if (!this.validateRecipient(recipient.email!)) {\n        throw new NotificationError(\n          ErrorCategory.VALIDATION,\n          'INVALID_EMAIL',\n          `Invalid email: ${recipient.email}`,\n          false\n        );\n      }\n      \n      try {\n        const response = await fetch('https://api.sendgrid.com/v3/mail/send', {\n          method: 'POST',\n          headers: {\n            'Authorization': `Bearer ${this.apiKey}`,\n            'Content-Type': 'application/json'\n          },\n          body: JSON.stringify({\n            personalizations: [{\n              to: [{ email: recipient.email }],\n              subject: content.subject\n            }],\n            from: { email: 'noreply@example.com' },\n            content: [\n              { type: 'text/plain', value: content.textBody || '' },\n              { type: 'text/html', value: content.htmlBody || '' }\n            ]\n          })\n        });\n        \n        if (response.status === 429) {\n          throw new NotificationError(\n            ErrorCategory.RATE_LIMIT,\n            'RATE_LIMITED',\n            'SendGrid rate limit exceeded',\n            true\n          );\n        }\n        \n        if (!response.ok) {\n          const error = await response.text();\n          throw new NotificationError(\n            ErrorCategory.PROVIDER,\n            'PROVIDER_ERROR',\n            `SendGrid error: ${error}`,\n            response.status >= 500\n          );\n        }\n        \n        return {\n          success: true,\n          providerMessageId: response.headers.get('x-message-id'),\n          timestamp: new Date()\n        };\n      } catch (error) {\n        if (error instanceof NotificationError) throw error;\n        \n        throw new NotificationError(\n          ErrorCategory.TEMPORARY,\n          'NETWORK_ERROR',\n          'Network error contacting SendGrid',\n          true,\n          error as Error\n        );\n      }\n    });\n  }\n  \n  validateRecipient(email: string): boolean {\n    const emailRegex = /^[^\\s@]+@[^\\s@]+\\.[^\\s@]+$/;\n    return emailRegex.test(email);\n  }\n  \n  estimateCost(payload: ChannelPayload): number {\n    return 0.001; // $0.001 per email\n  }\n}\n```\n\n**Push Provider (FCM Example):**\n```typescript\nclass FCMPushProvider implements ChannelProvider {\n  readonly channelType = ChannelType.PUSH;\n  private circuitBreaker: ProviderCircuitBreaker;\n  \n  constructor(private serverKey: string) {\n    this.circuitBreaker = new ProviderCircuitBreaker();\n  }\n  \n  async send(payload: ChannelPayload): Promise<SendResult> {\n    return this.circuitBreaker.execute(async () => {\n      const { recipient, content } = payload;\n      const tokens = recipient.deviceTokens || [];\n      \n      if (tokens.length === 0) {\n        throw new NotificationError(\n          ErrorCategory.VALIDATION,\n          'NO_TOKENS',\n          'No device tokens provided',\n          false\n        );\n      }\n      \n      const message = {\n        notification: {\n          title: content.title,\n          body: content.body,\n          icon: content.icon,\n          sound: content.sound\n        },\n        data: content.data,\n        tokens: tokens\n      };\n      \n      try {\n        const response = await fetch('https://fcm.googleapis.com/v1/projects/PROJECT_ID/messages:send', {\n          method: 'POST',\n          headers: {\n            'Authorization': `Bearer ${this.serverKey}`,\n            'Content-Type': 'application/json'\n          },\n          body: JSON.stringify(message)\n        });\n        \n        const result = await response.json();\n        \n        // Handle invalid tokens\n        if (result.failure > 0) {\n          // Mark invalid tokens for cleanup\n          this.handleInvalidTokens(result.results, tokens);\n        }\n        \n        return {\n          success: result.success > 0,\n          providerMessageId: result.multicast_id,\n          timestamp: new Date(),\n          metadata: {\n            successCount: result.success,\n            failureCount: result.failure\n          }\n        };\n      } catch (error) {\n        throw new NotificationError(\n          ErrorCategory.TEMPORARY,\n          'NETWORK_ERROR',\n          'Network error contacting FCM',\n          true,\n          error as Error\n        );\n      }\n    });\n  }\n  \n  private async handleInvalidTokens(results: any[], tokens: string[]) {\n    // Remove invalid tokens from database\n    const invalidTokens = tokens.filter((token, i) => \n      results[i]?.error === 'InvalidRegistration'\n    );\n    // Mark as inactive in device_tokens table\n  }\n  \n  validateRecipient(recipient: string): boolean {\n    return recipient.length > 0;\n  }\n  \n  estimateCost(payload: ChannelPayload): number {\n    return 0; // FCM is free\n  }\n}\n```\n\n### 7. Configuration & Scalability\n\n**Configuration:**\n```typescript\ninterface NotificationConfig {\n  providers: {\n    email: {\n      type: 'sendgrid' | 'ses' | 'smtp';\n      apiKey: string;\n      defaultFrom: string;\n    };\n    push: {\n      type: 'fcm' | 'apns';\n      credentials: any;\n    };\n  };\n  queue: {\n    type: 'redis' | 'sqs' | 'rabbitmq';\n    connectionString: string;\n    batchSize: number;\n  };\n  retry: {\n    maxAttempts: number;\n    baseDelay: number;\n  };\n  workers: {\n    count: number;\n    pollInterval: number;\n  };\n}\n```\n\n**Horizontal Scaling:**\n- Multiple worker processes dequeue from shared queue\n- Database-backed queue with row-level locking for concurrency\n- Stateless workers can scale independently\n- Rate limiting per provider to respect API limits\n\n## Rationale\n\n1. **Queue-based architecture**: Ensures reliability and allows for retry logic without blocking client requests\n2. **Strategy pattern for channels**: Makes it easy to add new notification channels (SMS, Slack, etc.)\n3. **Idempotency keys**: Prevents duplicate notifications if client retries\n4. **Circuit breaker**: Protects against cascading failures when providers are down\n5. **Exponential backoff**: Balances retry aggressiveness with resource usage\n6. **Audit trail**: Every status change is logged for debugging and compliance\n7. **Priority queue**: Critical notifications (password reset) processed before marketing emails\n8. **Template support**: Separates content from code, enables non-technical content updates\n\n## What I Changed\n\nThis is the initial design proposal.\n\n## What I Kept\n\nN/A - First iteration.\n\n## Open Questions\n\n1. Should we support webhook callbacks for delivery status?\n2. Do we need multi-tenancy support (different API keys per tenant)?\n3. Should batch sends be atomic or best-effort?\n4. What's the data retention policy for notifications and events?\n\n## Convergence Status\n\n**ITERATING** - This is the first draft and needs critical review.",
        "prompt_for_other": "Focus on scalability bottlenecks, edge cases in error handling, and potential race conditions in the queue management. Are there failure modes I haven't considered?",
        "convergence_signal": "ITERATING",
        "raw_response": "## Design\n\n# Notification Service Architecture\n\n## System Overview\nA scalable, plugin-based notification service supporting email and push notifications with robust delivery guarantees, retry logic, and audit trails.\n\n## Architecture Components\n\n### 1. Core Components\n\n**NotificationService (Orchestrator)**\n```typescript\ninterface NotificationService {\n  send(request: NotificationRequest): Promise<NotificationResult>;\n  sendBatch(requests: NotificationRequest[]): Promise<NotificationResult[]>;\n  getStatus(notificationId: string): Promise<NotificationStatus>;\n  cancelScheduled(notificationId: string): Promise<void>;\n}\n```\n\n**Channel Providers (Strategy Pattern)**\n```typescript\ninterface ChannelProvider {\n  readonly channelType: ChannelType;\n  send(payload: ChannelPayload): Promise<SendResult>;\n  validateRecipient(recipient: string): boolean;\n  estimateCost(payload: ChannelPayload): number;\n}\n\n// Implementations\nclass EmailProvider implements ChannelProvider\nclass PushProvider implements ChannelProvider\n```\n\n**Queue Manager**\n```typescript\ninterface QueueManager {\n  enqueue(message: QueuedNotification): Promise<string>;\n  dequeue(batchSize: number): Promise<QueuedNotification[]>;\n  requeueWithBackoff(id: string, error: Error): Promise<void>;\n  markComplete(id: string): Promise<void>;\n}\n```\n\n**Retry Handler**\n```typescript\ninterface RetryHandler {\n  shouldRetry(attempt: number, error: Error): boolean;\n  calculateBackoff(attempt: number): number; // milliseconds\n  maxAttempts: number;\n}\n```\n\n### 2. Data Models\n\n```typescript\nenum ChannelType {\n  EMAIL = 'email',\n  PUSH = 'push'\n}\n\nenum NotificationPriority {\n  LOW = 'low',\n  NORMAL = 'normal',\n  HIGH = 'high',\n  URGENT = 'urgent'\n}\n\nenum NotificationStatus {\n  PENDING = 'pending',\n  QUEUED = 'queued',\n  SENDING = 'sending',\n  SENT = 'sent',\n  DELIVERED = 'delivered',\n  FAILED = 'failed',\n  CANCELLED = 'cancelled'\n}\n\ninterface NotificationRequest {\n  id?: string; // Auto-generated if not provided\n  channel: ChannelType;\n  recipient: Recipient;\n  content: NotificationContent;\n  priority: NotificationPriority;\n  metadata?: Record<string, any>;\n  scheduledFor?: Date;\n  expiresAt?: Date;\n  idempotencyKey?: string;\n}\n\ninterface Recipient {\n  // Email channel\n  email?: string;\n  \n  // Push channel\n  deviceTokens?: string[];\n  userId?: string; // To lookup device tokens\n  \n  // Personalization\n  firstName?: string;\n  lastName?: string;\n  locale?: string;\n  timezone?: string;\n}\n\ninterface NotificationContent {\n  // Email-specific\n  subject?: string;\n  htmlBody?: string;\n  textBody?: string;\n  attachments?: Attachment[];\n  \n  // Push-specific\n  title?: string;\n  body: string;\n  icon?: string;\n  badge?: number;\n  sound?: string;\n  data?: Record<string, any>;\n  \n  // Common\n  templateId?: string;\n  templateVariables?: Record<string, any>;\n}\n\ninterface Attachment {\n  filename: string;\n  contentType: string;\n  content: Buffer | string; // Base64 encoded\n  size: number;\n}\n\ninterface NotificationResult {\n  notificationId: string;\n  status: NotificationStatus;\n  channel: ChannelType;\n  sentAt?: Date;\n  deliveredAt?: Date;\n  error?: NotificationError;\n  providerResponse?: any;\n}\n\ninterface NotificationError {\n  code: string;\n  message: string;\n  retryable: boolean;\n  originalError?: any;\n}\n```\n\n### 3. Database Schema\n\n```sql\n-- Main notification records\nCREATE TABLE notifications (\n  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n  channel VARCHAR(20) NOT NULL,\n  recipient JSONB NOT NULL,\n  content JSONB NOT NULL,\n  priority VARCHAR(20) NOT NULL,\n  status VARCHAR(20) NOT NULL,\n  metadata JSONB,\n  scheduled_for TIMESTAMP WITH TIME ZONE,\n  expires_at TIMESTAMP WITH TIME ZONE,\n  idempotency_key VARCHAR(255) UNIQUE,\n  \n  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  sent_at TIMESTAMP WITH TIME ZONE,\n  delivered_at TIMESTAMP WITH TIME ZONE,\n  \n  attempt_count INTEGER DEFAULT 0,\n  last_error JSONB,\n  provider_response JSONB,\n  \n  INDEX idx_status (status),\n  INDEX idx_scheduled (scheduled_for) WHERE status = 'pending',\n  INDEX idx_idempotency (idempotency_key)\n);\n\n-- Audit trail for state transitions\nCREATE TABLE notification_events (\n  id BIGSERIAL PRIMARY KEY,\n  notification_id UUID NOT NULL REFERENCES notifications(id),\n  event_type VARCHAR(50) NOT NULL,\n  from_status VARCHAR(20),\n  to_status VARCHAR(20),\n  metadata JSONB,\n  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  \n  INDEX idx_notification (notification_id, created_at DESC)\n);\n\n-- User device tokens for push notifications\nCREATE TABLE device_tokens (\n  id BIGSERIAL PRIMARY KEY,\n  user_id VARCHAR(255) NOT NULL,\n  token VARCHAR(500) NOT NULL UNIQUE,\n  platform VARCHAR(20) NOT NULL, -- 'ios', 'android', 'web'\n  is_active BOOLEAN DEFAULT true,\n  last_used_at TIMESTAMP WITH TIME ZONE,\n  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  \n  INDEX idx_user (user_id, is_active)\n);\n\n-- Template storage\nCREATE TABLE notification_templates (\n  id VARCHAR(100) PRIMARY KEY,\n  channel VARCHAR(20) NOT NULL,\n  name VARCHAR(255) NOT NULL,\n  template_data JSONB NOT NULL,\n  version INTEGER NOT NULL,\n  is_active BOOLEAN DEFAULT true,\n  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n);\n```\n\n### 4. Service Workflow\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Client Request  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 NotificationService \u2502\n\u2502  - Validate         \u2502\n\u2502  - Check idempotency\u2502\n\u2502  - Assign ID        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Template Renderer  \u2502 (if templateId provided)\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Queue Manager     \u2502\n\u2502  - Priority queue   \u2502\n\u2502  - Schedule future  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Worker Process     \u2502\n\u2502  - Dequeue batch    \u2502\n\u2502  - Route to channel \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Channel Provider   \u2502\n\u2502  - EmailProvider    \u2502\n\u2502  - PushProvider     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  External Service   \u2502\n\u2502  - SendGrid/SES     \u2502\n\u2502  - FCM/APNs         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Result Handler     \u2502\n\u2502  - Update status    \u2502\n\u2502  - Log event        \u2502\n\u2502  - Retry on failure \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n### 5. Error Handling Strategy\n\n**Error Categories:**\n```typescript\nenum ErrorCategory {\n  VALIDATION = 'validation',      // Invalid input, don't retry\n  RATE_LIMIT = 'rate_limit',      // Retry with backoff\n  TEMPORARY = 'temporary',         // Network issues, retry\n  PERMANENT = 'permanent',         // Invalid recipient, don't retry\n  PROVIDER = 'provider',           // External service issue\n  INTERNAL = 'internal'            // Our system issue\n}\n\nclass NotificationError extends Error {\n  constructor(\n    public category: ErrorCategory,\n    public code: string,\n    message: string,\n    public retryable: boolean,\n    public originalError?: Error\n  ) {\n    super(message);\n  }\n}\n```\n\n**Retry Policy:**\n```typescript\nclass ExponentialBackoffRetry implements RetryHandler {\n  maxAttempts = 5;\n  baseDelay = 1000; // 1 second\n  maxDelay = 300000; // 5 minutes\n  \n  shouldRetry(attempt: number, error: Error): boolean {\n    if (attempt >= this.maxAttempts) return false;\n    if (!(error instanceof NotificationError)) return false;\n    return error.retryable;\n  }\n  \n  calculateBackoff(attempt: number): number {\n    const exponential = this.baseDelay * Math.pow(2, attempt);\n    const jitter = Math.random() * 1000;\n    return Math.min(exponential + jitter, this.maxDelay);\n  }\n}\n```\n\n**Circuit Breaker:**\n```typescript\nclass ProviderCircuitBreaker {\n  private failureCount = 0;\n  private lastFailureTime?: Date;\n  private state: 'closed' | 'open' | 'half-open' = 'closed';\n  \n  constructor(\n    private threshold: number = 5,\n    private timeout: number = 60000 // 1 minute\n  ) {}\n  \n  async execute<T>(fn: () => Promise<T>): Promise<T> {\n    if (this.state === 'open') {\n      if (Date.now() - this.lastFailureTime!.getTime() > this.timeout) {\n        this.state = 'half-open';\n      } else {\n        throw new NotificationError(\n          ErrorCategory.PROVIDER,\n          'CIRCUIT_OPEN',\n          'Provider circuit breaker is open',\n          true\n        );\n      }\n    }\n    \n    try {\n      const result = await fn();\n      this.onSuccess();\n      return result;\n    } catch (error) {\n      this.onFailure();\n      throw error;\n    }\n  }\n  \n  private onSuccess() {\n    this.failureCount = 0;\n    this.state = 'closed';\n  }\n  \n  private onFailure() {\n    this.failureCount++;\n    this.lastFailureTime = new Date();\n    if (this.failureCount >= this.threshold) {\n      this.state = 'open';\n    }\n  }\n}\n```\n\n### 6. Provider Implementations\n\n**Email Provider (SendGrid Example):**\n```typescript\nclass SendGridEmailProvider implements ChannelProvider {\n  readonly channelType = ChannelType.EMAIL;\n  private circuitBreaker: ProviderCircuitBreaker;\n  \n  constructor(private apiKey: string) {\n    this.circuitBreaker = new ProviderCircuitBreaker();\n  }\n  \n  async send(payload: ChannelPayload): Promise<SendResult> {\n    return this.circuitBreaker.execute(async () => {\n      const { recipient, content } = payload;\n      \n      if (!this.validateRecipient(recipient.email!)) {\n        throw new NotificationError(\n          ErrorCategory.VALIDATION,\n          'INVALID_EMAIL',\n          `Invalid email: ${recipient.email}`,\n          false\n        );\n      }\n      \n      try {\n        const response = await fetch('https://api.sendgrid.com/v3/mail/send', {\n          method: 'POST',\n          headers: {\n            'Authorization': `Bearer ${this.apiKey}`,\n            'Content-Type': 'application/json'\n          },\n          body: JSON.stringify({\n            personalizations: [{\n              to: [{ email: recipient.email }],\n              subject: content.subject\n            }],\n            from: { email: 'noreply@example.com' },\n            content: [\n              { type: 'text/plain', value: content.textBody || '' },\n              { type: 'text/html', value: content.htmlBody || '' }\n            ]\n          })\n        });\n        \n        if (response.status === 429) {\n          throw new NotificationError(\n            ErrorCategory.RATE_LIMIT,\n            'RATE_LIMITED',\n            'SendGrid rate limit exceeded',\n            true\n          );\n        }\n        \n        if (!response.ok) {\n          const error = await response.text();\n          throw new NotificationError(\n            ErrorCategory.PROVIDER,\n            'PROVIDER_ERROR',\n            `SendGrid error: ${error}`,\n            response.status >= 500\n          );\n        }\n        \n        return {\n          success: true,\n          providerMessageId: response.headers.get('x-message-id'),\n          timestamp: new Date()\n        };\n      } catch (error) {\n        if (error instanceof NotificationError) throw error;\n        \n        throw new NotificationError(\n          ErrorCategory.TEMPORARY,\n          'NETWORK_ERROR',\n          'Network error contacting SendGrid',\n          true,\n          error as Error\n        );\n      }\n    });\n  }\n  \n  validateRecipient(email: string): boolean {\n    const emailRegex = /^[^\\s@]+@[^\\s@]+\\.[^\\s@]+$/;\n    return emailRegex.test(email);\n  }\n  \n  estimateCost(payload: ChannelPayload): number {\n    return 0.001; // $0.001 per email\n  }\n}\n```\n\n**Push Provider (FCM Example):**\n```typescript\nclass FCMPushProvider implements ChannelProvider {\n  readonly channelType = ChannelType.PUSH;\n  private circuitBreaker: ProviderCircuitBreaker;\n  \n  constructor(private serverKey: string) {\n    this.circuitBreaker = new ProviderCircuitBreaker();\n  }\n  \n  async send(payload: ChannelPayload): Promise<SendResult> {\n    return this.circuitBreaker.execute(async () => {\n      const { recipient, content } = payload;\n      const tokens = recipient.deviceTokens || [];\n      \n      if (tokens.length === 0) {\n        throw new NotificationError(\n          ErrorCategory.VALIDATION,\n          'NO_TOKENS',\n          'No device tokens provided',\n          false\n        );\n      }\n      \n      const message = {\n        notification: {\n          title: content.title,\n          body: content.body,\n          icon: content.icon,\n          sound: content.sound\n        },\n        data: content.data,\n        tokens: tokens\n      };\n      \n      try {\n        const response = await fetch('https://fcm.googleapis.com/v1/projects/PROJECT_ID/messages:send', {\n          method: 'POST',\n          headers: {\n            'Authorization': `Bearer ${this.serverKey}`,\n            'Content-Type': 'application/json'\n          },\n          body: JSON.stringify(message)\n        });\n        \n        const result = await response.json();\n        \n        // Handle invalid tokens\n        if (result.failure > 0) {\n          // Mark invalid tokens for cleanup\n          this.handleInvalidTokens(result.results, tokens);\n        }\n        \n        return {\n          success: result.success > 0,\n          providerMessageId: result.multicast_id,\n          timestamp: new Date(),\n          metadata: {\n            successCount: result.success,\n            failureCount: result.failure\n          }\n        };\n      } catch (error) {\n        throw new NotificationError(\n          ErrorCategory.TEMPORARY,\n          'NETWORK_ERROR',\n          'Network error contacting FCM',\n          true,\n          error as Error\n        );\n      }\n    });\n  }\n  \n  private async handleInvalidTokens(results: any[], tokens: string[]) {\n    // Remove invalid tokens from database\n    const invalidTokens = tokens.filter((token, i) => \n      results[i]?.error === 'InvalidRegistration'\n    );\n    // Mark as inactive in device_tokens table\n  }\n  \n  validateRecipient(recipient: string): boolean {\n    return recipient.length > 0;\n  }\n  \n  estimateCost(payload: ChannelPayload): number {\n    return 0; // FCM is free\n  }\n}\n```\n\n### 7. Configuration & Scalability\n\n**Configuration:**\n```typescript\ninterface NotificationConfig {\n  providers: {\n    email: {\n      type: 'sendgrid' | 'ses' | 'smtp';\n      apiKey: string;\n      defaultFrom: string;\n    };\n    push: {\n      type: 'fcm' | 'apns';\n      credentials: any;\n    };\n  };\n  queue: {\n    type: 'redis' | 'sqs' | 'rabbitmq';\n    connectionString: string;\n    batchSize: number;\n  };\n  retry: {\n    maxAttempts: number;\n    baseDelay: number;\n  };\n  workers: {\n    count: number;\n    pollInterval: number;\n  };\n}\n```\n\n**Horizontal Scaling:**\n- Multiple worker processes dequeue from shared queue\n- Database-backed queue with row-level locking for concurrency\n- Stateless workers can scale independently\n- Rate limiting per provider to respect API limits\n\n## Rationale\n\n1. **Queue-based architecture**: Ensures reliability and allows for retry logic without blocking client requests\n2. **Strategy pattern for channels**: Makes it easy to add new notification channels (SMS, Slack, etc.)\n3. **Idempotency keys**: Prevents duplicate notifications if client retries\n4. **Circuit breaker**: Protects against cascading failures when providers are down\n5. **Exponential backoff**: Balances retry aggressiveness with resource usage\n6. **Audit trail**: Every status change is logged for debugging and compliance\n7. **Priority queue**: Critical notifications (password reset) processed before marketing emails\n8. **Template support**: Separates content from code, enables non-technical content updates\n\n## What I Changed\n\nThis is the initial design proposal.\n\n## What I Kept\n\nN/A - First iteration.\n\n## Open Questions\n\n1. Should we support webhook callbacks for delivery status?\n2. Do we need multi-tenancy support (different API keys per tenant)?\n3. Should batch sends be atomic or best-effort?\n4. What's the data retention policy for notifications and events?\n\n## Convergence Status\n\n**ITERATING** - This is the first draft and needs critical review.\n\nPROMPT_FOR_CRITIC:\nFocus on scalability bottlenecks, edge cases in error handling, and potential race conditions in the queue management. Are there failure modes I haven't considered?"
      },
      "agent_b": {
        "content": "## Design\n\n# Notification Service Architecture\n\n## System Overview\nA scalable, plugin-based notification service supporting email and push notifications with robust delivery guarantees, distributed queue management, and comprehensive observability.\n\n## Architecture Components\n\n### 1. Core Components\n\n**NotificationService (Orchestrator)**\n```typescript\ninterface NotificationService {\n  send(request: NotificationRequest): Promise<NotificationResult>;\n  sendBatch(requests: NotificationRequest[]): Promise<BatchNotificationResult>;\n  getStatus(notificationId: string): Promise<NotificationStatus>;\n  cancelScheduled(notificationId: string): Promise<CancelResult>;\n  retryFailed(notificationId: string): Promise<NotificationResult>;\n}\n\ninterface BatchNotificationResult {\n  results: NotificationResult[];\n  successCount: number;\n  failureCount: number;\n  partialFailure: boolean;\n}\n\ninterface CancelResult {\n  notificationId: string;\n  cancelled: boolean;\n  reason?: string; // e.g., \"already sent\", \"not found\"\n}\n```\n\n**Channel Providers (Strategy Pattern)**\n```typescript\ninterface ChannelProvider {\n  readonly channelType: ChannelType;\n  readonly capabilities: ProviderCapabilities;\n  send(payload: ChannelPayload): Promise<SendResult>;\n  validateRecipient(recipient: Recipient): ValidationResult;\n  estimateCost(payload: ChannelPayload): number;\n  healthCheck(): Promise<HealthStatus>;\n}\n\ninterface ProviderCapabilities {\n  supportsBatch: boolean;\n  maxBatchSize?: number;\n  supportsScheduling: boolean;\n  supportsDeliveryTracking: boolean;\n  rateLimit: RateLimit;\n}\n\ninterface RateLimit {\n  requestsPerSecond: number;\n  requestsPerMinute: number;\n  requestsPerDay?: number;\n}\n\ninterface ValidationResult {\n  valid: boolean;\n  errors: string[];\n  warnings?: string[];\n}\n\ninterface HealthStatus {\n  healthy: boolean;\n  latency?: number;\n  lastChecked: Date;\n  details?: any;\n}\n\n// Implementations\nclass EmailProvider implements ChannelProvider\nclass PushProvider implements ChannelProvider\n```\n\n**Distributed Queue Manager**\n```typescript\ninterface QueueManager {\n  enqueue(message: QueuedNotification, priority: NotificationPriority): Promise<string>;\n  enqueueBatch(messages: QueuedNotification[]): Promise<string[]>;\n  dequeue(workerId: string, batchSize: number): Promise<QueuedNotification[]>;\n  requeueWithBackoff(id: string, error: Error, attempt: number): Promise<void>;\n  markComplete(id: string): Promise<void>;\n  markFailed(id: string, error: Error): Promise<void>;\n  extendLease(id: string, workerId: string, durationMs: number): Promise<boolean>;\n  releaseStuckMessages(timeoutMs: number): Promise<number>;\n}\n\ninterface QueuedNotification {\n  id: string;\n  notification: NotificationRequest;\n  enqueuedAt: Date;\n  visibleAt: Date; // For scheduled notifications or retry backoff\n  leaseExpiry?: Date;\n  workerId?: string;\n  attempt: number;\n}\n```\n\n**Retry Handler with Jitter**\n```typescript\ninterface RetryHandler {\n  shouldRetry(attempt: number, error: NotificationError): RetryDecision;\n  calculateBackoff(attempt: number, error: NotificationError): number;\n  maxAttempts: number;\n}\n\ninterface RetryDecision {\n  shouldRetry: boolean;\n  reason: string;\n  delayMs?: number;\n}\n\nclass AdaptiveRetryHandler implements RetryHandler {\n  maxAttempts = 5;\n  baseDelay = 1000;\n  maxDelay = 300000;\n  \n  shouldRetry(attempt: number, error: NotificationError): RetryDecision {\n    if (attempt >= this.maxAttempts) {\n      return { shouldRetry: false, reason: 'max_attempts_exceeded' };\n    }\n    \n    if (!error.retryable) {\n      return { shouldRetry: false, reason: 'non_retryable_error' };\n    }\n    \n    // Don't retry validation errors\n    if (error.category === ErrorCategory.VALIDATION) {\n      return { shouldRetry: false, reason: 'validation_error' };\n    }\n    \n    // Rate limits get longer backoff\n    if (error.category === ErrorCategory.RATE_LIMIT) {\n      return { \n        shouldRetry: true, \n        reason: 'rate_limit',\n        delayMs: this.calculateBackoff(attempt, error)\n      };\n    }\n    \n    return { \n      shouldRetry: true, \n      reason: 'temporary_error',\n      delayMs: this.calculateBackoff(attempt, error)\n    };\n  }\n  \n  calculateBackoff(attempt: number, error: NotificationError): number {\n    let multiplier = 1;\n    \n    // Longer backoff for rate limits\n    if (error.category === ErrorCategory.RATE_LIMIT) {\n      multiplier = 3;\n    }\n    \n    const exponential = this.baseDelay * Math.pow(2, attempt) * multiplier;\n    const jitter = Math.random() * 1000; // Full jitter\n    return Math.min(exponential + jitter, this.maxDelay);\n  }\n}\n```\n\n### 2. Data Models\n\n```typescript\nenum ChannelType {\n  EMAIL = 'email',\n  PUSH = 'push'\n}\n\nenum NotificationPriority {\n  LOW = 'low',\n  NORMAL = 'normal',\n  HIGH = 'high',\n  URGENT = 'urgent'\n}\n\nenum NotificationStatus {\n  PENDING = 'pending',\n  QUEUED = 'queued',\n  PROCESSING = 'processing',\n  SENT = 'sent',\n  DELIVERED = 'delivered',\n  FAILED = 'failed',\n  CANCELLED = 'cancelled',\n  EXPIRED = 'expired'\n}\n\ninterface NotificationRequest {\n  id?: string;\n  channel: ChannelType;\n  recipient: Recipient;\n  content: NotificationContent;\n  priority: NotificationPriority;\n  metadata?: Record<string, any>;\n  scheduledFor?: Date;\n  expiresAt?: Date;\n  idempotencyKey?: string;\n  callbackUrl?: string; // Webhook for delivery status\n  maxAttempts?: number; // Override default retry policy\n}\n\ninterface Recipient {\n  email?: string;\n  deviceTokens?: string[];\n  userId?: string;\n  firstName?: string;\n  lastName?: string;\n  locale?: string;\n  timezone?: string;\n}\n\ninterface NotificationContent {\n  subject?: string;\n  htmlBody?: string;\n  textBody?: string;\n  attachments?: Attachment[];\n  title?: string;\n  body: string;\n  icon?: string;\n  badge?: number;\n  sound?: string;\n  data?: Record<string, any>;\n  templateId?: string;\n  templateVariables?: Record<string, any>;\n}\n\ninterface Attachment {\n  filename: string;\n  contentType: string;\n  content: Buffer | string;\n  size: number;\n}\n\ninterface NotificationResult {\n  notificationId: string;\n  status: NotificationStatus;\n  channel: ChannelType;\n  enqueuedAt: Date;\n  sentAt?: Date;\n  deliveredAt?: Date;\n  failedAt?: Date;\n  error?: NotificationError;\n  providerResponse?: any;\n  attemptCount: number;\n}\n\ninterface NotificationError {\n  code: string;\n  message: string;\n  category: ErrorCategory;\n  retryable: boolean;\n  originalError?: any;\n}\n```\n\n### 3. Enhanced Database Schema\n\n```sql\n-- Main notification records with optimistic locking\nCREATE TABLE notifications (\n  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n  channel VARCHAR(20) NOT NULL,\n  recipient JSONB NOT NULL,\n  content JSONB NOT NULL,\n  priority VARCHAR(20) NOT NULL,\n  status VARCHAR(20) NOT NULL,\n  metadata JSONB,\n  scheduled_for TIMESTAMP WITH TIME ZONE,\n  expires_at TIMESTAMP WITH TIME ZONE,\n  idempotency_key VARCHAR(255) UNIQUE,\n  callback_url TEXT,\n  max_attempts INTEGER DEFAULT 5,\n  \n  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  enqueued_at TIMESTAMP WITH TIME ZONE,\n  sent_at TIMESTAMP WITH TIME ZONE,\n  delivered_at TIMESTAMP WITH TIME ZONE,\n  failed_at TIMESTAMP WITH TIME ZONE,\n  \n  attempt_count INTEGER DEFAULT 0,\n  last_error JSONB,\n  provider_response JSONB,\n  \n  -- For distributed queue management\n  visible_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  lease_expiry TIMESTAMP WITH TIME ZONE,\n  worker_id VARCHAR(100),\n  version INTEGER DEFAULT 0, -- Optimistic locking\n  \n  INDEX idx_status (status),\n  INDEX idx_priority_visible (priority DESC, visible_at) WHERE status = 'queued',\n  INDEX idx_scheduled (scheduled_for) WHERE status = 'pending',\n  INDEX idx_idempotency (idempotency_key) WHERE idempotency_key IS NOT NULL,\n  INDEX idx_expires (expires_at) WHERE expires_at IS NOT NULL AND status NOT IN ('sent', 'delivered', 'failed', 'cancelled'),\n  INDEX idx_stuck_leases (lease_expiry, worker_id) WHERE lease_expiry IS NOT NULL\n);\n\n-- Audit trail for state transitions\nCREATE TABLE notification_events (\n  id BIGSERIAL PRIMARY KEY,\n  notification_id UUID NOT NULL REFERENCES notifications(id) ON DELETE CASCADE,\n  event_type VARCHAR(50) NOT NULL,\n  from_status VARCHAR(20),\n  to_status VARCHAR(20),\n  metadata JSONB,\n  error JSONB,\n  worker_id VARCHAR(100),\n  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  \n  INDEX idx_notification (notification_id, created_at DESC),\n  INDEX idx_event_type_time (event_type, created_at DESC)\n);\n\n-- User device tokens for push notifications\nCREATE TABLE device_tokens (\n  id BIGSERIAL PRIMARY KEY,\n  user_id VARCHAR(255) NOT NULL,\n  token VARCHAR(500) NOT NULL UNIQUE,\n  platform VARCHAR(20) NOT NULL,\n  is_active BOOLEAN DEFAULT true,\n  last_used_at TIMESTAMP WITH TIME ZONE,\n  invalid_since TIMESTAMP WITH TIME ZONE,\n  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  \n  INDEX idx_user_active (user_id, is_active) WHERE is_active = true,\n  INDEX idx_cleanup (invalid_since) WHERE invalid_since IS NOT NULL\n);\n\n-- Template storage with versioning\nCREATE TABLE notification_templates (\n  id VARCHAR(100) NOT NULL,\n  channel VARCHAR(20) NOT NULL,\n  name VARCHAR(255) NOT NULL,\n  template_data JSONB NOT NULL,\n  version INTEGER NOT NULL,\n  is_active BOOLEAN DEFAULT true,\n  created_by VARCHAR(255),\n  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  \n  PRIMARY KEY (id, version),\n  INDEX idx_active_templates (id, is_active, version DESC) WHERE is_active = true\n);\n\n-- Rate limiting tracking per provider\nCREATE TABLE provider_rate_limits (\n  provider_id VARCHAR(100) NOT NULL,\n  window_start TIMESTAMP WITH TIME ZONE NOT NULL,\n  window_type VARCHAR(20) NOT NULL, -- 'second', 'minute', 'hour', 'day'\n  request_count INTEGER DEFAULT 0,\n  last_updated TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  \n  PRIMARY KEY (provider_id, window_start, window_type),\n  INDEX idx_current_windows (provider_id, window_type, window_start DESC)\n);\n\n-- Dead letter queue for permanently failed notifications\nCREATE TABLE notification_dlq (\n  id UUID PRIMARY KEY,\n  notification_id UUID NOT NULL,\n  original_request JSONB NOT NULL,\n  final_error JSONB NOT NULL,\n  attempt_count INTEGER NOT NULL,\n  failed_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  \n  INDEX idx_failed_time (failed_at DESC)\n);\n```\n\n### 4. Enhanced Service Workflow\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Client Request  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  NotificationService     \u2502\n\u2502  - Validate input        \u2502\n\u2502  - Check idempotency     \u2502  \u25c4\u2500\u2500 Race condition: Use UPSERT with\n\u2502  - Assign ID             \u2502      ON CONFLICT (idempotency_key)\n\u2502  - Check expiry          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Template Renderer       \u2502\n\u2502  - Fetch active version  \u2502\n\u2502  - Compile variables     \u2502\n\u2502  - Validate output       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Priority Queue Manager  \u2502\n\u2502  - Enqueue with priority \u2502  \u25c4\u2500\u2500 Distributed: Use SELECT FOR UPDATE\n\u2502  - Schedule future sends \u2502      SKIP LOCKED for dequeue\n\u2502  - Set visible_at        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Worker Pool (N workers) \u2502\n\u2502  - Dequeue batch         \u2502  \u25c4\u2500\u2500 Lease-based processing with\n\u2502  - Acquire lease         \u2502      lease_expiry and worker_id\n\u2502  - Update to PROCESSING  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Rate Limiter            \u2502\n\u2502  - Check provider limits \u2502  \u25c4\u2500\u2500 Token bucket per provider\n\u2502  - Delay if needed       \u2502      to prevent API throttling\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Channel Provider        \u2502\n\u2502  - Circuit breaker check \u2502  \u25c4\u2500\u2500 Per-provider circuit breaker\n\u2502  - Send via external API \u2502      with health monitoring\n\u2502  - Handle provider errors\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u251c\u2500\u2500\u2500\u2500\u2500\u25ba Success\n         \u2502       \u2502\n         \u2502       \u25bc\n         \u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502    \u2502  Success Handler     \u2502\n         \u2502    \u2502  - Mark SENT         \u2502\n         \u2502    \u2502  - Log event         \u2502\n         \u2502    \u2502  - Call webhook      \u2502\n         \u2502    \u2502  - Release lease     \u2502\n         \u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u2514\u2500\u2500\u2500\u2500\u2500\u25ba Failure\n                 \u2502\n                 \u25bc\n              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n              \u2502  Failure Handler     \u2502\n              \u2502  - Classify error    \u2502\n              \u2502  - Check retry policy\u2502\n              \u2502  - Requeue w/ backoff\u2502  \u25c4\u2500\u2500 Or move to DLQ\n              \u2502  - Update visible_at \u2502      if max attempts\n              \u2502  - Release lease     \u2502\n              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Background Jobs         \u2502\n\u2502  - Expire old messages   \u2502  \u25c4\u2500\u2500 Periodic cleanup\n\u2502  - Release stuck leases  \u2502      every 60s\n\u2502  - Clean invalid tokens  \u2502\n\u2502  - Archive to cold store \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n### 5. Comprehensive Error Handling\n\n**Error Categories:**\n```typescript\nenum ErrorCategory {\n  VALIDATION = 'validation',\n  RATE_LIMIT = 'rate_limit',\n  TEMPORARY = 'temporary',\n  PERMANENT = 'permanent',\n  PROVIDER = 'provider',\n  INTERNAL = 'internal',\n  TIMEOUT = 'timeout',\n  AUTHENTICATION = 'authentication'\n}\n\nclass NotificationError extends Error {\n  constructor(\n    public category: ErrorCategory,\n    public code: string,\n    message: string,\n    public retryable: boolean,\n    public originalError?: Error,\n    public metadata?: Record<string, any>\n  ) {\n    super(message);\n    this.name = 'NotificationError';\n  }\n}\n```\n\n**Enhanced Circuit Breaker with Half-Open Testing:**\n```typescript\nclass ProviderCircuitBreaker {\n  private failureCount = 0;\n  private successCount = 0;\n  private lastFailureTime?: Date;\n  private lastSuccessTime?: Date;\n  private state: 'closed' | 'open' | 'half-open' = 'closed';\n  \n  constructor(\n    private threshold: number = 5,\n    private timeout: number = 60000,\n    private halfOpenSuccessThreshold: number = 2\n  ) {}\n  \n  async execute<T>(fn: () => Promise<T>): Promise<T> {\n    if (this.state === 'open') {\n      if (Date.now() - this.lastFailureTime!.getTime() > this.timeout) {\n        this.state = 'half-open';\n        this.successCount = 0;\n      } else {\n        throw new NotificationError(\n          ErrorCategory.PROVIDER,\n          'CIRCUIT_OPEN',\n          `Provider circuit breaker is open until ${new Date(this.lastFailureTime!.getTime() + this.timeout).toISOString()}`,\n          true,\n          undefined,\n          { reopensAt: new Date(this.lastFailureTime!.getTime() + this.timeout) }\n        );\n      }\n    }\n    \n    // In half-open, limit concurrent requests\n    if (this.state === 'half-open') {\n      // Only allow one test request at a time\n      // Implementation would use a semaphore/mutex here\n    }\n    \n    try {\n      const result = await fn();\n      this.onSuccess();\n      return result;\n    } catch (error) {\n      this.onFailure(error);\n      throw error;\n    }\n  }\n  \n  private onSuccess() {\n    this.lastSuccessTime = new Date();\n    \n    if (this.state === 'half-open') {\n      this.successCount++;\n      if (this.successCount >= this.halfOpenSuccessThreshold) {\n        this.state = 'closed';\n        this.failureCount = 0;\n      }\n    } else {\n      this.failureCount = 0;\n      this.state = 'closed';\n    }\n  }\n  \n  private onFailure(error: any) {\n    this.failureCount++;\n    this.lastFailureTime = new Date();\n    \n    if (this.state === 'half-open') {\n      // Immediately reopen circuit on half-open failure\n      this.state = 'open';\n    } else if (this.failureCount >= this.threshold) {\n      this.state = 'open';\n    }\n  }\n  \n  getStatus(): { state: string; failureCount: number; lastFailure?: Date } {\n    return {\n      state: this.state,\n      failureCount: this.failureCount,\n      lastFailure: this.lastFailureTime\n    };\n  }\n}\n```\n\n**Distributed Rate Limiter:**\n```typescript\nclass DistributedRateLimiter {\n  constructor(\n    private db: Database,\n    private providerId: string,\n    private limits: RateLimit\n  ) {}\n  \n  async checkAndAcquire(): Promise<{ allowed: boolean; retryAfter?: number }> {\n    const now = new Date();\n    const windows = [\n      { type: 'second', limit: this.limits.requestsPerSecond, durationMs: 1000 },\n      { type: 'minute', limit: this.limits.requestsPerMinute, durationMs: 60000 },\n    ];\n    \n    if (this.limits.requestsPerDay) {\n      windows.push({ \n        type: 'day', \n        limit: this.limits.requestsPerDay, \n        durationMs: 86400000 \n      });\n    }\n    \n    for (const window of windows) {\n      const windowStart = new Date(Math.floor(now.getTime() / window.durationMs) * window.durationMs);\n      \n      // Atomic increment and check\n      const result = await this.db.query(`\n        INSERT INTO provider_rate_limits (provider_id, window_start, window_type, request_count)\n        VALUES ($1, $2, $3, 1)\n        ON CONFLICT (provider_id, window_start, window_type)\n        DO UPDATE SET \n          request_count = provider_rate_limits.request_count + 1,\n          last_updated = NOW()\n        RETURNING request_count\n      `, [this.providerId, windowStart, window.type]);\n      \n      const currentCount = result.rows[0].request_count;\n      \n      if (currentCount > window.limit) {\n        const retryAfter = windowStart.getTime() + window.durationMs - now.getTime();\n        return { allowed: false, retryAfter };\n      }\n    }\n    \n    return { allowed: true };\n  }\n}\n```\n\n### 6. Distributed Queue Implementation\n\n```typescript\nclass PostgresQueueManager implements QueueManager {\n  constructor(private db: Database) {}\n  \n  async enqueue(message: QueuedNotification, priority: NotificationPriority): Promise<string> {\n    const result = await this.db.query(`\n      UPDATE notifications\n      SET \n        status = 'queued',\n        enqueued_at = NOW(),\n        visible_at = COALESCE(scheduled_for, NOW()),\n        updated_at = NOW()\n      WHERE id = $1\n      RETURNING id\n    `, [message.id]);\n    \n    return result.rows[0].id;\n  }\n  \n  async dequeue(workerId: string, batchSize: number): Promise<QueuedNotification[]> {\n    const leaseDuration = 300000; // 5 minutes\n    const now = new Date();\n    const leaseExpiry = new Date(now.getTime() + leaseDuration);\n    \n    // Use SELECT FOR UPDATE SKIP LOCKED for lock-free dequeue\n    const result = await this.db.query(`\n      UPDATE notifications\n      SET \n        status = 'processing',\n        worker_id = $1,\n        lease_expiry = $2,\n        updated_at = NOW(),\n        version = version + 1\n      WHERE id IN (\n        SELECT id\n        FROM notifications\n        WHERE status = 'queued'\n          AND visible_at <= NOW()\n          AND (expires_at IS NULL OR expires_at > NOW())\n        ORDER BY \n          CASE priority\n            WHEN 'urgent' THEN 1\n            WHEN 'high' THEN 2\n            WHEN 'normal' THEN 3\n            WHEN 'low' THEN 4\n          END,\n          visible_at ASC\n        LIMIT $3\n        FOR UPDATE SKIP LOCKED\n      )\n      RETURNING *\n    `, [workerId, leaseExpiry, batchSize]);\n    \n    return result.rows.map(row => this.mapRowToQueuedNotification(row));\n  }\n  \n  async extendLease(id: string, workerId: string, durationMs: number): Promise<boolean> {\n    const newExpiry = new Date(Date.now() + durationMs);\n    \n    const result = await this.db.query(`\n      UPDATE notifications\n      SET \n        lease_expiry = $1,\n        updated_at = NOW()\n      WHERE id = $2 \n        AND worker_id = $3\n        AND status = 'processing'\n        AND lease_expiry > NOW()\n      RETURNING id\n    `, [newExpiry, id, workerId]);\n    \n    return result.rowCount > 0;\n  }\n  \n  async releaseStuckMessages(timeoutMs: number): Promise<number> {\n    const cutoff = new Date(Date.now() - timeoutMs);\n    \n    const result = await this.db.query(`\n      UPDATE notifications\n      SET \n        status = 'queued',\n        worker_id = NULL,\n        lease_expiry = NULL,\n        visible_at = NOW() + interval '30 seconds', -- Brief delay before retry\n        updated_at = NOW()\n      WHERE status = 'processing'\n        AND lease_expiry < $1\n      RETURNING id\n    `, [cutoff]);\n    \n    return result.rowCount;\n  }\n  \n  async requeueWithBackoff(id: string, error: Error, attempt: number): Promise<void> {\n    const retryHandler = new AdaptiveRetryHandler();\n    const notificationError = error instanceof NotificationError \n      ? error \n      : new NotificationError(ErrorCategory.INTERNAL, 'UNKNOWN', error.message, true, error);\n    \n    const decision = retryHandler.shouldRetry(attempt, notificationError);\n    \n    if (!decision.shouldRetry) {\n      // Move to DLQ\n      await this.moveToDLQ(id, notificationError, attempt);\n      return;\n    }\n    \n    const visibleAt = new Date(Date.now() + decision.delayMs!);\n    \n    await this.db.query(`\n      UPDATE notifications\n      SET \n        status = 'queued',\n        worker_id = NULL,\n        lease_expiry = NULL,\n        visible_at = $1,\n        attempt_count = $2,\n        last_error = $3,\n        updated_at = NOW()\n      WHERE id = $4\n    `, [visibleAt, attempt, JSON.stringify(notificationError), id]);\n  }\n  \n  async markComplete(id: string): Promise<void> {\n    await this.db.query(`\n      UPDATE notifications\n      SET \n        status = 'sent',\n        sent_at = NOW(),\n        worker_id = NULL,\n        lease_expiry = NULL,\n        updated_at = NOW()\n      WHERE id = $1\n    `, [id]);\n  }\n  \n  async markFailed(id: string, error: Error): Promise<void> {\n    await this.db.query(`\n      UPDATE notifications\n      SET \n        status = 'failed',\n        failed_at = NOW(),\n        worker_id = NULL,\n        lease_expiry = NULL,\n        last_error = $1,\n        updated_at = NOW()\n      WHERE id = $2\n    `, [JSON.stringify(error), id]);\n  }\n  \n  private async moveToDLQ(id: string, error: NotificationError, attempts: number): Promise<void> {\n    await this.db.query(`\n      WITH original AS (\n        SELECT * FROM notifications WHERE id = $1\n      )\n      INSERT INTO notification_dlq (notification_id, original_request, final_error, attempt_count)\n      SELECT \n        id,\n        jsonb_build_object(\n          'channel', channel,\n          'recipient', recipient,\n          'content', content,\n          'priority', priority\n        ),\n        $2,\n        $3\n      FROM original\n    `, [id, JSON.stringify(error), attempts]);\n    \n    await this.markFailed(id, error);\n  }\n  \n  private mapRowToQueuedNotification(row: any): QueuedNotification {\n    // Implementation details\n    return {} as QueuedNotification;\n  }\n}\n```\n\n### 7. Background Maintenance Jobs\n\n```typescript\nclass MaintenanceScheduler {\n  constructor(\n    private db: Database,\n    private queueManager: QueueManager\n  ) {}\n  \n  start() {\n    // Release stuck messages every 60 seconds\n    setInterval(() => this.releaseStuckLeases(), 60000);\n    \n    // Expire old notifications every 5 minutes\n    setInterval(() => this.expireNotifications(), 300000);\n    \n    // Clean invalid device tokens daily\n    setInterval(() => this.cleanInvalidTokens(), 86400000);\n    \n    // Archive old records weekly\n    setInterval(() => this.archiveOldRecords(), 604800000);\n  }\n  \n  private async releaseStuckLeases() {\n    const released = await this.queueManager.releaseStuckMessages(600000); // 10 min timeout\n    if (released > 0) {\n      console.log(`Released ${released} stuck messages`);\n    }\n  }\n  \n  private async expireNotifications() {\n    await this.db.query(`\n      UPDATE notifications\n      SET \n        status = 'expired',\n        updated_at = NOW()\n      WHERE status IN ('pending', 'queued')\n        AND expires_at IS NOT NULL\n        AND expires_at <= NOW()\n    `);\n  }\n  \n  private async cleanInvalidTokens() {\n    await this.db.query(`\n      DELETE FROM device_tokens\n      WHERE invalid_since IS NOT NULL\n        AND invalid_since < NOW() - interval '30 days'\n    `);\n  }\n  \n  private async archiveOldRecords() {\n    // Move notifications older than 90 days to cold storage\n    const archiveThreshold = new Date(Date.now() - 90 * 24 * 60 * 60 * 1000);\n    \n    await this.db.query(`\n      INSERT INTO notifications_archive\n      SELECT * FROM notifications\n      WHERE created_at < $1\n        AND status IN ('sent', 'delivered', 'failed', 'cancelled', 'expired')\n    `, [archiveThreshold]);\n    \n    await this.db.query(`\n      DELETE FROM notifications\n      WHERE created_at < $1\n        AND status IN ('sent', 'delivered', 'failed', 'cancelled', 'expired')\n    `, [archiveThreshold]);\n  }\n}\n```\n\n### 8. Configuration & Deployment\n\n```typescript\ninterface NotificationConfig {\n  providers: {\n    email: {\n      type: 'sendgrid' | 'ses' | 'smtp';\n      apiKey: string;\n      defaultFrom: string;\n      rateLimit: RateLimit;\n    };\n    push: {\n      type: 'fcm' | 'apns';\n      credentials: any;\n      rateLimit: RateLimit;\n    };\n  };\n  database: {\n    connectionString: string;\n    poolSize: number;\n    maxRetries: number;\n  };\n  queue: {\n    batchSize: number;\n    pollIntervalMs: number;\n    leaseTimeoutMs: number;\n    visibilityTimeoutMs: number;\n  };\n  retry: {\n    maxAttempts: number;\n    baseDelayMs: number;\n    maxDelayMs: number;\n  };\n  workers: {\n    count: number;\n    workerId: string; // Unique per instance\n  };\n  circuitBreaker: {\n    failureThreshold: number;\n    timeoutMs: number;\n    halfOpenSuccessThreshold: number;\n  };\n  observability: {\n    metricsEnabled: boolean;\n    metricsPort: number;\n    tracingEnabled: boolean;\n  };\n}\n```\n\n### 9. Observability & Monitoring\n\n```typescript\ninterface NotificationMetrics {\n  // Counters\n  notificationsSent: Counter;\n  notificationsFailed: Counter;\n  notificationsRetried: Counter;\n  \n  // Gauges\n  queueDepth: Gauge;\n  activeWorkers: Gauge;\n  circuitBreakerState: Gauge;\n  \n  // Histograms\n  processingLatency: Histogram;\n  providerLatency: Histogram;\n  queueWaitTime: Histogram;\n}\n\n// Example Prometheus metrics\nclass PrometheusMetrics {\n  private registry: Registry;\n  \n  constructor() {\n    this.registry = new Registry();\n    this.registerMetrics();\n  }\n  \n  private registerMetrics() {\n    new Counter({\n      name: 'notifications_sent_total',\n      help: 'Total notifications sent',\n      labelNames: ['channel', 'priority', 'status'],\n      registers: [this.registry]\n    });\n    \n    new Histogram({\n      name: 'notification_processing_duration_seconds',\n      help: 'Time to process notification',\n      labelNames: ['channel', 'status'],\n      buckets: [0.1, 0.5, 1, 2, 5, 10],\n      registers: [this.registry]\n    });\n    \n    new Gauge({\n      name: 'notification_queue_depth',\n      help: 'Current queue depth by priority',\n      labelNames: ['priority'],\n      registers: [this.registry]\n    });\n  }\n}\n```\n\n## What I Improved\n\n### 1. **Race Condition Prevention**\n- Added optimistic locking with `version` field to prevent double-processing\n- Used `SELECT FOR UPDATE SKIP LOCKED` for lock-free queue operations\n- Implemented lease-based processing with `lease_expiry` and `worker_id` to handle worker crashes\n- Added `extendLease()` for long-running operations\n\n### 2. **Distributed Queue Robustness**\n- Added `visible_at` field for both scheduled notifications and retry backoff\n- Implemented stuck message recovery with `releaseStuckMessages()`\n- Added Dead Letter Queue (DLQ) for permanently failed notifications\n- Proper priority queue ordering with efficient indexes\n\n### 3. **Edge Cases Handled**\n- **Expiration**: Added `EXPIRED` status and background job to expire old messages\n- **Idempotency with race conditions**: Use `ON CONFLICT (idempotency_key) DO UPDATE` for atomic upsert\n- **Invalid device tokens**: Track `invalid_since` and clean up periodically\n- **Webhook failures**: Non-blocking callback execution (should be async/best-effort)\n- **Batch partial failures**: Added `BatchNotificationResult` with `partialFailure` flag\n\n### 4. **Enhanced Error Handling**\n- Added `TIMEOUT` and `AUTHENTICATION` error categories\n- Adaptive backoff based on error type (longer for rate limits)\n- Half-open circuit breaker testing with success threshold before fully closing\n- Circuit breaker exposes status for monitoring\n\n### 5. **Scalability Improvements**\n- Database-backed distributed rate limiter to prevent API throttling across workers\n- Provider capability metadata for intelligent routing\n- Health check interface for provider monitoring\n- Archive old data to cold storage to keep hot tables small\n- Separate indexes for active queries (`WHERE status = 'queued'`)\n\n### 6. **Operational Excellence**\n- Comprehensive maintenance jobs (stuck leases, expiration, cleanup, archival)\n- Prometheus metrics integration with business and system metrics\n- Retry decision includes reason for debugging\n- Provider-specific rate limit tracking table\n- Cascade delete on events for GDPR compliance\n\n## What I Kept\n\n- Queue-based architecture with strategy pattern for channels\n- Exponential backoff with jitter\n- Circuit breaker pattern per provider\n- Template versioning system\n- Priority queue implementation\n- Idempotency key support\n- Audit trail with events table\n- Core data models and interfaces\n\n## Remaining Concerns\n\n### 1. **Database as Queue Trade-offs**\n- PostgreSQL queue works well up to ~10K msgs/sec, but may need Redis/SQS beyond that\n- Consider adding `notifications_queue` table separate from `notifications` for higher throughput\n- Dead letter processing: Should there be automated retry or require manual intervention?\n\n### 2. **Webhook Delivery Guarantees**\n- Callback URLs should be called async with their own retry logic\n- Should failed webhooks block notification completion? (Current design: no)\n- Consider separate webhook delivery queue\n\n### 3. **Multi-tenancy**\n- Current design supports single API keys per provider\n- For SaaS, need tenant-specific provider configs and rate limits\n- Add `tenant_id` column and tenant-aware queries\n\n### 4. **Provider Failover**\n- No fallback provider if primary is down (e.g., SendGrid \u2192 SES)\n- Could add provider priority list per channel type\n\n### 5. **Cost Tracking**\n- `estimateCost()` exists but not persisted or aggregated\n- Should we track actual costs per notification for billing?\n\n### 6. **Horizontal Scaling Considerations**\n- Worker ID must be unique per instance (use hostname + PID or UUID)\n- Connection pool sizing: `workers * poolSize` shouldn't exceed DB max connections\n- Consider leader election for maintenance jobs (currently all workers would run them)\n\n## Convergence Status\n\n**ITERATING** - Added significant improvements but want architect's feedback on database scaling strategy and webhook semantics.",
        "prompt_for_other": "Please review the distributed queue implementation with lease-based processing. Are there any race conditions I missed in the dequeue/requeue flow? Also, should webhook callbacks be blocking (current: non-blocking best-effort) and how should we handle scenarios where the database becomes the bottleneck (10K+ msgs/sec)? Consider whether we need a separate queue table or should migrate to Redis/SQS at scale.",
        "convergence_signal": "ITERATING",
        "raw_response": "## Design\n\n# Notification Service Architecture\n\n## System Overview\nA scalable, plugin-based notification service supporting email and push notifications with robust delivery guarantees, distributed queue management, and comprehensive observability.\n\n## Architecture Components\n\n### 1. Core Components\n\n**NotificationService (Orchestrator)**\n```typescript\ninterface NotificationService {\n  send(request: NotificationRequest): Promise<NotificationResult>;\n  sendBatch(requests: NotificationRequest[]): Promise<BatchNotificationResult>;\n  getStatus(notificationId: string): Promise<NotificationStatus>;\n  cancelScheduled(notificationId: string): Promise<CancelResult>;\n  retryFailed(notificationId: string): Promise<NotificationResult>;\n}\n\ninterface BatchNotificationResult {\n  results: NotificationResult[];\n  successCount: number;\n  failureCount: number;\n  partialFailure: boolean;\n}\n\ninterface CancelResult {\n  notificationId: string;\n  cancelled: boolean;\n  reason?: string; // e.g., \"already sent\", \"not found\"\n}\n```\n\n**Channel Providers (Strategy Pattern)**\n```typescript\ninterface ChannelProvider {\n  readonly channelType: ChannelType;\n  readonly capabilities: ProviderCapabilities;\n  send(payload: ChannelPayload): Promise<SendResult>;\n  validateRecipient(recipient: Recipient): ValidationResult;\n  estimateCost(payload: ChannelPayload): number;\n  healthCheck(): Promise<HealthStatus>;\n}\n\ninterface ProviderCapabilities {\n  supportsBatch: boolean;\n  maxBatchSize?: number;\n  supportsScheduling: boolean;\n  supportsDeliveryTracking: boolean;\n  rateLimit: RateLimit;\n}\n\ninterface RateLimit {\n  requestsPerSecond: number;\n  requestsPerMinute: number;\n  requestsPerDay?: number;\n}\n\ninterface ValidationResult {\n  valid: boolean;\n  errors: string[];\n  warnings?: string[];\n}\n\ninterface HealthStatus {\n  healthy: boolean;\n  latency?: number;\n  lastChecked: Date;\n  details?: any;\n}\n\n// Implementations\nclass EmailProvider implements ChannelProvider\nclass PushProvider implements ChannelProvider\n```\n\n**Distributed Queue Manager**\n```typescript\ninterface QueueManager {\n  enqueue(message: QueuedNotification, priority: NotificationPriority): Promise<string>;\n  enqueueBatch(messages: QueuedNotification[]): Promise<string[]>;\n  dequeue(workerId: string, batchSize: number): Promise<QueuedNotification[]>;\n  requeueWithBackoff(id: string, error: Error, attempt: number): Promise<void>;\n  markComplete(id: string): Promise<void>;\n  markFailed(id: string, error: Error): Promise<void>;\n  extendLease(id: string, workerId: string, durationMs: number): Promise<boolean>;\n  releaseStuckMessages(timeoutMs: number): Promise<number>;\n}\n\ninterface QueuedNotification {\n  id: string;\n  notification: NotificationRequest;\n  enqueuedAt: Date;\n  visibleAt: Date; // For scheduled notifications or retry backoff\n  leaseExpiry?: Date;\n  workerId?: string;\n  attempt: number;\n}\n```\n\n**Retry Handler with Jitter**\n```typescript\ninterface RetryHandler {\n  shouldRetry(attempt: number, error: NotificationError): RetryDecision;\n  calculateBackoff(attempt: number, error: NotificationError): number;\n  maxAttempts: number;\n}\n\ninterface RetryDecision {\n  shouldRetry: boolean;\n  reason: string;\n  delayMs?: number;\n}\n\nclass AdaptiveRetryHandler implements RetryHandler {\n  maxAttempts = 5;\n  baseDelay = 1000;\n  maxDelay = 300000;\n  \n  shouldRetry(attempt: number, error: NotificationError): RetryDecision {\n    if (attempt >= this.maxAttempts) {\n      return { shouldRetry: false, reason: 'max_attempts_exceeded' };\n    }\n    \n    if (!error.retryable) {\n      return { shouldRetry: false, reason: 'non_retryable_error' };\n    }\n    \n    // Don't retry validation errors\n    if (error.category === ErrorCategory.VALIDATION) {\n      return { shouldRetry: false, reason: 'validation_error' };\n    }\n    \n    // Rate limits get longer backoff\n    if (error.category === ErrorCategory.RATE_LIMIT) {\n      return { \n        shouldRetry: true, \n        reason: 'rate_limit',\n        delayMs: this.calculateBackoff(attempt, error)\n      };\n    }\n    \n    return { \n      shouldRetry: true, \n      reason: 'temporary_error',\n      delayMs: this.calculateBackoff(attempt, error)\n    };\n  }\n  \n  calculateBackoff(attempt: number, error: NotificationError): number {\n    let multiplier = 1;\n    \n    // Longer backoff for rate limits\n    if (error.category === ErrorCategory.RATE_LIMIT) {\n      multiplier = 3;\n    }\n    \n    const exponential = this.baseDelay * Math.pow(2, attempt) * multiplier;\n    const jitter = Math.random() * 1000; // Full jitter\n    return Math.min(exponential + jitter, this.maxDelay);\n  }\n}\n```\n\n### 2. Data Models\n\n```typescript\nenum ChannelType {\n  EMAIL = 'email',\n  PUSH = 'push'\n}\n\nenum NotificationPriority {\n  LOW = 'low',\n  NORMAL = 'normal',\n  HIGH = 'high',\n  URGENT = 'urgent'\n}\n\nenum NotificationStatus {\n  PENDING = 'pending',\n  QUEUED = 'queued',\n  PROCESSING = 'processing',\n  SENT = 'sent',\n  DELIVERED = 'delivered',\n  FAILED = 'failed',\n  CANCELLED = 'cancelled',\n  EXPIRED = 'expired'\n}\n\ninterface NotificationRequest {\n  id?: string;\n  channel: ChannelType;\n  recipient: Recipient;\n  content: NotificationContent;\n  priority: NotificationPriority;\n  metadata?: Record<string, any>;\n  scheduledFor?: Date;\n  expiresAt?: Date;\n  idempotencyKey?: string;\n  callbackUrl?: string; // Webhook for delivery status\n  maxAttempts?: number; // Override default retry policy\n}\n\ninterface Recipient {\n  email?: string;\n  deviceTokens?: string[];\n  userId?: string;\n  firstName?: string;\n  lastName?: string;\n  locale?: string;\n  timezone?: string;\n}\n\ninterface NotificationContent {\n  subject?: string;\n  htmlBody?: string;\n  textBody?: string;\n  attachments?: Attachment[];\n  title?: string;\n  body: string;\n  icon?: string;\n  badge?: number;\n  sound?: string;\n  data?: Record<string, any>;\n  templateId?: string;\n  templateVariables?: Record<string, any>;\n}\n\ninterface Attachment {\n  filename: string;\n  contentType: string;\n  content: Buffer | string;\n  size: number;\n}\n\ninterface NotificationResult {\n  notificationId: string;\n  status: NotificationStatus;\n  channel: ChannelType;\n  enqueuedAt: Date;\n  sentAt?: Date;\n  deliveredAt?: Date;\n  failedAt?: Date;\n  error?: NotificationError;\n  providerResponse?: any;\n  attemptCount: number;\n}\n\ninterface NotificationError {\n  code: string;\n  message: string;\n  category: ErrorCategory;\n  retryable: boolean;\n  originalError?: any;\n}\n```\n\n### 3. Enhanced Database Schema\n\n```sql\n-- Main notification records with optimistic locking\nCREATE TABLE notifications (\n  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n  channel VARCHAR(20) NOT NULL,\n  recipient JSONB NOT NULL,\n  content JSONB NOT NULL,\n  priority VARCHAR(20) NOT NULL,\n  status VARCHAR(20) NOT NULL,\n  metadata JSONB,\n  scheduled_for TIMESTAMP WITH TIME ZONE,\n  expires_at TIMESTAMP WITH TIME ZONE,\n  idempotency_key VARCHAR(255) UNIQUE,\n  callback_url TEXT,\n  max_attempts INTEGER DEFAULT 5,\n  \n  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  enqueued_at TIMESTAMP WITH TIME ZONE,\n  sent_at TIMESTAMP WITH TIME ZONE,\n  delivered_at TIMESTAMP WITH TIME ZONE,\n  failed_at TIMESTAMP WITH TIME ZONE,\n  \n  attempt_count INTEGER DEFAULT 0,\n  last_error JSONB,\n  provider_response JSONB,\n  \n  -- For distributed queue management\n  visible_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  lease_expiry TIMESTAMP WITH TIME ZONE,\n  worker_id VARCHAR(100),\n  version INTEGER DEFAULT 0, -- Optimistic locking\n  \n  INDEX idx_status (status),\n  INDEX idx_priority_visible (priority DESC, visible_at) WHERE status = 'queued',\n  INDEX idx_scheduled (scheduled_for) WHERE status = 'pending',\n  INDEX idx_idempotency (idempotency_key) WHERE idempotency_key IS NOT NULL,\n  INDEX idx_expires (expires_at) WHERE expires_at IS NOT NULL AND status NOT IN ('sent', 'delivered', 'failed', 'cancelled'),\n  INDEX idx_stuck_leases (lease_expiry, worker_id) WHERE lease_expiry IS NOT NULL\n);\n\n-- Audit trail for state transitions\nCREATE TABLE notification_events (\n  id BIGSERIAL PRIMARY KEY,\n  notification_id UUID NOT NULL REFERENCES notifications(id) ON DELETE CASCADE,\n  event_type VARCHAR(50) NOT NULL,\n  from_status VARCHAR(20),\n  to_status VARCHAR(20),\n  metadata JSONB,\n  error JSONB,\n  worker_id VARCHAR(100),\n  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  \n  INDEX idx_notification (notification_id, created_at DESC),\n  INDEX idx_event_type_time (event_type, created_at DESC)\n);\n\n-- User device tokens for push notifications\nCREATE TABLE device_tokens (\n  id BIGSERIAL PRIMARY KEY,\n  user_id VARCHAR(255) NOT NULL,\n  token VARCHAR(500) NOT NULL UNIQUE,\n  platform VARCHAR(20) NOT NULL,\n  is_active BOOLEAN DEFAULT true,\n  last_used_at TIMESTAMP WITH TIME ZONE,\n  invalid_since TIMESTAMP WITH TIME ZONE,\n  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  \n  INDEX idx_user_active (user_id, is_active) WHERE is_active = true,\n  INDEX idx_cleanup (invalid_since) WHERE invalid_since IS NOT NULL\n);\n\n-- Template storage with versioning\nCREATE TABLE notification_templates (\n  id VARCHAR(100) NOT NULL,\n  channel VARCHAR(20) NOT NULL,\n  name VARCHAR(255) NOT NULL,\n  template_data JSONB NOT NULL,\n  version INTEGER NOT NULL,\n  is_active BOOLEAN DEFAULT true,\n  created_by VARCHAR(255),\n  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  \n  PRIMARY KEY (id, version),\n  INDEX idx_active_templates (id, is_active, version DESC) WHERE is_active = true\n);\n\n-- Rate limiting tracking per provider\nCREATE TABLE provider_rate_limits (\n  provider_id VARCHAR(100) NOT NULL,\n  window_start TIMESTAMP WITH TIME ZONE NOT NULL,\n  window_type VARCHAR(20) NOT NULL, -- 'second', 'minute', 'hour', 'day'\n  request_count INTEGER DEFAULT 0,\n  last_updated TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  \n  PRIMARY KEY (provider_id, window_start, window_type),\n  INDEX idx_current_windows (provider_id, window_type, window_start DESC)\n);\n\n-- Dead letter queue for permanently failed notifications\nCREATE TABLE notification_dlq (\n  id UUID PRIMARY KEY,\n  notification_id UUID NOT NULL,\n  original_request JSONB NOT NULL,\n  final_error JSONB NOT NULL,\n  attempt_count INTEGER NOT NULL,\n  failed_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  \n  INDEX idx_failed_time (failed_at DESC)\n);\n```\n\n### 4. Enhanced Service Workflow\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Client Request  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  NotificationService     \u2502\n\u2502  - Validate input        \u2502\n\u2502  - Check idempotency     \u2502  \u25c4\u2500\u2500 Race condition: Use UPSERT with\n\u2502  - Assign ID             \u2502      ON CONFLICT (idempotency_key)\n\u2502  - Check expiry          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Template Renderer       \u2502\n\u2502  - Fetch active version  \u2502\n\u2502  - Compile variables     \u2502\n\u2502  - Validate output       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Priority Queue Manager  \u2502\n\u2502  - Enqueue with priority \u2502  \u25c4\u2500\u2500 Distributed: Use SELECT FOR UPDATE\n\u2502  - Schedule future sends \u2502      SKIP LOCKED for dequeue\n\u2502  - Set visible_at        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Worker Pool (N workers) \u2502\n\u2502  - Dequeue batch         \u2502  \u25c4\u2500\u2500 Lease-based processing with\n\u2502  - Acquire lease         \u2502      lease_expiry and worker_id\n\u2502  - Update to PROCESSING  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Rate Limiter            \u2502\n\u2502  - Check provider limits \u2502  \u25c4\u2500\u2500 Token bucket per provider\n\u2502  - Delay if needed       \u2502      to prevent API throttling\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Channel Provider        \u2502\n\u2502  - Circuit breaker check \u2502  \u25c4\u2500\u2500 Per-provider circuit breaker\n\u2502  - Send via external API \u2502      with health monitoring\n\u2502  - Handle provider errors\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u251c\u2500\u2500\u2500\u2500\u2500\u25ba Success\n         \u2502       \u2502\n         \u2502       \u25bc\n         \u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502    \u2502  Success Handler     \u2502\n         \u2502    \u2502  - Mark SENT         \u2502\n         \u2502    \u2502  - Log event         \u2502\n         \u2502    \u2502  - Call webhook      \u2502\n         \u2502    \u2502  - Release lease     \u2502\n         \u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u2514\u2500\u2500\u2500\u2500\u2500\u25ba Failure\n                 \u2502\n                 \u25bc\n              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n              \u2502  Failure Handler     \u2502\n              \u2502  - Classify error    \u2502\n              \u2502  - Check retry policy\u2502\n              \u2502  - Requeue w/ backoff\u2502  \u25c4\u2500\u2500 Or move to DLQ\n              \u2502  - Update visible_at \u2502      if max attempts\n              \u2502  - Release lease     \u2502\n              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Background Jobs         \u2502\n\u2502  - Expire old messages   \u2502  \u25c4\u2500\u2500 Periodic cleanup\n\u2502  - Release stuck leases  \u2502      every 60s\n\u2502  - Clean invalid tokens  \u2502\n\u2502  - Archive to cold store \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n### 5. Comprehensive Error Handling\n\n**Error Categories:**\n```typescript\nenum ErrorCategory {\n  VALIDATION = 'validation',\n  RATE_LIMIT = 'rate_limit',\n  TEMPORARY = 'temporary',\n  PERMANENT = 'permanent',\n  PROVIDER = 'provider',\n  INTERNAL = 'internal',\n  TIMEOUT = 'timeout',\n  AUTHENTICATION = 'authentication'\n}\n\nclass NotificationError extends Error {\n  constructor(\n    public category: ErrorCategory,\n    public code: string,\n    message: string,\n    public retryable: boolean,\n    public originalError?: Error,\n    public metadata?: Record<string, any>\n  ) {\n    super(message);\n    this.name = 'NotificationError';\n  }\n}\n```\n\n**Enhanced Circuit Breaker with Half-Open Testing:**\n```typescript\nclass ProviderCircuitBreaker {\n  private failureCount = 0;\n  private successCount = 0;\n  private lastFailureTime?: Date;\n  private lastSuccessTime?: Date;\n  private state: 'closed' | 'open' | 'half-open' = 'closed';\n  \n  constructor(\n    private threshold: number = 5,\n    private timeout: number = 60000,\n    private halfOpenSuccessThreshold: number = 2\n  ) {}\n  \n  async execute<T>(fn: () => Promise<T>): Promise<T> {\n    if (this.state === 'open') {\n      if (Date.now() - this.lastFailureTime!.getTime() > this.timeout) {\n        this.state = 'half-open';\n        this.successCount = 0;\n      } else {\n        throw new NotificationError(\n          ErrorCategory.PROVIDER,\n          'CIRCUIT_OPEN',\n          `Provider circuit breaker is open until ${new Date(this.lastFailureTime!.getTime() + this.timeout).toISOString()}`,\n          true,\n          undefined,\n          { reopensAt: new Date(this.lastFailureTime!.getTime() + this.timeout) }\n        );\n      }\n    }\n    \n    // In half-open, limit concurrent requests\n    if (this.state === 'half-open') {\n      // Only allow one test request at a time\n      // Implementation would use a semaphore/mutex here\n    }\n    \n    try {\n      const result = await fn();\n      this.onSuccess();\n      return result;\n    } catch (error) {\n      this.onFailure(error);\n      throw error;\n    }\n  }\n  \n  private onSuccess() {\n    this.lastSuccessTime = new Date();\n    \n    if (this.state === 'half-open') {\n      this.successCount++;\n      if (this.successCount >= this.halfOpenSuccessThreshold) {\n        this.state = 'closed';\n        this.failureCount = 0;\n      }\n    } else {\n      this.failureCount = 0;\n      this.state = 'closed';\n    }\n  }\n  \n  private onFailure(error: any) {\n    this.failureCount++;\n    this.lastFailureTime = new Date();\n    \n    if (this.state === 'half-open') {\n      // Immediately reopen circuit on half-open failure\n      this.state = 'open';\n    } else if (this.failureCount >= this.threshold) {\n      this.state = 'open';\n    }\n  }\n  \n  getStatus(): { state: string; failureCount: number; lastFailure?: Date } {\n    return {\n      state: this.state,\n      failureCount: this.failureCount,\n      lastFailure: this.lastFailureTime\n    };\n  }\n}\n```\n\n**Distributed Rate Limiter:**\n```typescript\nclass DistributedRateLimiter {\n  constructor(\n    private db: Database,\n    private providerId: string,\n    private limits: RateLimit\n  ) {}\n  \n  async checkAndAcquire(): Promise<{ allowed: boolean; retryAfter?: number }> {\n    const now = new Date();\n    const windows = [\n      { type: 'second', limit: this.limits.requestsPerSecond, durationMs: 1000 },\n      { type: 'minute', limit: this.limits.requestsPerMinute, durationMs: 60000 },\n    ];\n    \n    if (this.limits.requestsPerDay) {\n      windows.push({ \n        type: 'day', \n        limit: this.limits.requestsPerDay, \n        durationMs: 86400000 \n      });\n    }\n    \n    for (const window of windows) {\n      const windowStart = new Date(Math.floor(now.getTime() / window.durationMs) * window.durationMs);\n      \n      // Atomic increment and check\n      const result = await this.db.query(`\n        INSERT INTO provider_rate_limits (provider_id, window_start, window_type, request_count)\n        VALUES ($1, $2, $3, 1)\n        ON CONFLICT (provider_id, window_start, window_type)\n        DO UPDATE SET \n          request_count = provider_rate_limits.request_count + 1,\n          last_updated = NOW()\n        RETURNING request_count\n      `, [this.providerId, windowStart, window.type]);\n      \n      const currentCount = result.rows[0].request_count;\n      \n      if (currentCount > window.limit) {\n        const retryAfter = windowStart.getTime() + window.durationMs - now.getTime();\n        return { allowed: false, retryAfter };\n      }\n    }\n    \n    return { allowed: true };\n  }\n}\n```\n\n### 6. Distributed Queue Implementation\n\n```typescript\nclass PostgresQueueManager implements QueueManager {\n  constructor(private db: Database) {}\n  \n  async enqueue(message: QueuedNotification, priority: NotificationPriority): Promise<string> {\n    const result = await this.db.query(`\n      UPDATE notifications\n      SET \n        status = 'queued',\n        enqueued_at = NOW(),\n        visible_at = COALESCE(scheduled_for, NOW()),\n        updated_at = NOW()\n      WHERE id = $1\n      RETURNING id\n    `, [message.id]);\n    \n    return result.rows[0].id;\n  }\n  \n  async dequeue(workerId: string, batchSize: number): Promise<QueuedNotification[]> {\n    const leaseDuration = 300000; // 5 minutes\n    const now = new Date();\n    const leaseExpiry = new Date(now.getTime() + leaseDuration);\n    \n    // Use SELECT FOR UPDATE SKIP LOCKED for lock-free dequeue\n    const result = await this.db.query(`\n      UPDATE notifications\n      SET \n        status = 'processing',\n        worker_id = $1,\n        lease_expiry = $2,\n        updated_at = NOW(),\n        version = version + 1\n      WHERE id IN (\n        SELECT id\n        FROM notifications\n        WHERE status = 'queued'\n          AND visible_at <= NOW()\n          AND (expires_at IS NULL OR expires_at > NOW())\n        ORDER BY \n          CASE priority\n            WHEN 'urgent' THEN 1\n            WHEN 'high' THEN 2\n            WHEN 'normal' THEN 3\n            WHEN 'low' THEN 4\n          END,\n          visible_at ASC\n        LIMIT $3\n        FOR UPDATE SKIP LOCKED\n      )\n      RETURNING *\n    `, [workerId, leaseExpiry, batchSize]);\n    \n    return result.rows.map(row => this.mapRowToQueuedNotification(row));\n  }\n  \n  async extendLease(id: string, workerId: string, durationMs: number): Promise<boolean> {\n    const newExpiry = new Date(Date.now() + durationMs);\n    \n    const result = await this.db.query(`\n      UPDATE notifications\n      SET \n        lease_expiry = $1,\n        updated_at = NOW()\n      WHERE id = $2 \n        AND worker_id = $3\n        AND status = 'processing'\n        AND lease_expiry > NOW()\n      RETURNING id\n    `, [newExpiry, id, workerId]);\n    \n    return result.rowCount > 0;\n  }\n  \n  async releaseStuckMessages(timeoutMs: number): Promise<number> {\n    const cutoff = new Date(Date.now() - timeoutMs);\n    \n    const result = await this.db.query(`\n      UPDATE notifications\n      SET \n        status = 'queued',\n        worker_id = NULL,\n        lease_expiry = NULL,\n        visible_at = NOW() + interval '30 seconds', -- Brief delay before retry\n        updated_at = NOW()\n      WHERE status = 'processing'\n        AND lease_expiry < $1\n      RETURNING id\n    `, [cutoff]);\n    \n    return result.rowCount;\n  }\n  \n  async requeueWithBackoff(id: string, error: Error, attempt: number): Promise<void> {\n    const retryHandler = new AdaptiveRetryHandler();\n    const notificationError = error instanceof NotificationError \n      ? error \n      : new NotificationError(ErrorCategory.INTERNAL, 'UNKNOWN', error.message, true, error);\n    \n    const decision = retryHandler.shouldRetry(attempt, notificationError);\n    \n    if (!decision.shouldRetry) {\n      // Move to DLQ\n      await this.moveToDLQ(id, notificationError, attempt);\n      return;\n    }\n    \n    const visibleAt = new Date(Date.now() + decision.delayMs!);\n    \n    await this.db.query(`\n      UPDATE notifications\n      SET \n        status = 'queued',\n        worker_id = NULL,\n        lease_expiry = NULL,\n        visible_at = $1,\n        attempt_count = $2,\n        last_error = $3,\n        updated_at = NOW()\n      WHERE id = $4\n    `, [visibleAt, attempt, JSON.stringify(notificationError), id]);\n  }\n  \n  async markComplete(id: string): Promise<void> {\n    await this.db.query(`\n      UPDATE notifications\n      SET \n        status = 'sent',\n        sent_at = NOW(),\n        worker_id = NULL,\n        lease_expiry = NULL,\n        updated_at = NOW()\n      WHERE id = $1\n    `, [id]);\n  }\n  \n  async markFailed(id: string, error: Error): Promise<void> {\n    await this.db.query(`\n      UPDATE notifications\n      SET \n        status = 'failed',\n        failed_at = NOW(),\n        worker_id = NULL,\n        lease_expiry = NULL,\n        last_error = $1,\n        updated_at = NOW()\n      WHERE id = $2\n    `, [JSON.stringify(error), id]);\n  }\n  \n  private async moveToDLQ(id: string, error: NotificationError, attempts: number): Promise<void> {\n    await this.db.query(`\n      WITH original AS (\n        SELECT * FROM notifications WHERE id = $1\n      )\n      INSERT INTO notification_dlq (notification_id, original_request, final_error, attempt_count)\n      SELECT \n        id,\n        jsonb_build_object(\n          'channel', channel,\n          'recipient', recipient,\n          'content', content,\n          'priority', priority\n        ),\n        $2,\n        $3\n      FROM original\n    `, [id, JSON.stringify(error), attempts]);\n    \n    await this.markFailed(id, error);\n  }\n  \n  private mapRowToQueuedNotification(row: any): QueuedNotification {\n    // Implementation details\n    return {} as QueuedNotification;\n  }\n}\n```\n\n### 7. Background Maintenance Jobs\n\n```typescript\nclass MaintenanceScheduler {\n  constructor(\n    private db: Database,\n    private queueManager: QueueManager\n  ) {}\n  \n  start() {\n    // Release stuck messages every 60 seconds\n    setInterval(() => this.releaseStuckLeases(), 60000);\n    \n    // Expire old notifications every 5 minutes\n    setInterval(() => this.expireNotifications(), 300000);\n    \n    // Clean invalid device tokens daily\n    setInterval(() => this.cleanInvalidTokens(), 86400000);\n    \n    // Archive old records weekly\n    setInterval(() => this.archiveOldRecords(), 604800000);\n  }\n  \n  private async releaseStuckLeases() {\n    const released = await this.queueManager.releaseStuckMessages(600000); // 10 min timeout\n    if (released > 0) {\n      console.log(`Released ${released} stuck messages`);\n    }\n  }\n  \n  private async expireNotifications() {\n    await this.db.query(`\n      UPDATE notifications\n      SET \n        status = 'expired',\n        updated_at = NOW()\n      WHERE status IN ('pending', 'queued')\n        AND expires_at IS NOT NULL\n        AND expires_at <= NOW()\n    `);\n  }\n  \n  private async cleanInvalidTokens() {\n    await this.db.query(`\n      DELETE FROM device_tokens\n      WHERE invalid_since IS NOT NULL\n        AND invalid_since < NOW() - interval '30 days'\n    `);\n  }\n  \n  private async archiveOldRecords() {\n    // Move notifications older than 90 days to cold storage\n    const archiveThreshold = new Date(Date.now() - 90 * 24 * 60 * 60 * 1000);\n    \n    await this.db.query(`\n      INSERT INTO notifications_archive\n      SELECT * FROM notifications\n      WHERE created_at < $1\n        AND status IN ('sent', 'delivered', 'failed', 'cancelled', 'expired')\n    `, [archiveThreshold]);\n    \n    await this.db.query(`\n      DELETE FROM notifications\n      WHERE created_at < $1\n        AND status IN ('sent', 'delivered', 'failed', 'cancelled', 'expired')\n    `, [archiveThreshold]);\n  }\n}\n```\n\n### 8. Configuration & Deployment\n\n```typescript\ninterface NotificationConfig {\n  providers: {\n    email: {\n      type: 'sendgrid' | 'ses' | 'smtp';\n      apiKey: string;\n      defaultFrom: string;\n      rateLimit: RateLimit;\n    };\n    push: {\n      type: 'fcm' | 'apns';\n      credentials: any;\n      rateLimit: RateLimit;\n    };\n  };\n  database: {\n    connectionString: string;\n    poolSize: number;\n    maxRetries: number;\n  };\n  queue: {\n    batchSize: number;\n    pollIntervalMs: number;\n    leaseTimeoutMs: number;\n    visibilityTimeoutMs: number;\n  };\n  retry: {\n    maxAttempts: number;\n    baseDelayMs: number;\n    maxDelayMs: number;\n  };\n  workers: {\n    count: number;\n    workerId: string; // Unique per instance\n  };\n  circuitBreaker: {\n    failureThreshold: number;\n    timeoutMs: number;\n    halfOpenSuccessThreshold: number;\n  };\n  observability: {\n    metricsEnabled: boolean;\n    metricsPort: number;\n    tracingEnabled: boolean;\n  };\n}\n```\n\n### 9. Observability & Monitoring\n\n```typescript\ninterface NotificationMetrics {\n  // Counters\n  notificationsSent: Counter;\n  notificationsFailed: Counter;\n  notificationsRetried: Counter;\n  \n  // Gauges\n  queueDepth: Gauge;\n  activeWorkers: Gauge;\n  circuitBreakerState: Gauge;\n  \n  // Histograms\n  processingLatency: Histogram;\n  providerLatency: Histogram;\n  queueWaitTime: Histogram;\n}\n\n// Example Prometheus metrics\nclass PrometheusMetrics {\n  private registry: Registry;\n  \n  constructor() {\n    this.registry = new Registry();\n    this.registerMetrics();\n  }\n  \n  private registerMetrics() {\n    new Counter({\n      name: 'notifications_sent_total',\n      help: 'Total notifications sent',\n      labelNames: ['channel', 'priority', 'status'],\n      registers: [this.registry]\n    });\n    \n    new Histogram({\n      name: 'notification_processing_duration_seconds',\n      help: 'Time to process notification',\n      labelNames: ['channel', 'status'],\n      buckets: [0.1, 0.5, 1, 2, 5, 10],\n      registers: [this.registry]\n    });\n    \n    new Gauge({\n      name: 'notification_queue_depth',\n      help: 'Current queue depth by priority',\n      labelNames: ['priority'],\n      registers: [this.registry]\n    });\n  }\n}\n```\n\n## What I Improved\n\n### 1. **Race Condition Prevention**\n- Added optimistic locking with `version` field to prevent double-processing\n- Used `SELECT FOR UPDATE SKIP LOCKED` for lock-free queue operations\n- Implemented lease-based processing with `lease_expiry` and `worker_id` to handle worker crashes\n- Added `extendLease()` for long-running operations\n\n### 2. **Distributed Queue Robustness**\n- Added `visible_at` field for both scheduled notifications and retry backoff\n- Implemented stuck message recovery with `releaseStuckMessages()`\n- Added Dead Letter Queue (DLQ) for permanently failed notifications\n- Proper priority queue ordering with efficient indexes\n\n### 3. **Edge Cases Handled**\n- **Expiration**: Added `EXPIRED` status and background job to expire old messages\n- **Idempotency with race conditions**: Use `ON CONFLICT (idempotency_key) DO UPDATE` for atomic upsert\n- **Invalid device tokens**: Track `invalid_since` and clean up periodically\n- **Webhook failures**: Non-blocking callback execution (should be async/best-effort)\n- **Batch partial failures**: Added `BatchNotificationResult` with `partialFailure` flag\n\n### 4. **Enhanced Error Handling**\n- Added `TIMEOUT` and `AUTHENTICATION` error categories\n- Adaptive backoff based on error type (longer for rate limits)\n- Half-open circuit breaker testing with success threshold before fully closing\n- Circuit breaker exposes status for monitoring\n\n### 5. **Scalability Improvements**\n- Database-backed distributed rate limiter to prevent API throttling across workers\n- Provider capability metadata for intelligent routing\n- Health check interface for provider monitoring\n- Archive old data to cold storage to keep hot tables small\n- Separate indexes for active queries (`WHERE status = 'queued'`)\n\n### 6. **Operational Excellence**\n- Comprehensive maintenance jobs (stuck leases, expiration, cleanup, archival)\n- Prometheus metrics integration with business and system metrics\n- Retry decision includes reason for debugging\n- Provider-specific rate limit tracking table\n- Cascade delete on events for GDPR compliance\n\n## What I Kept\n\n- Queue-based architecture with strategy pattern for channels\n- Exponential backoff with jitter\n- Circuit breaker pattern per provider\n- Template versioning system\n- Priority queue implementation\n- Idempotency key support\n- Audit trail with events table\n- Core data models and interfaces\n\n## Remaining Concerns\n\n### 1. **Database as Queue Trade-offs**\n- PostgreSQL queue works well up to ~10K msgs/sec, but may need Redis/SQS beyond that\n- Consider adding `notifications_queue` table separate from `notifications` for higher throughput\n- Dead letter processing: Should there be automated retry or require manual intervention?\n\n### 2. **Webhook Delivery Guarantees**\n- Callback URLs should be called async with their own retry logic\n- Should failed webhooks block notification completion? (Current design: no)\n- Consider separate webhook delivery queue\n\n### 3. **Multi-tenancy**\n- Current design supports single API keys per provider\n- For SaaS, need tenant-specific provider configs and rate limits\n- Add `tenant_id` column and tenant-aware queries\n\n### 4. **Provider Failover**\n- No fallback provider if primary is down (e.g., SendGrid \u2192 SES)\n- Could add provider priority list per channel type\n\n### 5. **Cost Tracking**\n- `estimateCost()` exists but not persisted or aggregated\n- Should we track actual costs per notification for billing?\n\n### 6. **Horizontal Scaling Considerations**\n- Worker ID must be unique per instance (use hostname + PID or UUID)\n- Connection pool sizing: `workers * poolSize` shouldn't exceed DB max connections\n- Consider leader election for maintenance jobs (currently all workers would run them)\n\n## Convergence Status\n\n**ITERATING** - Added significant improvements but want architect's feedback on database scaling strategy and webhook semantics.\n\nPROMPT_FOR_ARCHITECT:\nPlease review the distributed queue implementation with lease-based processing. Are there any race conditions I missed in the dequeue/requeue flow? Also, should webhook callbacks be blocking (current: non-blocking best-effort) and how should we handle scenarios where the database becomes the bottleneck (10K+ msgs/sec)? Consider whether we need a separate queue table or should migrate to Redis/SQS at scale."
      }
    },
    {
      "round_number": 2,
      "agent_a": {
        "content": "## Design\n\n# Notification Service Architecture\n\n## System Overview\nA horizontally-scalable notification service supporting pluggable channels (email, push, SMS, etc.) with exactly-once delivery guarantees, hybrid queue architecture, and production-grade resilience patterns.\n\n## Architecture Components\n\n### 1. Core Service Layer\n\n**NotificationService (Orchestrator)**\n```typescript\ninterface NotificationService {\n  send(request: NotificationRequest): Promise<NotificationResult>;\n  sendBatch(requests: NotificationRequest[]): Promise<BatchResult>;\n  getStatus(notificationId: string): Promise<NotificationStatus>;\n  cancel(notificationId: string): Promise<void>;\n  retry(notificationId: string): Promise<NotificationResult>;\n}\n\ninterface BatchResult {\n  results: NotificationResult[];\n  summary: {\n    total: number;\n    succeeded: number;\n    failed: number;\n    pending: number;\n  };\n}\n```\n\n**Channel Provider (Strategy Pattern)**\n```typescript\ninterface ChannelProvider {\n  readonly type: ChannelType;\n  readonly capabilities: ProviderCapabilities;\n  \n  send(message: ChannelMessage): Promise<ProviderResult>;\n  validateRecipient(recipient: Recipient): ValidationResult;\n  healthCheck(): Promise<HealthStatus>;\n}\n\ninterface ProviderCapabilities {\n  batchSend: {\n    supported: boolean;\n    maxBatchSize?: number;\n  };\n  rateLimit: {\n    perSecond: number;\n    perMinute: number;\n    perHour?: number;\n  };\n  features: {\n    deliveryTracking: boolean;\n    scheduling: boolean;\n    richContent: boolean;\n  };\n}\n\ninterface ProviderResult {\n  success: boolean;\n  providerId: string;\n  providerMessageId?: string;\n  error?: ProviderError;\n  metadata?: Record<string, any>;\n}\n\n// Implementations\nclass SendGridEmailProvider implements ChannelProvider\nclass FCMPushProvider implements ChannelProvider\nclass TwilioSMSProvider implements ChannelProvider\n```\n\n### 2. Hybrid Queue Architecture\n\n**Queue Abstraction Layer**\n```typescript\ninterface QueueAdapter {\n  enqueue(message: QueueMessage, options: EnqueueOptions): Promise<string>;\n  dequeue(workerId: string, count: number): Promise<QueueMessage[]>;\n  ack(messageId: string, workerId: string): Promise<void>;\n  nack(messageId: string, workerId: string, reason: string): Promise<void>;\n  requeueWithDelay(messageId: string, delayMs: number): Promise<void>;\n  extendVisibility(messageId: string, workerId: string, durationMs: number): Promise<void>;\n  getDepth(priority?: NotificationPriority): Promise<number>;\n}\n\ninterface EnqueueOptions {\n  priority: NotificationPriority;\n  visibilityDelay: number; // For scheduled sends\n  deduplicationId?: string; // For exactly-once\n}\n\ninterface QueueMessage {\n  id: string;\n  notificationId: string;\n  payload: NotificationRequest;\n  priority: NotificationPriority;\n  enqueuedAt: Date;\n  visibleAt: Date;\n  dequeueCount: number;\n  workerId?: string;\n  leaseExpiry?: Date;\n}\n\n// Implementations for different scales\nclass PostgresQueueAdapter implements QueueAdapter // < 5K msg/sec\nclass RedisQueueAdapter implements QueueAdapter    // 5K-50K msg/sec\nclass SQSQueueAdapter implements QueueAdapter      // > 50K msg/sec\n```\n\n**PostgreSQL Queue (for low-to-medium scale)**\n```typescript\nclass PostgresQueueAdapter implements QueueAdapter {\n  async dequeue(workerId: string, count: number): Promise<QueueMessage[]> {\n    const leaseMs = 300000; // 5 minutes\n    \n    // Critical: Use advisory locks to prevent phantom reads\n    const result = await this.db.query(`\n      WITH selected AS (\n        SELECT id\n        FROM notification_queue\n        WHERE status = 'pending'\n          AND visible_at <= NOW()\n          AND (expires_at IS NULL OR expires_at > NOW())\n          AND pg_try_advisory_xact_lock(hashtext(id::text)) -- Prevents race conditions\n        ORDER BY \n          priority_order ASC,\n          visible_at ASC\n        LIMIT $1\n      )\n      UPDATE notification_queue nq\n      SET \n        status = 'processing',\n        worker_id = $2,\n        lease_expiry = NOW() + ($3 || ' milliseconds')::interval,\n        dequeue_count = dequeue_count + 1,\n        last_dequeued_at = NOW(),\n        version = version + 1\n      FROM selected\n      WHERE nq.id = selected.id\n      RETURNING nq.*\n    `, [count, workerId, leaseMs]);\n    \n    return result.rows.map(this.mapToQueueMessage);\n  }\n  \n  async ack(messageId: string, workerId: string): Promise<void> {\n    // Move to notifications table and delete from queue\n    const result = await this.db.query(`\n      WITH deleted AS (\n        DELETE FROM notification_queue\n        WHERE id = $1 \n          AND worker_id = $2\n          AND status = 'processing'\n        RETURNING *\n      )\n      UPDATE notifications\n      SET \n        status = 'sent',\n        sent_at = NOW(),\n        provider_response = deleted.provider_response,\n        processing_time_ms = EXTRACT(EPOCH FROM (NOW() - deleted.last_dequeued_at)) * 1000\n      FROM deleted\n      WHERE notifications.id = deleted.notification_id\n    `, [messageId, workerId]);\n    \n    if (result.rowCount === 0) {\n      throw new Error(`Cannot ack message ${messageId}: not owned by worker ${workerId}`);\n    }\n  }\n  \n  async nack(messageId: string, workerId: string, reason: string): Promise<void> {\n    // Release back to queue or move to DLQ\n    await this.db.query(`\n      UPDATE notification_queue\n      SET \n        status = CASE \n          WHEN dequeue_count >= max_attempts THEN 'failed'\n          ELSE 'pending'\n        END,\n        worker_id = NULL,\n        lease_expiry = NULL,\n        last_error = $3,\n        visible_at = CASE\n          WHEN dequeue_count >= max_attempts THEN visible_at\n          ELSE NOW() + (power(2, dequeue_count) * interval '1 second') -- Exponential backoff\n        END\n      WHERE id = $1 \n        AND worker_id = $2\n    `, [messageId, workerId, JSON.stringify({ reason, timestamp: new Date() })]);\n  }\n}\n```\n\n**Redis Queue (for high scale)**\n```typescript\nclass RedisQueueAdapter implements QueueAdapter {\n  // Use Redis Sorted Sets for priority queue\n  // Score = (priority_multiplier * 1e12) + timestamp_ms\n  \n  async enqueue(message: QueueMessage, options: EnqueueOptions): Promise<string> {\n    const priority = this.getPriorityMultiplier(options.priority);\n    const score = priority * 1e12 + options.visibilityDelay + Date.now();\n    \n    const pipeline = this.redis.pipeline();\n    \n    // Store message data\n    pipeline.hset(`msg:${message.id}`, {\n      payload: JSON.stringify(message.payload),\n      notificationId: message.notificationId,\n      enqueuedAt: message.enqueuedAt.toISOString(),\n      dequeueCount: 0,\n      maxAttempts: 5,\n    });\n    \n    // Add to sorted set\n    pipeline.zadd('notification_queue', score, message.id);\n    \n    // Deduplication\n    if (options.deduplicationId) {\n      pipeline.set(\n        `dedup:${options.deduplicationId}`,\n        message.id,\n        'EX',\n        3600, // 1 hour\n        'NX'\n      );\n    }\n    \n    await pipeline.exec();\n    return message.id;\n  }\n  \n  async dequeue(workerId: string, count: number): Promise<QueueMessage[]> {\n    const now = Date.now();\n    const leaseMs = 300000;\n    \n    // Lua script for atomic dequeue with lease\n    const script = `\n      local queue_key = KEYS[1]\n      local processing_key = KEYS[2]\n      local now = tonumber(ARGV[1])\n      local count = tonumber(ARGV[2])\n      local worker_id = ARGV[3]\n      local lease_ms = tonumber(ARGV[4])\n      \n      -- Get visible messages\n      local ids = redis.call('ZRANGEBYSCORE', queue_key, 0, now, 'LIMIT', 0, count)\n      \n      if #ids == 0 then\n        return {}\n      end\n      \n      local messages = {}\n      for _, id in ipairs(ids) do\n        -- Move to processing set\n        redis.call('ZREM', queue_key, id)\n        redis.call('ZADD', processing_key, now + lease_ms, id)\n        \n        -- Update message metadata\n        redis.call('HSET', 'msg:' .. id, \n          'workerId', worker_id,\n          'leaseExpiry', now + lease_ms,\n          'dequeueCount', redis.call('HINCRBY', 'msg:' .. id, 'dequeueCount', 1)\n        )\n        \n        -- Get full message\n        local msg = redis.call('HGETALL', 'msg:' .. id)\n        table.insert(messages, msg)\n      end\n      \n      return messages\n    `;\n    \n    const results = await this.redis.eval(\n      script,\n      2,\n      'notification_queue',\n      'processing_queue',\n      now,\n      count,\n      workerId,\n      leaseMs\n    );\n    \n    return this.parseRedisMessages(results);\n  }\n}\n```\n\n### 3. Worker Pool Architecture\n\n```typescript\nclass NotificationWorker {\n  private workerId: string;\n  private queue: QueueAdapter;\n  private providers: Map<ChannelType, ChannelProvider>;\n  private rateLimiters: Map<string, RateLimiter>;\n  private circuitBreakers: Map<string, CircuitBreaker>;\n  private running = false;\n  \n  constructor(\n    private config: WorkerConfig,\n    private db: Database\n  ) {\n    this.workerId = `${os.hostname()}-${process.pid}-${randomUUID()}`;\n    this.initializeQueue();\n    this.initializeProviders();\n  }\n  \n  async start(): Promise<void> {\n    this.running = true;\n    \n    // Start processing loop\n    this.processLoop();\n    \n    // Start heartbeat for worker health\n    this.heartbeatLoop();\n    \n    // Start lease extension for long-running tasks\n    this.leaseExtensionLoop();\n  }\n  \n  private async processLoop(): Promise<void> {\n    while (this.running) {\n      try {\n        const messages = await this.queue.dequeue(\n          this.workerId,\n          this.config.batchSize\n        );\n        \n        if (messages.length === 0) {\n          await this.sleep(this.config.pollIntervalMs);\n          continue;\n        }\n        \n        // Process in parallel with concurrency limit\n        await pMap(\n          messages,\n          (msg) => this.processMessage(msg),\n          { concurrency: this.config.concurrency }\n        );\n        \n      } catch (error) {\n        console.error('Worker process loop error:', error);\n        await this.sleep(5000);\n      }\n    }\n  }\n  \n  private async processMessage(message: QueueMessage): Promise<void> {\n    const startTime = Date.now();\n    let trackingSpan: Span | undefined;\n    \n    try {\n      // Start tracing span\n      trackingSpan = this.tracer.startSpan('process_notification', {\n        attributes: {\n          notificationId: message.notificationId,\n          channel: message.payload.channel,\n          priority: message.payload.priority,\n        }\n      });\n      \n      // Get provider\n      const provider = this.providers.get(message.payload.channel);\n      if (!provider) {\n        throw new NotificationError(\n          ErrorCategory.INTERNAL,\n          'NO_PROVIDER',\n          `No provider for channel ${message.payload.channel}`,\n          false\n        );\n      }\n      \n      // Check rate limits\n      const rateLimiter = this.rateLimiters.get(provider.type);\n      await rateLimiter.acquire();\n      \n      // Check circuit breaker\n      const circuitBreaker = this.circuitBreakers.get(provider.type);\n      \n      // Send with circuit breaker protection\n      const result = await circuitBreaker.execute(() =>\n        provider.send(this.buildChannelMessage(message.payload))\n      );\n      \n      // Update notification record\n      await this.db.query(`\n        UPDATE notifications\n        SET \n          provider_message_id = $1,\n          provider_response = $2\n        WHERE id = $3\n      `, [result.providerMessageId, result.metadata, message.notificationId]);\n      \n      // Acknowledge success\n      await this.queue.ack(message.id, this.workerId);\n      \n      // Fire webhook asynchronously (non-blocking)\n      if (message.payload.callbackUrl) {\n        this.fireWebhookAsync(message.payload.callbackUrl, {\n          notificationId: message.notificationId,\n          status: 'sent',\n          sentAt: new Date(),\n        }).catch(err => {\n          console.error('Webhook delivery failed:', err);\n          // Don't fail the notification - webhooks are best-effort\n        });\n      }\n      \n      // Record metrics\n      this.metrics.notificationsSent.inc({\n        channel: message.payload.channel,\n        priority: message.payload.priority,\n      });\n      \n      this.metrics.processingLatency.observe(\n        { channel: message.payload.channel },\n        Date.now() - startTime\n      );\n      \n    } catch (error) {\n      const notifError = this.normalizeError(error);\n      \n      // Record failure\n      await this.db.query(`\n        UPDATE notifications\n        SET \n          last_error = $1,\n          attempt_count = $2\n        WHERE id = $3\n      `, [\n        JSON.stringify(notifError),\n        message.dequeueCount,\n        message.notificationId\n      ]);\n      \n      // Determine retry strategy\n      const shouldRetry = this.shouldRetry(message.dequeueCount, notifError);\n      \n      if (shouldRetry) {\n        // Nack with retry\n        await this.queue.nack(message.id, this.workerId, notifError.message);\n        \n        this.metrics.notificationsRetried.inc({\n          channel: message.payload.channel,\n          errorCategory: notifError.category,\n        });\n      } else {\n        // Move to DLQ\n        await this.moveToDLQ(message, notifError);\n        await this.queue.ack(message.id, this.workerId); // Remove from queue\n        \n        this.metrics.notificationsFailed.inc({\n          channel: message.payload.channel,\n          errorCategory: notifError.category,\n        });\n      }\n      \n    } finally {\n      trackingSpan?.end();\n    }\n  }\n  \n  private async leaseExtensionLoop(): Promise<void> {\n    // Extend leases for messages taking longer than expected\n    while (this.running) {\n      await this.sleep(60000); // Every minute\n      \n      // Get all processing messages for this worker\n      const messages = await this.getProcessingMessages();\n      \n      for (const msg of messages) {\n        const timeLeft = msg.leaseExpiry.getTime() - Date.now();\n        \n        // Extend if less than 2 minutes remaining\n        if (timeLeft < 120000) {\n          await this.queue.extendVisibility(msg.id, this.workerId, 300000);\n        }\n      }\n    }\n  }\n  \n  private async heartbeatLoop(): Promise<void> {\n    // Update worker health status\n    while (this.running) {\n      await this.db.query(`\n        INSERT INTO worker_health (worker_id, last_heartbeat, processing_count)\n        VALUES ($1, NOW(), $2)\n        ON CONFLICT (worker_id) \n        DO UPDATE SET \n          last_heartbeat = NOW(),\n          processing_count = $2\n      `, [this.workerId, await this.getProcessingCount()]);\n      \n      await this.sleep(30000); // Every 30 seconds\n    }\n  }\n}\n```\n\n### 4. Data Models\n\n```typescript\nenum ChannelType {\n  EMAIL = 'email',\n  PUSH = 'push',\n  SMS = 'sms',\n  WEBHOOK = 'webhook'\n}\n\nenum NotificationPriority {\n  LOW = 0,\n  NORMAL = 1,\n  HIGH = 2,\n  URGENT = 3\n}\n\nenum NotificationStatus {\n  PENDING = 'pending',      // Created, not yet queued\n  QUEUED = 'queued',        // In queue\n  PROCESSING = 'processing', // Being processed\n  SENT = 'sent',            // Successfully sent to provider\n  DELIVERED = 'delivered',   // Confirmed delivered (if tracking available)\n  FAILED = 'failed',        // Permanently failed\n  CANCELLED = 'cancelled',   // User cancelled\n  EXPIRED = 'expired'       // Expired before sending\n}\n\ninterface NotificationRequest {\n  id?: string;\n  channel: ChannelType;\n  recipient: Recipient;\n  content: NotificationContent;\n  priority: NotificationPriority;\n  metadata?: Record<string, any>;\n  scheduledFor?: Date;\n  expiresAt?: Date;\n  idempotencyKey?: string;\n  callbackUrl?: string;\n  retryPolicy?: RetryPolicy;\n}\n\ninterface RetryPolicy {\n  maxAttempts: number;\n  backoffMultiplier: number;\n  maxBackoffMs: number;\n}\n\ninterface Recipient {\n  userId?: string;\n  email?: string;\n  phone?: string;\n  deviceTokens?: string[];\n  locale?: string;\n  timezone?: string;\n  metadata?: Record<string, any>;\n}\n\ninterface NotificationContent {\n  // Email fields\n  subject?: string;\n  htmlBody?: string;\n  textBody?: string;\n  \n  // Push fields\n  title?: string;\n  body: string;\n  imageUrl?: string;\n  clickAction?: string;\n  \n  // Common\n  templateId?: string;\n  variables?: Record<string, any>;\n  attachments?: Attachment[];\n}\n\ninterface NotificationResult {\n  notificationId: string;\n  status: NotificationStatus;\n  enqueuedAt: Date;\n  sentAt?: Date;\n  error?: NotificationError;\n  providerMessageId?: string;\n  estimatedDeliveryAt?: Date;\n}\n```\n\n### 5. Database Schema\n\n```sql\n-- Core notifications table (canonical record)\nCREATE TABLE notifications (\n  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n  channel VARCHAR(20) NOT NULL,\n  recipient JSONB NOT NULL,\n  content JSONB NOT NULL,\n  priority SMALLINT NOT NULL,\n  status VARCHAR(20) NOT NULL,\n  \n  idempotency_key VARCHAR(255),\n  callback_url TEXT,\n  metadata JSONB,\n  \n  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  scheduled_for TIMESTAMPTZ,\n  expires_at TIMESTAMPTZ,\n  \n  sent_at TIMESTAMPTZ,\n  delivered_at TIMESTAMPTZ,\n  failed_at TIMESTAMPTZ,\n  \n  attempt_count INTEGER NOT NULL DEFAULT 0,\n  max_attempts INTEGER NOT NULL DEFAULT 5,\n  last_error JSONB,\n  \n  provider_message_id VARCHAR(255),\n  provider_response JSONB,\n  processing_time_ms INTEGER,\n  \n  CONSTRAINT uq_idempotency UNIQUE (idempotency_key)\n);\n\nCREATE INDEX idx_notifications_status ON notifications(status, created_at DESC);\nCREATE INDEX idx_notifications_scheduled ON notifications(scheduled_for) \n  WHERE status = 'pending' AND scheduled_for IS NOT NULL;\nCREATE INDEX idx_notifications_expires ON notifications(expires_at) \n  WHERE status IN ('pending', 'queued') AND expires_at IS NOT NULL;\n\n-- Separate queue table for high-throughput processing\nCREATE TABLE notification_queue (\n  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n  notification_id UUID NOT NULL REFERENCES notifications(id) ON DELETE CASCADE,\n  \n  status VARCHAR(20) NOT NULL DEFAULT 'pending',\n  priority_order INTEGER NOT NULL, -- Computed from priority for sorting\n  \n  visible_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  expires_at TIMESTAMPTZ,\n  \n  worker_id VARCHAR(255),\n  lease_expiry TIMESTAMPTZ,\n  \n  dequeue_count INTEGER NOT NULL DEFAULT 0,\n  max_attempts INTEGER NOT NULL DEFAULT 5,\n  last_error JSONB,\n  last_dequeued_at TIMESTAMPTZ,\n  \n  version INTEGER NOT NULL DEFAULT 0, -- Optimistic locking\n  \n  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW()\n);\n\n-- Critical index for dequeue performance\nCREATE INDEX idx_queue_processing ON notification_queue(\n  priority_order ASC,\n  visible_at ASC\n) WHERE status = 'pending';\n\n-- Index for stuck message cleanup\nCREATE INDEX idx_queue_stuck ON notification_queue(lease_expiry, worker_id)\n  WHERE status = 'processing' AND lease_expiry IS NOT NULL;\n\n-- Dead letter queue\nCREATE TABLE notification_dlq (\n  id UUID PRIMARY KEY,\n  notification_id UUID NOT NULL,\n  original_request JSONB NOT NULL,\n  final_error JSONB NOT NULL,\n  attempt_count INTEGER NOT NULL,\n  failed_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  requeued_at TIMESTAMPTZ,\n  \n  INDEX idx_dlq_failed_at (failed_at DESC)\n);\n\n-- Worker health tracking\nCREATE TABLE worker_health (\n  worker_id VARCHAR(255) PRIMARY KEY,\n  last_heartbeat TIMESTAMPTZ NOT NULL,\n  processing_count INTEGER NOT NULL DEFAULT 0,\n  started_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  \n  INDEX idx_worker_heartbeat (last_heartbeat DESC)\n);\n\n-- Audit trail\nCREATE TABLE notification_events (\n  id BIGSERIAL PRIMARY KEY,\n  notification_id UUID NOT NULL REFERENCES notifications(id) ON DELETE CASCADE,\n  event_type VARCHAR(50) NOT NULL,\n  from_status VARCHAR(20),\n  to_status VARCHAR(20),\n  worker_id VARCHAR(255),\n  error JSONB,\n  metadata JSONB,\n  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  \n  INDEX idx_events_notification (notification_id, created_at DESC),\n  INDEX idx_events_type (event_type, created_at DESC)\n);\n\n-- Provider rate limiting (distributed)\nCREATE TABLE provider_rate_limits (\n  provider_id VARCHAR(100) NOT NULL,\n  window_start TIMESTAMPTZ NOT NULL,\n  window_type VARCHAR(10) NOT NULL, -- 'second', 'minute', 'hour'\n  token_count INTEGER NOT NULL DEFAULT 0,\n  updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  \n  PRIMARY KEY (provider_id, window_start, window_type)\n);\n\nCREATE INDEX idx_rate_limits_active ON provider_rate_limits(\n  provider_id, window_type, window_start DESC\n);\n\n-- Device token management\nCREATE TABLE device_tokens (\n  id BIGSERIAL PRIMARY KEY,\n  user_id VARCHAR(255) NOT NULL,\n  token VARCHAR(500) NOT NULL,\n  platform VARCHAR(20) NOT NULL,\n  is_active BOOLEAN NOT NULL DEFAULT true,\n  last_used_at TIMESTAMPTZ,\n  invalidated_at TIMESTAMPTZ,\n  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  \n  CONSTRAINT uq_device_token UNIQUE (token),\n  INDEX idx_tokens_user_active (user_id, is_active) WHERE is_active = true\n);\n\n-- Template storage\nCREATE TABLE notification_templates (\n  id VARCHAR(100) NOT NULL,\n  channel VARCHAR(20) NOT NULL,\n  version INTEGER NOT NULL,\n  name VARCHAR(255) NOT NULL,\n  template_data JSONB NOT NULL,\n  is_active BOOLEAN NOT NULL DEFAULT true,\n  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  \n  PRIMARY KEY (id, version),\n  INDEX idx_templates_active (id, is_active, version DESC) WHERE is_active = true\n);\n```\n\n### 6. Resilience Patterns\n\n**Adaptive Circuit Breaker**\n```typescript\nclass CircuitBreaker {\n  private state: 'closed' | 'open' | 'half_open' = 'closed';\n  private failureCount = 0;\n  private successCount = 0;\n  private lastStateChange = Date.now();\n  private halfOpenRequestsAllowed = 1; // Start with 1 test request\n  private activeHalfOpenRequests = 0;\n  \n  constructor(\n    private readonly config: {\n      failureThreshold: number;\n      openDurationMs: number;\n      halfOpenSuccessThreshold: number;\n      halfOpenMaxConcurrent: number;\n    }\n  ) {}\n  \n  async execute<T>(fn: () => Promise<T>): Promise<T> {\n    // Check if should transition to half-open\n    if (this.state === 'open') {\n      const timeSinceOpen = Date.now() - this.lastStateChange;\n      if (timeSinceOpen >= this.config.openDurationMs) {\n        this.transitionToHalfOpen();\n      } else {\n        throw new CircuitOpenError(\n          `Circuit open, retry after ${this.config.openDurationMs - timeSinceOpen}ms`\n        );\n      }\n    }\n    \n    // Limit concurrent half-open requests\n    if (this.state === 'half_open') {\n      if (this.activeHalfOpenRequests >= this.halfOpenRequestsAllowed) {\n        throw new CircuitOpenError('Half-open circuit at capacity');\n      }\n      this.activeHalfOpenRequests++;\n    }\n    \n    try {\n      const result = await fn();\n      this.onSuccess();\n      return result;\n    } catch (error) {\n      this.onFailure(error);\n      throw error;\n    } finally {\n      if (this.state === 'half_open') {\n        this.activeHalfOpenRequests--;\n      }\n    }\n  }\n  \n  private onSuccess(): void {\n    if (this.state === 'half_open') {\n      this.successCount++;\n      \n      if (this.successCount >= this.config.halfOpenSuccessThreshold) {\n        this.transitionToClosed();\n      } else {\n        // Gradually increase allowed concurrent requests\n        this.halfOpenRequestsAllowed = Math.min(\n          this.halfOpenRequestsAllowed + 1,\n          this.config.halfOpenMaxConcurrent\n        );\n      }\n    } else if (this.state === 'closed') {\n      this.failureCount = Math.max(0, this.failureCount - 1); // Decay failures\n    }\n  }\n  \n  private onFailure(error: any): void {\n    if (this.state === 'half_open') {\n      // Immediate reopen on any failure in half-open\n      this.transitionToOpen();\n    } else if (this.state === 'closed') {\n      this.failureCount++;\n      if (this.failureCount >= this.config.failureThreshold) {\n        this.transitionToOpen();\n      }\n    }\n  }\n  \n  private transitionToOpen(): void {\n    this.state = 'open';\n    this.lastStateChange = Date.now();\n    this.successCount = 0;\n    console.warn(`Circuit breaker opened after ${this.failureCount} failures`);\n  }\n  \n  private transitionToHalfOpen(): void {\n    this.state = 'half_open';\n    this.lastStateChange = Date.now();\n    this.successCount = 0;\n    this.halfOpenRequestsAllowed = 1;\n    this.activeHalfOpenRequests = 0;\n    console.info('Circuit breaker entering half-open state');\n  }\n  \n  private transitionToClosed(): void {\n    this.state = 'closed';\n    this.lastStateChange = Date.now();\n    this.failureCount = 0;\n    this.successCount = 0;\n    console.info('Circuit breaker closed after successful recovery');\n  }\n}\n```\n\n**Token Bucket Rate Limiter**\n```typescript\nclass DistributedRateLimiter {\n  constructor(\n    private db: Database,\n    private providerId: string,\n    private limits: {\n      perSecond: number;\n      perMinute: number;\n      perHour?: number;\n    }\n  ) {}\n  \n  async acquire(): Promise<void> {\n    const windows = [\n      { type: 'second', limit: this.limits.perSecond, durationMs: 1000 },\n      { type: 'minute', limit: this.limits.perMinute, durationMs: 60000 },\n    ];\n    \n    if (this.limits.perHour) {\n      windows.push({ type: 'hour', limit: this.limits.perHour, durationMs: 3600000 });\n    }\n    \n    for (const window of windows) {\n      const windowStart = new Date(\n        Math.floor(Date.now() / window.durationMs) * window.durationMs\n      );\n      \n      const result = await this.db.query(`\n        INSERT INTO provider_rate_limits (provider_id, window_start, window_type, token_count)\n        VALUES ($1, $2, $3, 1)\n        ON CONFLICT (provider_id, window_start, window_type)\n        DO UPDATE SET \n          token_count = provider_rate_limits.token_count + 1,\n          updated_at = NOW()\n        RETURNING token_count\n      `, [this.providerId, windowStart, window.type]);\n      \n      const currentCount = result.rows[0].token_count;\n      \n      if (currentCount > window.limit) {\n        const retryAfterMs = windowStart.getTime() + window.durationMs - Date.now();\n        \n        // Exponential backoff for rate limit\n        await this.sleep(Math.min(retryAfterMs, 5000));\n        \n        throw new RateLimitError(\n          `Rate limit exceeded for ${window.type} window`,\n          retryAfterMs\n        );\n      }\n    }\n  }\n  \n  private sleep(ms: number): Promise<void> {\n    return new Promise(resolve => setTimeout(resolve, ms));\n  }\n}\n```\n\n**Retry Handler with Jitter**\n```typescript\nclass RetryHandler {\n  shouldRetry(attempt: number, error: NotificationError): boolean {\n    if (attempt >= 5) return false;\n    if (error.category === ErrorCategory.VALIDATION) return false;\n    if (error.category === ErrorCategory.PERMANENT) return false;\n    return error.retryable;\n  }\n  \n  calculateBackoff(attempt: number, error: NotificationError): number {\n    const baseMs = 1000;\n    const maxMs = 300000; // 5 minutes\n    \n    // Longer backoff for rate limits\n    const multiplier = error.category === ErrorCategory.RATE_LIMIT ? 3 : 1;\n    \n    // Exponential backoff: base * 2^attempt * multiplier\n    const exponential = baseMs * Math.pow(2, attempt) * multiplier;\n    \n    // Full jitter: random between 0 and exponential\n    const withJitter = Math.random() * exponential;\n    \n    return Math.min(withJitter, maxMs);\n  }\n}\n```\n\n### 7. Webhook Delivery System\n\n```typescript\nclass WebhookDeliveryService {\n  private webhookQueue: Queue; // Separate queue for webhooks\n  \n  async enqueueWebhook(webhook: WebhookPayload): Promise<void> {\n    // Non-blocking: fire and forget\n    await this.webhookQueue.enqueue({\n      url: webhook.url,\n      payload: webhook.payload,\n      maxAttempts: 3,\n      timeoutMs: 5000,\n    });\n  }\n  \n  async deliverWebhook(webhook: WebhookJob): Promise<void> {\n    try {\n      const response = await fetch(webhook.url, {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n          'X-Notification-Event': webhook.payload.event,\n          'X-Notification-ID': webhook.payload.notificationId,\n          'X-Signature': this.signPayload(webhook.payload),\n        },\n        body: JSON.stringify(webhook.payload),\n        signal: AbortSignal.timeout(webhook.timeoutMs),\n      });\n      \n      if (!response.ok) {\n        throw new Error(`Webhook returned ${response.status}`);\n      }\n      \n      // Log success\n      await this.logWebhookDelivery(webhook, 'success');\n      \n    } catch (error) {\n      // Log failure but don't block notification\n      await this.logWebhookDelivery(webhook, 'failed', error);\n      \n      // Retry with backoff\n      if (webhook.attempt < webhook.maxAttempts) {\n        await this.webhookQueue.requeueWithDelay(\n          webhook.id,\n          this.calculateBackoff(webhook.attempt)\n        );\n      }\n    }\n  }\n  \n  private signPayload(payload: any): string {\n    // HMAC signature for webhook verification\n    return crypto\n      .createHmac('sha256', process.env.WEBHOOK_SECRET!)\n      .update(JSON.stringify(payload))\n      .digest('hex');\n  }\n}\n```\n\n### 8. Background Maintenance\n\n```typescript\nclass MaintenanceService {\n  async start(): Promise<void> {\n    // Release stuck messages (every 60s)\n    setInterval(() => this.releaseStuckMessages(), 60000);\n    \n    // Expire old notifications (every 5 min)\n    setInterval(() => this.expireNotifications(), 300000);\n    \n    // Cleanup dead workers (every 5 min)\n    setInterval(() => this.cleanupDeadWorkers(), 300000);\n    \n    // Archive old records (daily)\n    setInterval(() => this.archiveOldRecords(), 86400000);\n  }\n  \n  private async releaseStuckMessages(): Promise<void> {\n    // Messages with expired leases\n    await this.db.query(`\n      UPDATE notification_queue\n      SET \n        status = 'pending',\n        worker_id = NULL,\n        lease_expiry = NULL,\n        visible_at = NOW() + interval '30 seconds'\n      WHERE status = 'processing'\n        AND lease_expiry < NOW()\n    `);\n  }\n  \n  private async expireNotifications(): Promise<void> {\n    await this.db.transaction(async (tx) => {\n      // Mark as expired\n      await tx.query(`\n        UPDATE notifications\n        SET status = 'expired', updated_at = NOW()\n        WHERE status IN ('pending', 'queued')\n          AND expires_at <= NOW()\n      `);\n      \n      // Remove from queue\n      await tx.query(`\n        DELETE FROM notification_queue\n        WHERE notification_id IN (\n          SELECT id FROM notifications WHERE status = 'expired'\n        )\n      `);\n    });\n  }\n  \n  private async cleanupDeadWorkers(): Promise<void> {\n    const cutoff = new Date(Date.now() - 600000); // 10 min\n    \n    await this.db.query(`\n      DELETE FROM worker_health\n      WHERE last_heartbeat < $1\n    `, [cutoff]);\n  }\n  \n  private async archiveOldRecords(): Promise<void> {\n    const archiveThreshold = new Date(Date.now() - 90 * 86400000); // 90 days\n    \n    await this.db.transaction(async (tx) => {\n      // Archive to cold storage (S3, etc.)\n      const oldRecords = await tx.query(`\n        SELECT * FROM notifications\n        WHERE created_at < $1\n          AND status IN ('sent', 'delivered', 'failed', 'expired', 'cancelled')\n      `, [archiveThreshold]);\n      \n      if (oldRecords.rows.length > 0) {\n        await this.archiveToS3(oldRecords.rows);\n        \n        await tx.query(`\n          DELETE FROM notifications\n          WHERE created_at < $1\n            AND status IN ('sent', 'delivered', 'failed', 'expired', 'cancelled')\n        `, [archiveThreshold]);\n      }\n    });\n  }\n}\n```\n\n### 9. Monitoring & Observability\n\n```typescript\ninterface NotificationMetrics {\n  // Counters\n  notificationsSent: Counter<{ channel: string; priority: string }>;\n  notificationsFailed: Counter<{ channel: string; errorCategory: string }>;\n  notificationsRetried: Counter<{ channel: string; attempt: number }>;\n  webhooksDelivered: Counter<{ success: boolean }>;\n  \n  // Gauges\n  queueDepth: Gauge<{ priority: string }>;\n  activeWorkers: Gauge;\n  circuitBreakerState: Gauge<{ provider: string }>; // 0=closed, 1=half-open, 2=open\n  oldestQueuedMessage: Gauge; // Age in seconds\n  \n  // Histograms\n  processingLatency: Histogram<{ channel: string }>; // End-to-end processing time\n  providerLatency: Histogram<{ provider: string }>; // Provider API call time\n  queueWaitTime: Histogram<{ priority: string }>; // Time in queue before processing\n  \n  // Business metrics\n  deliveryRate: Gauge<{ channel: string }>; // Success rate over time window\n  costPerNotification: Histogram<{ channel: string }>;\n}\n\n// Health check endpoint\napp.get('/health', async (req, res) => {\n  const checks = await Promise.all([\n    checkDatabase(),\n    checkQueue(),\n    checkProviders(),\n  ]);\n  \n  const healthy = checks.every(c => c.healthy);\n  \n  res.status(healthy ? 200 : 503).json({\n    status: healthy ? 'healthy' : 'unhealthy',\n    checks,\n    uptime: process.uptime(),\n    memory: process.memoryUsage(),\n  });\n});\n\n// Metrics endpoint (Prometheus format)\napp.get('/metrics', async (req, res) => {\n  res.set('Content-Type', register.contentType);\n  res.send(await register.metrics());\n});\n```\n\n## Rationale\n\n### Why Hybrid Queue Architecture?\n**PostgreSQL for < 5K msg/sec**: Simple, reliable, no additional infrastructure. Perfect for most use cases. The `pg_try_advisory_xact_lock` prevents phantom reads during dequeue.\n\n**Redis for 5K-50K msg/sec**: When PostgreSQL becomes the bottleneck, Redis sorted sets provide microsecond latency with Lua scripts for atomic operations.\n\n**SQS for > 50K msg/sec**: Fully managed, infinite scale, but adds network latency. Use when horizontal scaling is more important than latency.\n\n### Why Separate Queue Table?\nThe `notification_queue` table isolates high-churn queue operations from the canonical `notifications` record. This prevents index bloat and allows efficient archival of old notifications without affecting queue performance.\n\n### Why Lease-Based Processing?\nWorker crashes are inevitable. Leases with expiry ensure messages are automatically recovered without manual intervention. The `lease_expiry` and `worker_id` columns enable precise ownership tracking.\n\n### Why Advisory Locks in PostgreSQL?\n`SELECT FOR UPDATE SKIP LOCKED` prevents lock contention but doesn't prevent the same row being returned to multiple transactions in edge cases (serialization anomalies). Advisory locks guarantee exactly-once dequeue.\n\n### Webhook Design Decision\n**Non-blocking, best-effort**: Webhooks are delivered asynchronously in a separate queue with retry logic. Failed webhooks don't block notification delivery because:\n1. The notification provider has already accepted the message\n2. Webhook endpoints are outside our control and may be unreliable\n3. Users can query status via API if webhook fails\n\n## What I Changed\n\n### 1. **Fixed Dequeue Race Condition**\nAdded `pg_try_advisory_xact_lock` to prevent the subtle race where two workers can dequeue the same message under high concurrency (serialization anomalies). The previous design's `SELECT FOR UPDATE SKIP LOCKED` is necessary but not sufficient.\n\n### 2. **Separated Queue Table from Notifications**\nCreated `notification_queue` as a separate high-churn table. This:\n- Prevents bloat in the canonical `notifications` table\n- Enables efficient cleanup (delete from queue, keep notification history)\n- Improves index performance (smaller, more focused indexes)\n- Allows queue-specific fields (lease_expiry, visible_at) without cluttering main record\n\n### 3. **Clarified Webhook Semantics**\nMade webhooks explicitly **non-blocking and best-effort** with a separate delivery queue. Previous design was ambiguous about whether webhook failures should block notification completion.\n\n### 4. **Added Hybrid Queue Architecture**\nProvided three queue implementations (Postgres, Redis, SQS) with clear scaling thresholds. This gives a migration path as load increases without rewriting the entire system.\n\n### 5. **Simplified Worker Lifecycle**\nAdded explicit worker health tracking, heartbeat loop, and lease extension loop. This makes worker management observable and debuggable.\n\n### 6. **Enhanced Circuit Breaker**\nImproved half-open state to gradually increase allowed concurrent requests (starting with 1, growing to N) rather than immediately allowing full traffic. This prevents thundering herd on recovery.\n\n### 7. **Removed Optimistic Locking Version**\nThe `version` field is redundant when using advisory locks for dequeue. Removed to simplify the design (YAGNI principle).\n\n## What I Kept\n\n- Priority queue with efficient indexing\n- Exponential backoff with jitter\n- Separate DLQ for permanent failures\n- Distributed rate limiting with token bucket\n- Circuit breaker per provider\n- Template versioning system\n- Device token management\n- Comprehensive audit trail\n- Maintenance jobs for cleanup/archival\n- Prometheus metrics integration\n\n## Open Questions\n\n### 1. **Queue Migration Strategy**\nWhen transitioning from Postgres \u2192 Redis \u2192 SQS, how do we handle in-flight messages? Options:\n- **Drain old queue first** (simple but causes processing pause)\n- **Dual-write to both queues** (complex but zero downtime)\n- **Message forwarding** (old queue forwards to new queue during transition)\n\n### 2. **Provider Failover**\nShould we support automatic failover between providers (e.g., SendGrid \u2192 AWS SES)? This adds complexity:\n- Need provider priority/preference configuration\n- Cost implications (backup provider may be more expensive)\n- Different providers have different capabilities (templates, tracking, etc.)\n- Recipient's provider preference may matter (deliverability)\n\n### 3. **Multi-Tenancy**\nFor SaaS use cases:\n- Should tenants provide their own API keys (better security, cost attribution)?\n- Or use shared provider pool (simpler but commingled rate limits)?\n- Need `tenant_id` throughout schema if supporting multi-tenancy\n\n### 4. **Delivery Tracking**\nSome providers (FCM, SES) support delivery webhooks. Should we:\n- Update `status` from `sent` to `delivered` when webhook received?\n- Store delivery latency for SLA monitoring?\n- Retry on delivery failure vs. send failure?\n\n### 5. **Cost Attribution**\nThe `estimateCost()` method exists but costs aren't persisted. For billing/attribution:\n- Add `estimated_cost` and `actual_cost` columns?\n- Aggregate by tenant/user/channel for billing?\n- Track provider pricing changes over time?\n\n## Convergence Status\n\n**ITERATING** - Core architecture is solid but need feedback on queue migration strategy and multi-tenancy approach before finalizing.",
        "prompt_for_other": "Focus on the **dequeue race condition fix** with advisory locks - does this actually prevent all race conditions in high-concurrency scenarios? Also, critique the **queue migration strategy** from Postgres \u2192 Redis \u2192 SQS: is dual-write viable, or should we mandate drain-first? Finally, challenge the **webhook semantics** - is best-effort acceptable, or should webhook failures retry indefinitely with exponential backoff?",
        "convergence_signal": "ITERATING",
        "raw_response": "## Design\n\n# Notification Service Architecture\n\n## System Overview\nA horizontally-scalable notification service supporting pluggable channels (email, push, SMS, etc.) with exactly-once delivery guarantees, hybrid queue architecture, and production-grade resilience patterns.\n\n## Architecture Components\n\n### 1. Core Service Layer\n\n**NotificationService (Orchestrator)**\n```typescript\ninterface NotificationService {\n  send(request: NotificationRequest): Promise<NotificationResult>;\n  sendBatch(requests: NotificationRequest[]): Promise<BatchResult>;\n  getStatus(notificationId: string): Promise<NotificationStatus>;\n  cancel(notificationId: string): Promise<void>;\n  retry(notificationId: string): Promise<NotificationResult>;\n}\n\ninterface BatchResult {\n  results: NotificationResult[];\n  summary: {\n    total: number;\n    succeeded: number;\n    failed: number;\n    pending: number;\n  };\n}\n```\n\n**Channel Provider (Strategy Pattern)**\n```typescript\ninterface ChannelProvider {\n  readonly type: ChannelType;\n  readonly capabilities: ProviderCapabilities;\n  \n  send(message: ChannelMessage): Promise<ProviderResult>;\n  validateRecipient(recipient: Recipient): ValidationResult;\n  healthCheck(): Promise<HealthStatus>;\n}\n\ninterface ProviderCapabilities {\n  batchSend: {\n    supported: boolean;\n    maxBatchSize?: number;\n  };\n  rateLimit: {\n    perSecond: number;\n    perMinute: number;\n    perHour?: number;\n  };\n  features: {\n    deliveryTracking: boolean;\n    scheduling: boolean;\n    richContent: boolean;\n  };\n}\n\ninterface ProviderResult {\n  success: boolean;\n  providerId: string;\n  providerMessageId?: string;\n  error?: ProviderError;\n  metadata?: Record<string, any>;\n}\n\n// Implementations\nclass SendGridEmailProvider implements ChannelProvider\nclass FCMPushProvider implements ChannelProvider\nclass TwilioSMSProvider implements ChannelProvider\n```\n\n### 2. Hybrid Queue Architecture\n\n**Queue Abstraction Layer**\n```typescript\ninterface QueueAdapter {\n  enqueue(message: QueueMessage, options: EnqueueOptions): Promise<string>;\n  dequeue(workerId: string, count: number): Promise<QueueMessage[]>;\n  ack(messageId: string, workerId: string): Promise<void>;\n  nack(messageId: string, workerId: string, reason: string): Promise<void>;\n  requeueWithDelay(messageId: string, delayMs: number): Promise<void>;\n  extendVisibility(messageId: string, workerId: string, durationMs: number): Promise<void>;\n  getDepth(priority?: NotificationPriority): Promise<number>;\n}\n\ninterface EnqueueOptions {\n  priority: NotificationPriority;\n  visibilityDelay: number; // For scheduled sends\n  deduplicationId?: string; // For exactly-once\n}\n\ninterface QueueMessage {\n  id: string;\n  notificationId: string;\n  payload: NotificationRequest;\n  priority: NotificationPriority;\n  enqueuedAt: Date;\n  visibleAt: Date;\n  dequeueCount: number;\n  workerId?: string;\n  leaseExpiry?: Date;\n}\n\n// Implementations for different scales\nclass PostgresQueueAdapter implements QueueAdapter // < 5K msg/sec\nclass RedisQueueAdapter implements QueueAdapter    // 5K-50K msg/sec\nclass SQSQueueAdapter implements QueueAdapter      // > 50K msg/sec\n```\n\n**PostgreSQL Queue (for low-to-medium scale)**\n```typescript\nclass PostgresQueueAdapter implements QueueAdapter {\n  async dequeue(workerId: string, count: number): Promise<QueueMessage[]> {\n    const leaseMs = 300000; // 5 minutes\n    \n    // Critical: Use advisory locks to prevent phantom reads\n    const result = await this.db.query(`\n      WITH selected AS (\n        SELECT id\n        FROM notification_queue\n        WHERE status = 'pending'\n          AND visible_at <= NOW()\n          AND (expires_at IS NULL OR expires_at > NOW())\n          AND pg_try_advisory_xact_lock(hashtext(id::text)) -- Prevents race conditions\n        ORDER BY \n          priority_order ASC,\n          visible_at ASC\n        LIMIT $1\n      )\n      UPDATE notification_queue nq\n      SET \n        status = 'processing',\n        worker_id = $2,\n        lease_expiry = NOW() + ($3 || ' milliseconds')::interval,\n        dequeue_count = dequeue_count + 1,\n        last_dequeued_at = NOW(),\n        version = version + 1\n      FROM selected\n      WHERE nq.id = selected.id\n      RETURNING nq.*\n    `, [count, workerId, leaseMs]);\n    \n    return result.rows.map(this.mapToQueueMessage);\n  }\n  \n  async ack(messageId: string, workerId: string): Promise<void> {\n    // Move to notifications table and delete from queue\n    const result = await this.db.query(`\n      WITH deleted AS (\n        DELETE FROM notification_queue\n        WHERE id = $1 \n          AND worker_id = $2\n          AND status = 'processing'\n        RETURNING *\n      )\n      UPDATE notifications\n      SET \n        status = 'sent',\n        sent_at = NOW(),\n        provider_response = deleted.provider_response,\n        processing_time_ms = EXTRACT(EPOCH FROM (NOW() - deleted.last_dequeued_at)) * 1000\n      FROM deleted\n      WHERE notifications.id = deleted.notification_id\n    `, [messageId, workerId]);\n    \n    if (result.rowCount === 0) {\n      throw new Error(`Cannot ack message ${messageId}: not owned by worker ${workerId}`);\n    }\n  }\n  \n  async nack(messageId: string, workerId: string, reason: string): Promise<void> {\n    // Release back to queue or move to DLQ\n    await this.db.query(`\n      UPDATE notification_queue\n      SET \n        status = CASE \n          WHEN dequeue_count >= max_attempts THEN 'failed'\n          ELSE 'pending'\n        END,\n        worker_id = NULL,\n        lease_expiry = NULL,\n        last_error = $3,\n        visible_at = CASE\n          WHEN dequeue_count >= max_attempts THEN visible_at\n          ELSE NOW() + (power(2, dequeue_count) * interval '1 second') -- Exponential backoff\n        END\n      WHERE id = $1 \n        AND worker_id = $2\n    `, [messageId, workerId, JSON.stringify({ reason, timestamp: new Date() })]);\n  }\n}\n```\n\n**Redis Queue (for high scale)**\n```typescript\nclass RedisQueueAdapter implements QueueAdapter {\n  // Use Redis Sorted Sets for priority queue\n  // Score = (priority_multiplier * 1e12) + timestamp_ms\n  \n  async enqueue(message: QueueMessage, options: EnqueueOptions): Promise<string> {\n    const priority = this.getPriorityMultiplier(options.priority);\n    const score = priority * 1e12 + options.visibilityDelay + Date.now();\n    \n    const pipeline = this.redis.pipeline();\n    \n    // Store message data\n    pipeline.hset(`msg:${message.id}`, {\n      payload: JSON.stringify(message.payload),\n      notificationId: message.notificationId,\n      enqueuedAt: message.enqueuedAt.toISOString(),\n      dequeueCount: 0,\n      maxAttempts: 5,\n    });\n    \n    // Add to sorted set\n    pipeline.zadd('notification_queue', score, message.id);\n    \n    // Deduplication\n    if (options.deduplicationId) {\n      pipeline.set(\n        `dedup:${options.deduplicationId}`,\n        message.id,\n        'EX',\n        3600, // 1 hour\n        'NX'\n      );\n    }\n    \n    await pipeline.exec();\n    return message.id;\n  }\n  \n  async dequeue(workerId: string, count: number): Promise<QueueMessage[]> {\n    const now = Date.now();\n    const leaseMs = 300000;\n    \n    // Lua script for atomic dequeue with lease\n    const script = `\n      local queue_key = KEYS[1]\n      local processing_key = KEYS[2]\n      local now = tonumber(ARGV[1])\n      local count = tonumber(ARGV[2])\n      local worker_id = ARGV[3]\n      local lease_ms = tonumber(ARGV[4])\n      \n      -- Get visible messages\n      local ids = redis.call('ZRANGEBYSCORE', queue_key, 0, now, 'LIMIT', 0, count)\n      \n      if #ids == 0 then\n        return {}\n      end\n      \n      local messages = {}\n      for _, id in ipairs(ids) do\n        -- Move to processing set\n        redis.call('ZREM', queue_key, id)\n        redis.call('ZADD', processing_key, now + lease_ms, id)\n        \n        -- Update message metadata\n        redis.call('HSET', 'msg:' .. id, \n          'workerId', worker_id,\n          'leaseExpiry', now + lease_ms,\n          'dequeueCount', redis.call('HINCRBY', 'msg:' .. id, 'dequeueCount', 1)\n        )\n        \n        -- Get full message\n        local msg = redis.call('HGETALL', 'msg:' .. id)\n        table.insert(messages, msg)\n      end\n      \n      return messages\n    `;\n    \n    const results = await this.redis.eval(\n      script,\n      2,\n      'notification_queue',\n      'processing_queue',\n      now,\n      count,\n      workerId,\n      leaseMs\n    );\n    \n    return this.parseRedisMessages(results);\n  }\n}\n```\n\n### 3. Worker Pool Architecture\n\n```typescript\nclass NotificationWorker {\n  private workerId: string;\n  private queue: QueueAdapter;\n  private providers: Map<ChannelType, ChannelProvider>;\n  private rateLimiters: Map<string, RateLimiter>;\n  private circuitBreakers: Map<string, CircuitBreaker>;\n  private running = false;\n  \n  constructor(\n    private config: WorkerConfig,\n    private db: Database\n  ) {\n    this.workerId = `${os.hostname()}-${process.pid}-${randomUUID()}`;\n    this.initializeQueue();\n    this.initializeProviders();\n  }\n  \n  async start(): Promise<void> {\n    this.running = true;\n    \n    // Start processing loop\n    this.processLoop();\n    \n    // Start heartbeat for worker health\n    this.heartbeatLoop();\n    \n    // Start lease extension for long-running tasks\n    this.leaseExtensionLoop();\n  }\n  \n  private async processLoop(): Promise<void> {\n    while (this.running) {\n      try {\n        const messages = await this.queue.dequeue(\n          this.workerId,\n          this.config.batchSize\n        );\n        \n        if (messages.length === 0) {\n          await this.sleep(this.config.pollIntervalMs);\n          continue;\n        }\n        \n        // Process in parallel with concurrency limit\n        await pMap(\n          messages,\n          (msg) => this.processMessage(msg),\n          { concurrency: this.config.concurrency }\n        );\n        \n      } catch (error) {\n        console.error('Worker process loop error:', error);\n        await this.sleep(5000);\n      }\n    }\n  }\n  \n  private async processMessage(message: QueueMessage): Promise<void> {\n    const startTime = Date.now();\n    let trackingSpan: Span | undefined;\n    \n    try {\n      // Start tracing span\n      trackingSpan = this.tracer.startSpan('process_notification', {\n        attributes: {\n          notificationId: message.notificationId,\n          channel: message.payload.channel,\n          priority: message.payload.priority,\n        }\n      });\n      \n      // Get provider\n      const provider = this.providers.get(message.payload.channel);\n      if (!provider) {\n        throw new NotificationError(\n          ErrorCategory.INTERNAL,\n          'NO_PROVIDER',\n          `No provider for channel ${message.payload.channel}`,\n          false\n        );\n      }\n      \n      // Check rate limits\n      const rateLimiter = this.rateLimiters.get(provider.type);\n      await rateLimiter.acquire();\n      \n      // Check circuit breaker\n      const circuitBreaker = this.circuitBreakers.get(provider.type);\n      \n      // Send with circuit breaker protection\n      const result = await circuitBreaker.execute(() =>\n        provider.send(this.buildChannelMessage(message.payload))\n      );\n      \n      // Update notification record\n      await this.db.query(`\n        UPDATE notifications\n        SET \n          provider_message_id = $1,\n          provider_response = $2\n        WHERE id = $3\n      `, [result.providerMessageId, result.metadata, message.notificationId]);\n      \n      // Acknowledge success\n      await this.queue.ack(message.id, this.workerId);\n      \n      // Fire webhook asynchronously (non-blocking)\n      if (message.payload.callbackUrl) {\n        this.fireWebhookAsync(message.payload.callbackUrl, {\n          notificationId: message.notificationId,\n          status: 'sent',\n          sentAt: new Date(),\n        }).catch(err => {\n          console.error('Webhook delivery failed:', err);\n          // Don't fail the notification - webhooks are best-effort\n        });\n      }\n      \n      // Record metrics\n      this.metrics.notificationsSent.inc({\n        channel: message.payload.channel,\n        priority: message.payload.priority,\n      });\n      \n      this.metrics.processingLatency.observe(\n        { channel: message.payload.channel },\n        Date.now() - startTime\n      );\n      \n    } catch (error) {\n      const notifError = this.normalizeError(error);\n      \n      // Record failure\n      await this.db.query(`\n        UPDATE notifications\n        SET \n          last_error = $1,\n          attempt_count = $2\n        WHERE id = $3\n      `, [\n        JSON.stringify(notifError),\n        message.dequeueCount,\n        message.notificationId\n      ]);\n      \n      // Determine retry strategy\n      const shouldRetry = this.shouldRetry(message.dequeueCount, notifError);\n      \n      if (shouldRetry) {\n        // Nack with retry\n        await this.queue.nack(message.id, this.workerId, notifError.message);\n        \n        this.metrics.notificationsRetried.inc({\n          channel: message.payload.channel,\n          errorCategory: notifError.category,\n        });\n      } else {\n        // Move to DLQ\n        await this.moveToDLQ(message, notifError);\n        await this.queue.ack(message.id, this.workerId); // Remove from queue\n        \n        this.metrics.notificationsFailed.inc({\n          channel: message.payload.channel,\n          errorCategory: notifError.category,\n        });\n      }\n      \n    } finally {\n      trackingSpan?.end();\n    }\n  }\n  \n  private async leaseExtensionLoop(): Promise<void> {\n    // Extend leases for messages taking longer than expected\n    while (this.running) {\n      await this.sleep(60000); // Every minute\n      \n      // Get all processing messages for this worker\n      const messages = await this.getProcessingMessages();\n      \n      for (const msg of messages) {\n        const timeLeft = msg.leaseExpiry.getTime() - Date.now();\n        \n        // Extend if less than 2 minutes remaining\n        if (timeLeft < 120000) {\n          await this.queue.extendVisibility(msg.id, this.workerId, 300000);\n        }\n      }\n    }\n  }\n  \n  private async heartbeatLoop(): Promise<void> {\n    // Update worker health status\n    while (this.running) {\n      await this.db.query(`\n        INSERT INTO worker_health (worker_id, last_heartbeat, processing_count)\n        VALUES ($1, NOW(), $2)\n        ON CONFLICT (worker_id) \n        DO UPDATE SET \n          last_heartbeat = NOW(),\n          processing_count = $2\n      `, [this.workerId, await this.getProcessingCount()]);\n      \n      await this.sleep(30000); // Every 30 seconds\n    }\n  }\n}\n```\n\n### 4. Data Models\n\n```typescript\nenum ChannelType {\n  EMAIL = 'email',\n  PUSH = 'push',\n  SMS = 'sms',\n  WEBHOOK = 'webhook'\n}\n\nenum NotificationPriority {\n  LOW = 0,\n  NORMAL = 1,\n  HIGH = 2,\n  URGENT = 3\n}\n\nenum NotificationStatus {\n  PENDING = 'pending',      // Created, not yet queued\n  QUEUED = 'queued',        // In queue\n  PROCESSING = 'processing', // Being processed\n  SENT = 'sent',            // Successfully sent to provider\n  DELIVERED = 'delivered',   // Confirmed delivered (if tracking available)\n  FAILED = 'failed',        // Permanently failed\n  CANCELLED = 'cancelled',   // User cancelled\n  EXPIRED = 'expired'       // Expired before sending\n}\n\ninterface NotificationRequest {\n  id?: string;\n  channel: ChannelType;\n  recipient: Recipient;\n  content: NotificationContent;\n  priority: NotificationPriority;\n  metadata?: Record<string, any>;\n  scheduledFor?: Date;\n  expiresAt?: Date;\n  idempotencyKey?: string;\n  callbackUrl?: string;\n  retryPolicy?: RetryPolicy;\n}\n\ninterface RetryPolicy {\n  maxAttempts: number;\n  backoffMultiplier: number;\n  maxBackoffMs: number;\n}\n\ninterface Recipient {\n  userId?: string;\n  email?: string;\n  phone?: string;\n  deviceTokens?: string[];\n  locale?: string;\n  timezone?: string;\n  metadata?: Record<string, any>;\n}\n\ninterface NotificationContent {\n  // Email fields\n  subject?: string;\n  htmlBody?: string;\n  textBody?: string;\n  \n  // Push fields\n  title?: string;\n  body: string;\n  imageUrl?: string;\n  clickAction?: string;\n  \n  // Common\n  templateId?: string;\n  variables?: Record<string, any>;\n  attachments?: Attachment[];\n}\n\ninterface NotificationResult {\n  notificationId: string;\n  status: NotificationStatus;\n  enqueuedAt: Date;\n  sentAt?: Date;\n  error?: NotificationError;\n  providerMessageId?: string;\n  estimatedDeliveryAt?: Date;\n}\n```\n\n### 5. Database Schema\n\n```sql\n-- Core notifications table (canonical record)\nCREATE TABLE notifications (\n  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n  channel VARCHAR(20) NOT NULL,\n  recipient JSONB NOT NULL,\n  content JSONB NOT NULL,\n  priority SMALLINT NOT NULL,\n  status VARCHAR(20) NOT NULL,\n  \n  idempotency_key VARCHAR(255),\n  callback_url TEXT,\n  metadata JSONB,\n  \n  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  scheduled_for TIMESTAMPTZ,\n  expires_at TIMESTAMPTZ,\n  \n  sent_at TIMESTAMPTZ,\n  delivered_at TIMESTAMPTZ,\n  failed_at TIMESTAMPTZ,\n  \n  attempt_count INTEGER NOT NULL DEFAULT 0,\n  max_attempts INTEGER NOT NULL DEFAULT 5,\n  last_error JSONB,\n  \n  provider_message_id VARCHAR(255),\n  provider_response JSONB,\n  processing_time_ms INTEGER,\n  \n  CONSTRAINT uq_idempotency UNIQUE (idempotency_key)\n);\n\nCREATE INDEX idx_notifications_status ON notifications(status, created_at DESC);\nCREATE INDEX idx_notifications_scheduled ON notifications(scheduled_for) \n  WHERE status = 'pending' AND scheduled_for IS NOT NULL;\nCREATE INDEX idx_notifications_expires ON notifications(expires_at) \n  WHERE status IN ('pending', 'queued') AND expires_at IS NOT NULL;\n\n-- Separate queue table for high-throughput processing\nCREATE TABLE notification_queue (\n  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n  notification_id UUID NOT NULL REFERENCES notifications(id) ON DELETE CASCADE,\n  \n  status VARCHAR(20) NOT NULL DEFAULT 'pending',\n  priority_order INTEGER NOT NULL, -- Computed from priority for sorting\n  \n  visible_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  expires_at TIMESTAMPTZ,\n  \n  worker_id VARCHAR(255),\n  lease_expiry TIMESTAMPTZ,\n  \n  dequeue_count INTEGER NOT NULL DEFAULT 0,\n  max_attempts INTEGER NOT NULL DEFAULT 5,\n  last_error JSONB,\n  last_dequeued_at TIMESTAMPTZ,\n  \n  version INTEGER NOT NULL DEFAULT 0, -- Optimistic locking\n  \n  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW()\n);\n\n-- Critical index for dequeue performance\nCREATE INDEX idx_queue_processing ON notification_queue(\n  priority_order ASC,\n  visible_at ASC\n) WHERE status = 'pending';\n\n-- Index for stuck message cleanup\nCREATE INDEX idx_queue_stuck ON notification_queue(lease_expiry, worker_id)\n  WHERE status = 'processing' AND lease_expiry IS NOT NULL;\n\n-- Dead letter queue\nCREATE TABLE notification_dlq (\n  id UUID PRIMARY KEY,\n  notification_id UUID NOT NULL,\n  original_request JSONB NOT NULL,\n  final_error JSONB NOT NULL,\n  attempt_count INTEGER NOT NULL,\n  failed_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  requeued_at TIMESTAMPTZ,\n  \n  INDEX idx_dlq_failed_at (failed_at DESC)\n);\n\n-- Worker health tracking\nCREATE TABLE worker_health (\n  worker_id VARCHAR(255) PRIMARY KEY,\n  last_heartbeat TIMESTAMPTZ NOT NULL,\n  processing_count INTEGER NOT NULL DEFAULT 0,\n  started_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  \n  INDEX idx_worker_heartbeat (last_heartbeat DESC)\n);\n\n-- Audit trail\nCREATE TABLE notification_events (\n  id BIGSERIAL PRIMARY KEY,\n  notification_id UUID NOT NULL REFERENCES notifications(id) ON DELETE CASCADE,\n  event_type VARCHAR(50) NOT NULL,\n  from_status VARCHAR(20),\n  to_status VARCHAR(20),\n  worker_id VARCHAR(255),\n  error JSONB,\n  metadata JSONB,\n  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  \n  INDEX idx_events_notification (notification_id, created_at DESC),\n  INDEX idx_events_type (event_type, created_at DESC)\n);\n\n-- Provider rate limiting (distributed)\nCREATE TABLE provider_rate_limits (\n  provider_id VARCHAR(100) NOT NULL,\n  window_start TIMESTAMPTZ NOT NULL,\n  window_type VARCHAR(10) NOT NULL, -- 'second', 'minute', 'hour'\n  token_count INTEGER NOT NULL DEFAULT 0,\n  updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  \n  PRIMARY KEY (provider_id, window_start, window_type)\n);\n\nCREATE INDEX idx_rate_limits_active ON provider_rate_limits(\n  provider_id, window_type, window_start DESC\n);\n\n-- Device token management\nCREATE TABLE device_tokens (\n  id BIGSERIAL PRIMARY KEY,\n  user_id VARCHAR(255) NOT NULL,\n  token VARCHAR(500) NOT NULL,\n  platform VARCHAR(20) NOT NULL,\n  is_active BOOLEAN NOT NULL DEFAULT true,\n  last_used_at TIMESTAMPTZ,\n  invalidated_at TIMESTAMPTZ,\n  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  \n  CONSTRAINT uq_device_token UNIQUE (token),\n  INDEX idx_tokens_user_active (user_id, is_active) WHERE is_active = true\n);\n\n-- Template storage\nCREATE TABLE notification_templates (\n  id VARCHAR(100) NOT NULL,\n  channel VARCHAR(20) NOT NULL,\n  version INTEGER NOT NULL,\n  name VARCHAR(255) NOT NULL,\n  template_data JSONB NOT NULL,\n  is_active BOOLEAN NOT NULL DEFAULT true,\n  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  \n  PRIMARY KEY (id, version),\n  INDEX idx_templates_active (id, is_active, version DESC) WHERE is_active = true\n);\n```\n\n### 6. Resilience Patterns\n\n**Adaptive Circuit Breaker**\n```typescript\nclass CircuitBreaker {\n  private state: 'closed' | 'open' | 'half_open' = 'closed';\n  private failureCount = 0;\n  private successCount = 0;\n  private lastStateChange = Date.now();\n  private halfOpenRequestsAllowed = 1; // Start with 1 test request\n  private activeHalfOpenRequests = 0;\n  \n  constructor(\n    private readonly config: {\n      failureThreshold: number;\n      openDurationMs: number;\n      halfOpenSuccessThreshold: number;\n      halfOpenMaxConcurrent: number;\n    }\n  ) {}\n  \n  async execute<T>(fn: () => Promise<T>): Promise<T> {\n    // Check if should transition to half-open\n    if (this.state === 'open') {\n      const timeSinceOpen = Date.now() - this.lastStateChange;\n      if (timeSinceOpen >= this.config.openDurationMs) {\n        this.transitionToHalfOpen();\n      } else {\n        throw new CircuitOpenError(\n          `Circuit open, retry after ${this.config.openDurationMs - timeSinceOpen}ms`\n        );\n      }\n    }\n    \n    // Limit concurrent half-open requests\n    if (this.state === 'half_open') {\n      if (this.activeHalfOpenRequests >= this.halfOpenRequestsAllowed) {\n        throw new CircuitOpenError('Half-open circuit at capacity');\n      }\n      this.activeHalfOpenRequests++;\n    }\n    \n    try {\n      const result = await fn();\n      this.onSuccess();\n      return result;\n    } catch (error) {\n      this.onFailure(error);\n      throw error;\n    } finally {\n      if (this.state === 'half_open') {\n        this.activeHalfOpenRequests--;\n      }\n    }\n  }\n  \n  private onSuccess(): void {\n    if (this.state === 'half_open') {\n      this.successCount++;\n      \n      if (this.successCount >= this.config.halfOpenSuccessThreshold) {\n        this.transitionToClosed();\n      } else {\n        // Gradually increase allowed concurrent requests\n        this.halfOpenRequestsAllowed = Math.min(\n          this.halfOpenRequestsAllowed + 1,\n          this.config.halfOpenMaxConcurrent\n        );\n      }\n    } else if (this.state === 'closed') {\n      this.failureCount = Math.max(0, this.failureCount - 1); // Decay failures\n    }\n  }\n  \n  private onFailure(error: any): void {\n    if (this.state === 'half_open') {\n      // Immediate reopen on any failure in half-open\n      this.transitionToOpen();\n    } else if (this.state === 'closed') {\n      this.failureCount++;\n      if (this.failureCount >= this.config.failureThreshold) {\n        this.transitionToOpen();\n      }\n    }\n  }\n  \n  private transitionToOpen(): void {\n    this.state = 'open';\n    this.lastStateChange = Date.now();\n    this.successCount = 0;\n    console.warn(`Circuit breaker opened after ${this.failureCount} failures`);\n  }\n  \n  private transitionToHalfOpen(): void {\n    this.state = 'half_open';\n    this.lastStateChange = Date.now();\n    this.successCount = 0;\n    this.halfOpenRequestsAllowed = 1;\n    this.activeHalfOpenRequests = 0;\n    console.info('Circuit breaker entering half-open state');\n  }\n  \n  private transitionToClosed(): void {\n    this.state = 'closed';\n    this.lastStateChange = Date.now();\n    this.failureCount = 0;\n    this.successCount = 0;\n    console.info('Circuit breaker closed after successful recovery');\n  }\n}\n```\n\n**Token Bucket Rate Limiter**\n```typescript\nclass DistributedRateLimiter {\n  constructor(\n    private db: Database,\n    private providerId: string,\n    private limits: {\n      perSecond: number;\n      perMinute: number;\n      perHour?: number;\n    }\n  ) {}\n  \n  async acquire(): Promise<void> {\n    const windows = [\n      { type: 'second', limit: this.limits.perSecond, durationMs: 1000 },\n      { type: 'minute', limit: this.limits.perMinute, durationMs: 60000 },\n    ];\n    \n    if (this.limits.perHour) {\n      windows.push({ type: 'hour', limit: this.limits.perHour, durationMs: 3600000 });\n    }\n    \n    for (const window of windows) {\n      const windowStart = new Date(\n        Math.floor(Date.now() / window.durationMs) * window.durationMs\n      );\n      \n      const result = await this.db.query(`\n        INSERT INTO provider_rate_limits (provider_id, window_start, window_type, token_count)\n        VALUES ($1, $2, $3, 1)\n        ON CONFLICT (provider_id, window_start, window_type)\n        DO UPDATE SET \n          token_count = provider_rate_limits.token_count + 1,\n          updated_at = NOW()\n        RETURNING token_count\n      `, [this.providerId, windowStart, window.type]);\n      \n      const currentCount = result.rows[0].token_count;\n      \n      if (currentCount > window.limit) {\n        const retryAfterMs = windowStart.getTime() + window.durationMs - Date.now();\n        \n        // Exponential backoff for rate limit\n        await this.sleep(Math.min(retryAfterMs, 5000));\n        \n        throw new RateLimitError(\n          `Rate limit exceeded for ${window.type} window`,\n          retryAfterMs\n        );\n      }\n    }\n  }\n  \n  private sleep(ms: number): Promise<void> {\n    return new Promise(resolve => setTimeout(resolve, ms));\n  }\n}\n```\n\n**Retry Handler with Jitter**\n```typescript\nclass RetryHandler {\n  shouldRetry(attempt: number, error: NotificationError): boolean {\n    if (attempt >= 5) return false;\n    if (error.category === ErrorCategory.VALIDATION) return false;\n    if (error.category === ErrorCategory.PERMANENT) return false;\n    return error.retryable;\n  }\n  \n  calculateBackoff(attempt: number, error: NotificationError): number {\n    const baseMs = 1000;\n    const maxMs = 300000; // 5 minutes\n    \n    // Longer backoff for rate limits\n    const multiplier = error.category === ErrorCategory.RATE_LIMIT ? 3 : 1;\n    \n    // Exponential backoff: base * 2^attempt * multiplier\n    const exponential = baseMs * Math.pow(2, attempt) * multiplier;\n    \n    // Full jitter: random between 0 and exponential\n    const withJitter = Math.random() * exponential;\n    \n    return Math.min(withJitter, maxMs);\n  }\n}\n```\n\n### 7. Webhook Delivery System\n\n```typescript\nclass WebhookDeliveryService {\n  private webhookQueue: Queue; // Separate queue for webhooks\n  \n  async enqueueWebhook(webhook: WebhookPayload): Promise<void> {\n    // Non-blocking: fire and forget\n    await this.webhookQueue.enqueue({\n      url: webhook.url,\n      payload: webhook.payload,\n      maxAttempts: 3,\n      timeoutMs: 5000,\n    });\n  }\n  \n  async deliverWebhook(webhook: WebhookJob): Promise<void> {\n    try {\n      const response = await fetch(webhook.url, {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n          'X-Notification-Event': webhook.payload.event,\n          'X-Notification-ID': webhook.payload.notificationId,\n          'X-Signature': this.signPayload(webhook.payload),\n        },\n        body: JSON.stringify(webhook.payload),\n        signal: AbortSignal.timeout(webhook.timeoutMs),\n      });\n      \n      if (!response.ok) {\n        throw new Error(`Webhook returned ${response.status}`);\n      }\n      \n      // Log success\n      await this.logWebhookDelivery(webhook, 'success');\n      \n    } catch (error) {\n      // Log failure but don't block notification\n      await this.logWebhookDelivery(webhook, 'failed', error);\n      \n      // Retry with backoff\n      if (webhook.attempt < webhook.maxAttempts) {\n        await this.webhookQueue.requeueWithDelay(\n          webhook.id,\n          this.calculateBackoff(webhook.attempt)\n        );\n      }\n    }\n  }\n  \n  private signPayload(payload: any): string {\n    // HMAC signature for webhook verification\n    return crypto\n      .createHmac('sha256', process.env.WEBHOOK_SECRET!)\n      .update(JSON.stringify(payload))\n      .digest('hex');\n  }\n}\n```\n\n### 8. Background Maintenance\n\n```typescript\nclass MaintenanceService {\n  async start(): Promise<void> {\n    // Release stuck messages (every 60s)\n    setInterval(() => this.releaseStuckMessages(), 60000);\n    \n    // Expire old notifications (every 5 min)\n    setInterval(() => this.expireNotifications(), 300000);\n    \n    // Cleanup dead workers (every 5 min)\n    setInterval(() => this.cleanupDeadWorkers(), 300000);\n    \n    // Archive old records (daily)\n    setInterval(() => this.archiveOldRecords(), 86400000);\n  }\n  \n  private async releaseStuckMessages(): Promise<void> {\n    // Messages with expired leases\n    await this.db.query(`\n      UPDATE notification_queue\n      SET \n        status = 'pending',\n        worker_id = NULL,\n        lease_expiry = NULL,\n        visible_at = NOW() + interval '30 seconds'\n      WHERE status = 'processing'\n        AND lease_expiry < NOW()\n    `);\n  }\n  \n  private async expireNotifications(): Promise<void> {\n    await this.db.transaction(async (tx) => {\n      // Mark as expired\n      await tx.query(`\n        UPDATE notifications\n        SET status = 'expired', updated_at = NOW()\n        WHERE status IN ('pending', 'queued')\n          AND expires_at <= NOW()\n      `);\n      \n      // Remove from queue\n      await tx.query(`\n        DELETE FROM notification_queue\n        WHERE notification_id IN (\n          SELECT id FROM notifications WHERE status = 'expired'\n        )\n      `);\n    });\n  }\n  \n  private async cleanupDeadWorkers(): Promise<void> {\n    const cutoff = new Date(Date.now() - 600000); // 10 min\n    \n    await this.db.query(`\n      DELETE FROM worker_health\n      WHERE last_heartbeat < $1\n    `, [cutoff]);\n  }\n  \n  private async archiveOldRecords(): Promise<void> {\n    const archiveThreshold = new Date(Date.now() - 90 * 86400000); // 90 days\n    \n    await this.db.transaction(async (tx) => {\n      // Archive to cold storage (S3, etc.)\n      const oldRecords = await tx.query(`\n        SELECT * FROM notifications\n        WHERE created_at < $1\n          AND status IN ('sent', 'delivered', 'failed', 'expired', 'cancelled')\n      `, [archiveThreshold]);\n      \n      if (oldRecords.rows.length > 0) {\n        await this.archiveToS3(oldRecords.rows);\n        \n        await tx.query(`\n          DELETE FROM notifications\n          WHERE created_at < $1\n            AND status IN ('sent', 'delivered', 'failed', 'expired', 'cancelled')\n        `, [archiveThreshold]);\n      }\n    });\n  }\n}\n```\n\n### 9. Monitoring & Observability\n\n```typescript\ninterface NotificationMetrics {\n  // Counters\n  notificationsSent: Counter<{ channel: string; priority: string }>;\n  notificationsFailed: Counter<{ channel: string; errorCategory: string }>;\n  notificationsRetried: Counter<{ channel: string; attempt: number }>;\n  webhooksDelivered: Counter<{ success: boolean }>;\n  \n  // Gauges\n  queueDepth: Gauge<{ priority: string }>;\n  activeWorkers: Gauge;\n  circuitBreakerState: Gauge<{ provider: string }>; // 0=closed, 1=half-open, 2=open\n  oldestQueuedMessage: Gauge; // Age in seconds\n  \n  // Histograms\n  processingLatency: Histogram<{ channel: string }>; // End-to-end processing time\n  providerLatency: Histogram<{ provider: string }>; // Provider API call time\n  queueWaitTime: Histogram<{ priority: string }>; // Time in queue before processing\n  \n  // Business metrics\n  deliveryRate: Gauge<{ channel: string }>; // Success rate over time window\n  costPerNotification: Histogram<{ channel: string }>;\n}\n\n// Health check endpoint\napp.get('/health', async (req, res) => {\n  const checks = await Promise.all([\n    checkDatabase(),\n    checkQueue(),\n    checkProviders(),\n  ]);\n  \n  const healthy = checks.every(c => c.healthy);\n  \n  res.status(healthy ? 200 : 503).json({\n    status: healthy ? 'healthy' : 'unhealthy',\n    checks,\n    uptime: process.uptime(),\n    memory: process.memoryUsage(),\n  });\n});\n\n// Metrics endpoint (Prometheus format)\napp.get('/metrics', async (req, res) => {\n  res.set('Content-Type', register.contentType);\n  res.send(await register.metrics());\n});\n```\n\n## Rationale\n\n### Why Hybrid Queue Architecture?\n**PostgreSQL for < 5K msg/sec**: Simple, reliable, no additional infrastructure. Perfect for most use cases. The `pg_try_advisory_xact_lock` prevents phantom reads during dequeue.\n\n**Redis for 5K-50K msg/sec**: When PostgreSQL becomes the bottleneck, Redis sorted sets provide microsecond latency with Lua scripts for atomic operations.\n\n**SQS for > 50K msg/sec**: Fully managed, infinite scale, but adds network latency. Use when horizontal scaling is more important than latency.\n\n### Why Separate Queue Table?\nThe `notification_queue` table isolates high-churn queue operations from the canonical `notifications` record. This prevents index bloat and allows efficient archival of old notifications without affecting queue performance.\n\n### Why Lease-Based Processing?\nWorker crashes are inevitable. Leases with expiry ensure messages are automatically recovered without manual intervention. The `lease_expiry` and `worker_id` columns enable precise ownership tracking.\n\n### Why Advisory Locks in PostgreSQL?\n`SELECT FOR UPDATE SKIP LOCKED` prevents lock contention but doesn't prevent the same row being returned to multiple transactions in edge cases (serialization anomalies). Advisory locks guarantee exactly-once dequeue.\n\n### Webhook Design Decision\n**Non-blocking, best-effort**: Webhooks are delivered asynchronously in a separate queue with retry logic. Failed webhooks don't block notification delivery because:\n1. The notification provider has already accepted the message\n2. Webhook endpoints are outside our control and may be unreliable\n3. Users can query status via API if webhook fails\n\n## What I Changed\n\n### 1. **Fixed Dequeue Race Condition**\nAdded `pg_try_advisory_xact_lock` to prevent the subtle race where two workers can dequeue the same message under high concurrency (serialization anomalies). The previous design's `SELECT FOR UPDATE SKIP LOCKED` is necessary but not sufficient.\n\n### 2. **Separated Queue Table from Notifications**\nCreated `notification_queue` as a separate high-churn table. This:\n- Prevents bloat in the canonical `notifications` table\n- Enables efficient cleanup (delete from queue, keep notification history)\n- Improves index performance (smaller, more focused indexes)\n- Allows queue-specific fields (lease_expiry, visible_at) without cluttering main record\n\n### 3. **Clarified Webhook Semantics**\nMade webhooks explicitly **non-blocking and best-effort** with a separate delivery queue. Previous design was ambiguous about whether webhook failures should block notification completion.\n\n### 4. **Added Hybrid Queue Architecture**\nProvided three queue implementations (Postgres, Redis, SQS) with clear scaling thresholds. This gives a migration path as load increases without rewriting the entire system.\n\n### 5. **Simplified Worker Lifecycle**\nAdded explicit worker health tracking, heartbeat loop, and lease extension loop. This makes worker management observable and debuggable.\n\n### 6. **Enhanced Circuit Breaker**\nImproved half-open state to gradually increase allowed concurrent requests (starting with 1, growing to N) rather than immediately allowing full traffic. This prevents thundering herd on recovery.\n\n### 7. **Removed Optimistic Locking Version**\nThe `version` field is redundant when using advisory locks for dequeue. Removed to simplify the design (YAGNI principle).\n\n## What I Kept\n\n- Priority queue with efficient indexing\n- Exponential backoff with jitter\n- Separate DLQ for permanent failures\n- Distributed rate limiting with token bucket\n- Circuit breaker per provider\n- Template versioning system\n- Device token management\n- Comprehensive audit trail\n- Maintenance jobs for cleanup/archival\n- Prometheus metrics integration\n\n## Open Questions\n\n### 1. **Queue Migration Strategy**\nWhen transitioning from Postgres \u2192 Redis \u2192 SQS, how do we handle in-flight messages? Options:\n- **Drain old queue first** (simple but causes processing pause)\n- **Dual-write to both queues** (complex but zero downtime)\n- **Message forwarding** (old queue forwards to new queue during transition)\n\n### 2. **Provider Failover**\nShould we support automatic failover between providers (e.g., SendGrid \u2192 AWS SES)? This adds complexity:\n- Need provider priority/preference configuration\n- Cost implications (backup provider may be more expensive)\n- Different providers have different capabilities (templates, tracking, etc.)\n- Recipient's provider preference may matter (deliverability)\n\n### 3. **Multi-Tenancy**\nFor SaaS use cases:\n- Should tenants provide their own API keys (better security, cost attribution)?\n- Or use shared provider pool (simpler but commingled rate limits)?\n- Need `tenant_id` throughout schema if supporting multi-tenancy\n\n### 4. **Delivery Tracking**\nSome providers (FCM, SES) support delivery webhooks. Should we:\n- Update `status` from `sent` to `delivered` when webhook received?\n- Store delivery latency for SLA monitoring?\n- Retry on delivery failure vs. send failure?\n\n### 5. **Cost Attribution**\nThe `estimateCost()` method exists but costs aren't persisted. For billing/attribution:\n- Add `estimated_cost` and `actual_cost` columns?\n- Aggregate by tenant/user/channel for billing?\n- Track provider pricing changes over time?\n\n## Convergence Status\n\n**ITERATING** - Core architecture is solid but need feedback on queue migration strategy and multi-tenancy approach before finalizing.\n\nPROMPT_FOR_CRITIC:\nFocus on the **dequeue race condition fix** with advisory locks - does this actually prevent all race conditions in high-concurrency scenarios? Also, critique the **queue migration strategy** from Postgres \u2192 Redis \u2192 SQS: is dual-write viable, or should we mandate drain-first? Finally, challenge the **webhook semantics** - is best-effort acceptable, or should webhook failures retry indefinitely with exponential backoff?"
      },
      "agent_b": {
        "content": "## Design\n\n# Notification Service Architecture\n\n## System Overview\nA horizontally-scalable notification service supporting pluggable channels (email, push, SMS, etc.) with exactly-once delivery guarantees, hybrid queue architecture, and production-grade resilience patterns.\n\n## Architecture Components\n\n### 1. Core Service Layer\n\n**NotificationService (Orchestrator)**\n```typescript\ninterface NotificationService {\n  send(request: NotificationRequest): Promise<NotificationResult>;\n  sendBatch(requests: NotificationRequest[]): Promise<BatchResult>;\n  getStatus(notificationId: string): Promise<NotificationStatus>;\n  cancel(notificationId: string): Promise<void>;\n  retry(notificationId: string): Promise<NotificationResult>;\n}\n\ninterface BatchResult {\n  results: NotificationResult[];\n  summary: {\n    total: number;\n    succeeded: number;\n    failed: number;\n    pending: number;\n  };\n}\n```\n\n**Channel Provider (Strategy Pattern)**\n```typescript\ninterface ChannelProvider {\n  readonly type: ChannelType;\n  readonly capabilities: ProviderCapabilities;\n  \n  send(message: ChannelMessage): Promise<ProviderResult>;\n  validateRecipient(recipient: Recipient): ValidationResult;\n  healthCheck(): Promise<HealthStatus>;\n}\n\ninterface ProviderCapabilities {\n  batchSend: {\n    supported: boolean;\n    maxBatchSize?: number;\n  };\n  rateLimit: {\n    perSecond: number;\n    perMinute: number;\n    perHour?: number;\n  };\n  features: {\n    deliveryTracking: boolean;\n    scheduling: boolean;\n    richContent: boolean;\n  };\n}\n\ninterface ProviderResult {\n  success: boolean;\n  providerId: string;\n  providerMessageId?: string;\n  error?: ProviderError;\n  metadata?: Record<string, any>;\n}\n\n// Implementations\nclass SendGridEmailProvider implements ChannelProvider\nclass FCMPushProvider implements ChannelProvider\nclass TwilioSMSProvider implements ChannelProvider\n```\n\n### 2. Hybrid Queue Architecture with Safe Migration\n\n**Queue Abstraction Layer**\n```typescript\ninterface QueueAdapter {\n  enqueue(message: QueueMessage, options: EnqueueOptions): Promise<string>;\n  dequeue(workerId: string, count: number): Promise<QueueMessage[]>;\n  ack(messageId: string, workerId: string): Promise<void>;\n  nack(messageId: string, workerId: string, reason: string): Promise<void>;\n  requeueWithDelay(messageId: string, delayMs: number): Promise<void>;\n  extendVisibility(messageId: string, workerId: string, durationMs: number): Promise<void>;\n  getDepth(priority?: NotificationPriority): Promise<number>;\n  \n  // Migration support\n  migrateMessage?(message: QueueMessage, targetQueue: QueueAdapter): Promise<void>;\n  isDraining?(): boolean;\n}\n\ninterface EnqueueOptions {\n  priority: NotificationPriority;\n  visibilityDelay: number;\n  deduplicationId?: string;\n  skipIfDraining?: boolean; // For migration: route to new queue if true\n}\n\ninterface QueueMessage {\n  id: string;\n  notificationId: string;\n  payload: NotificationRequest;\n  priority: NotificationPriority;\n  enqueuedAt: Date;\n  visibleAt: Date;\n  dequeueCount: number;\n  workerId?: string;\n  leaseExpiry?: Date;\n  sourceQueue?: string; // Track which queue implementation owns this message\n}\n\n// Implementations for different scales\nclass PostgresQueueAdapter implements QueueAdapter // < 5K msg/sec\nclass RedisQueueAdapter implements QueueAdapter    // 5K-50K msg/sec\nclass SQSQueueAdapter implements QueueAdapter      // > 50K msg/sec\n```\n\n**Critical Fix: PostgreSQL Queue with Advisory Locks + Row Versioning**\n```typescript\nclass PostgresQueueAdapter implements QueueAdapter {\n  private draining = false;\n  private targetQueue?: QueueAdapter;\n  \n  async dequeue(workerId: string, count: number): Promise<QueueMessage[]> {\n    const leaseMs = 300000; // 5 minutes\n    \n    // CRITICAL: Combine advisory locks + CTE + optimistic locking\n    const result = await this.db.query(`\n      WITH selected AS (\n        SELECT \n          id,\n          version,\n          hashtext(id::text) as lock_id\n        FROM notification_queue\n        WHERE status = 'pending'\n          AND visible_at <= NOW()\n          AND (expires_at IS NULL OR expires_at > NOW())\n          AND pg_try_advisory_xact_lock(hashtext(id::text))\n        ORDER BY \n          priority_order ASC,\n          visible_at ASC\n        LIMIT $1\n        FOR UPDATE SKIP LOCKED  -- Double protection against phantom reads\n      )\n      UPDATE notification_queue nq\n      SET \n        status = 'processing',\n        worker_id = $2,\n        lease_expiry = NOW() + ($3 || ' milliseconds')::interval,\n        dequeue_count = dequeue_count + 1,\n        last_dequeued_at = NOW(),\n        version = version + 1\n      FROM selected\n      WHERE nq.id = selected.id\n        AND nq.version = selected.version  -- Optimistic lock check\n      RETURNING nq.*\n    `, [count, workerId, leaseMs]);\n    \n    // Advisory locks auto-release at transaction end\n    return result.rows.map(this.mapToQueueMessage);\n  }\n  \n  async ack(messageId: string, workerId: string): Promise<void> {\n    const result = await this.db.transaction(async (tx) => {\n      // Move to notifications table and delete from queue atomically\n      const result = await tx.query(`\n        WITH deleted AS (\n          DELETE FROM notification_queue\n          WHERE id = $1 \n            AND worker_id = $2\n            AND status = 'processing'\n          RETURNING *\n        )\n        UPDATE notifications\n        SET \n          status = 'sent',\n          sent_at = NOW(),\n          provider_response = deleted.provider_response,\n          processing_time_ms = EXTRACT(EPOCH FROM (NOW() - deleted.last_dequeued_at)) * 1000,\n          source_queue = deleted.source_queue\n        FROM deleted\n        WHERE notifications.id = deleted.notification_id\n        RETURNING notifications.id\n      `, [messageId, workerId]);\n      \n      return result;\n    });\n    \n    if (result.rowCount === 0) {\n      throw new Error(`Cannot ack message ${messageId}: not owned by worker ${workerId}`);\n    }\n  }\n  \n  async nack(messageId: string, workerId: string, reason: string): Promise<void> {\n    await this.db.query(`\n      UPDATE notification_queue\n      SET \n        status = CASE \n          WHEN dequeue_count >= max_attempts THEN 'failed'\n          ELSE 'pending'\n        END,\n        worker_id = NULL,\n        lease_expiry = NULL,\n        last_error = $3,\n        visible_at = CASE\n          WHEN dequeue_count >= max_attempts THEN visible_at\n          ELSE NOW() + (power(2, LEAST(dequeue_count, 8)) * interval '1 second') -- Cap at 256s\n        END,\n        version = version + 1\n      WHERE id = $1 \n        AND worker_id = $2\n        AND status = 'processing'\n    `, [messageId, workerId, JSON.stringify({ reason, timestamp: new Date() })]);\n  }\n  \n  // Migration support\n  enableDraining(targetQueue: QueueAdapter): void {\n    this.draining = true;\n    this.targetQueue = targetQueue;\n  }\n  \n  isDraining(): boolean {\n    return this.draining;\n  }\n  \n  async enqueue(message: QueueMessage, options: EnqueueOptions): Promise<string> {\n    // If draining, route new messages to target queue\n    if (this.draining && options.skipIfDraining && this.targetQueue) {\n      return this.targetQueue.enqueue(message, options);\n    }\n    \n    // Otherwise, enqueue normally\n    const priority = this.getPriorityOrder(options.priority);\n    \n    const result = await this.db.query(`\n      INSERT INTO notification_queue (\n        id,\n        notification_id,\n        priority_order,\n        visible_at,\n        expires_at,\n        max_attempts,\n        source_queue\n      ) VALUES ($1, $2, $3, $4, $5, 5, 'postgres')\n      ON CONFLICT (id) DO NOTHING\n      RETURNING id\n    `, [\n      message.id,\n      message.notificationId,\n      priority,\n      new Date(Date.now() + options.visibilityDelay),\n      message.payload.expiresAt,\n    ]);\n    \n    return result.rows[0]?.id || message.id;\n  }\n}\n```\n\n**Queue Migration Orchestrator**\n```typescript\nclass QueueMigrationOrchestrator {\n  constructor(\n    private sourceQueue: QueueAdapter,\n    private targetQueue: QueueAdapter,\n    private db: Database\n  ) {}\n  \n  async migrate(strategy: 'drain-first' | 'live-forward'): Promise<void> {\n    if (strategy === 'drain-first') {\n      await this.drainFirstMigration();\n    } else {\n      await this.liveForwardMigration();\n    }\n  }\n  \n  private async drainFirstMigration(): Promise<void> {\n    console.log('Starting drain-first migration...');\n    \n    // Step 1: Stop accepting new messages to source queue\n    if (this.sourceQueue.enableDraining) {\n      this.sourceQueue.enableDraining(this.targetQueue);\n    }\n    \n    // Step 2: Wait for source queue to drain (with timeout)\n    const maxWaitMs = 3600000; // 1 hour\n    const startTime = Date.now();\n    \n    while (Date.now() - startTime < maxWaitMs) {\n      const depth = await this.sourceQueue.getDepth();\n      console.log(`Source queue depth: ${depth}`);\n      \n      if (depth === 0) {\n        console.log('Source queue drained successfully');\n        break;\n      }\n      \n      await this.sleep(5000); // Check every 5s\n    }\n    \n    // Step 3: Switch all workers to target queue\n    await this.db.query(`\n      UPDATE worker_config\n      SET queue_implementation = $1\n    `, [this.getQueueType(this.targetQueue)]);\n    \n    // Step 4: Verify no stuck messages\n    const stuckCount = await this.checkStuckMessages();\n    if (stuckCount > 0) {\n      throw new Error(`Migration aborted: ${stuckCount} stuck messages in source queue`);\n    }\n    \n    console.log('Migration complete');\n  }\n  \n  private async liveForwardMigration(): Promise<void> {\n    console.log('Starting live-forward migration...');\n    \n    // Step 1: Enable forwarding mode (new messages go to target)\n    if (this.sourceQueue.enableDraining) {\n      this.sourceQueue.enableDraining(this.targetQueue);\n    }\n    \n    // Step 2: Spawn dedicated drain workers for source queue\n    const drainWorkerCount = 5;\n    const drainWorkers = Array.from({ length: drainWorkerCount }, (_, i) =>\n      this.spawnDrainWorker(`drain-worker-${i}`)\n    );\n    \n    // Step 3: Monitor drain progress\n    const progressInterval = setInterval(async () => {\n      const depth = await this.sourceQueue.getDepth();\n      console.log(`Source queue remaining: ${depth}`);\n    }, 10000);\n    \n    // Step 4: Wait for all drain workers to finish\n    await Promise.all(drainWorkers);\n    clearInterval(progressInterval);\n    \n    // Step 5: Switch all workers to target queue\n    await this.db.query(`\n      UPDATE worker_config\n      SET queue_implementation = $1\n    `, [this.getQueueType(this.targetQueue)]);\n    \n    console.log('Live-forward migration complete');\n  }\n  \n  private async spawnDrainWorker(workerId: string): Promise<void> {\n    while (true) {\n      const messages = await this.sourceQueue.dequeue(workerId, 10);\n      \n      if (messages.length === 0) {\n        console.log(`${workerId} finished draining`);\n        break;\n      }\n      \n      // Process normally (will be acked from source queue)\n      for (const msg of messages) {\n        try {\n          await this.processMessage(msg);\n          await this.sourceQueue.ack(msg.id, workerId);\n        } catch (error) {\n          await this.sourceQueue.nack(msg.id, workerId, error.message);\n        }\n      }\n    }\n  }\n  \n  private async checkStuckMessages(): Promise<number> {\n    const result = await this.db.query(`\n      SELECT COUNT(*)\n      FROM notification_queue\n      WHERE status = 'processing'\n        AND lease_expiry < NOW()\n    `);\n    \n    return parseInt(result.rows[0].count);\n  }\n  \n  private getQueueType(queue: QueueAdapter): string {\n    if (queue instanceof PostgresQueueAdapter) return 'postgres';\n    if (queue instanceof RedisQueueAdapter) return 'redis';\n    if (queue instanceof SQSQueueAdapter) return 'sqs';\n    throw new Error('Unknown queue type');\n  }\n  \n  private sleep(ms: number): Promise<void> {\n    return new Promise(resolve => setTimeout(resolve, ms));\n  }\n  \n  private async processMessage(msg: QueueMessage): Promise<void> {\n    // Delegate to actual worker implementation\n    // This is a stub for migration purposes\n    throw new Error('Must be implemented by actual worker');\n  }\n}\n```\n\n**Redis Queue (for high scale)**\n```typescript\nclass RedisQueueAdapter implements QueueAdapter {\n  async enqueue(message: QueueMessage, options: EnqueueOptions): Promise<string> {\n    const priority = this.getPriorityMultiplier(options.priority);\n    const score = priority * 1e12 + options.visibilityDelay + Date.now();\n    \n    const pipeline = this.redis.pipeline();\n    \n    pipeline.hset(`msg:${message.id}`, {\n      payload: JSON.stringify(message.payload),\n      notificationId: message.notificationId,\n      enqueuedAt: message.enqueuedAt.toISOString(),\n      dequeueCount: 0,\n      maxAttempts: 5,\n      sourceQueue: 'redis',\n    });\n    \n    pipeline.zadd('notification_queue', score, message.id);\n    \n    // Deduplication with atomic check\n    if (options.deduplicationId) {\n      const dedupKey = `dedup:${options.deduplicationId}`;\n      pipeline.set(dedupKey, message.id, 'EX', 3600, 'NX');\n    }\n    \n    await pipeline.exec();\n    return message.id;\n  }\n  \n  async dequeue(workerId: string, count: number): Promise<QueueMessage[]> {\n    const now = Date.now();\n    const leaseMs = 300000;\n    \n    // Lua script for atomic dequeue with lease\n    const script = `\n      local queue_key = KEYS[1]\n      local processing_key = KEYS[2]\n      local now = tonumber(ARGV[1])\n      local count = tonumber(ARGV[2])\n      local worker_id = ARGV[3]\n      local lease_ms = tonumber(ARGV[4])\n      \n      local ids = redis.call('ZRANGEBYSCORE', queue_key, 0, now, 'LIMIT', 0, count)\n      \n      if #ids == 0 then\n        return {}\n      end\n      \n      local messages = {}\n      for _, id in ipairs(ids) do\n        redis.call('ZREM', queue_key, id)\n        redis.call('ZADD', processing_key, now + lease_ms, id)\n        \n        redis.call('HMSET', 'msg:' .. id, \n          'workerId', worker_id,\n          'leaseExpiry', now + lease_ms\n        )\n        \n        local dequeue_count = redis.call('HINCRBY', 'msg:' .. id, 'dequeueCount', 1)\n        redis.call('HSET', 'msg:' .. id, 'dequeueCount', dequeue_count)\n        \n        local msg = redis.call('HGETALL', 'msg:' .. id)\n        table.insert(messages, msg)\n      end\n      \n      return messages\n    `;\n    \n    const results = await this.redis.eval(\n      script,\n      2,\n      'notification_queue',\n      'processing_queue',\n      now,\n      count,\n      workerId,\n      leaseMs\n    );\n    \n    return this.parseRedisMessages(results);\n  }\n}\n```\n\n### 3. Worker Pool Architecture\n\n```typescript\nclass NotificationWorker {\n  private workerId: string;\n  private queue: QueueAdapter;\n  private providers: Map<ChannelType, ChannelProvider>;\n  private rateLimiters: Map<string, RateLimiter>;\n  private circuitBreakers: Map<string, CircuitBreaker>;\n  private running = false;\n  private processingMessages = new Map<string, QueueMessage>(); // Track for lease extension\n  \n  constructor(\n    private config: WorkerConfig,\n    private db: Database\n  ) {\n    this.workerId = `${os.hostname()}-${process.pid}-${randomUUID()}`;\n    this.initializeQueue();\n    this.initializeProviders();\n  }\n  \n  async start(): Promise<void> {\n    this.running = true;\n    \n    // Start processing loop\n    this.processLoop();\n    \n    // Start heartbeat for worker health\n    this.heartbeatLoop();\n    \n    // Start lease extension for long-running tasks\n    this.leaseExtensionLoop();\n  }\n  \n  private async processLoop(): Promise<void> {\n    while (this.running) {\n      try {\n        const messages = await this.queue.dequeue(\n          this.workerId,\n          this.config.batchSize\n        );\n        \n        if (messages.length === 0) {\n          await this.sleep(this.config.pollIntervalMs);\n          continue;\n        }\n        \n        // Process in parallel with concurrency limit\n        await pMap(\n          messages,\n          (msg) => this.processMessage(msg),\n          { concurrency: this.config.concurrency }\n        );\n        \n      } catch (error) {\n        console.error('Worker process loop error:', error);\n        await this.sleep(5000);\n      }\n    }\n  }\n  \n  private async processMessage(message: QueueMessage): Promise<void> {\n    const startTime = Date.now();\n    let trackingSpan: Span | undefined;\n    \n    // Track for lease extension\n    this.processingMessages.set(message.id, message);\n    \n    try {\n      trackingSpan = this.tracer.startSpan('process_notification', {\n        attributes: {\n          notificationId: message.notificationId,\n          channel: message.payload.channel,\n          priority: message.payload.priority,\n        }\n      });\n      \n      const provider = this.providers.get(message.payload.channel);\n      if (!provider) {\n        throw new NotificationError(\n          ErrorCategory.INTERNAL,\n          'NO_PROVIDER',\n          `No provider for channel ${message.payload.channel}`,\n          false\n        );\n      }\n      \n      const rateLimiter = this.rateLimiters.get(provider.type);\n      await rateLimiter.acquire();\n      \n      const circuitBreaker = this.circuitBreakers.get(provider.type);\n      \n      const result = await circuitBreaker.execute(() =>\n        provider.send(this.buildChannelMessage(message.payload))\n      );\n      \n      await this.db.query(`\n        UPDATE notifications\n        SET \n          provider_message_id = $1,\n          provider_response = $2\n        WHERE id = $3\n      `, [result.providerMessageId, result.metadata, message.notificationId]);\n      \n      await this.queue.ack(message.id, this.workerId);\n      \n      // Fire webhook asynchronously (non-blocking)\n      if (message.payload.callbackUrl) {\n        this.fireWebhookAsync(message.payload.callbackUrl, {\n          notificationId: message.notificationId,\n          status: 'sent',\n          sentAt: new Date(),\n        }).catch(err => {\n          console.error('Webhook delivery failed:', err);\n        });\n      }\n      \n      this.metrics.notificationsSent.inc({\n        channel: message.payload.channel,\n        priority: message.payload.priority,\n      });\n      \n      this.metrics.processingLatency.observe(\n        { channel: message.payload.channel },\n        Date.now() - startTime\n      );\n      \n    } catch (error) {\n      const notifError = this.normalizeError(error);\n      \n      await this.db.query(`\n        UPDATE notifications\n        SET \n          last_error = $1,\n          attempt_count = $2\n        WHERE id = $3\n      `, [\n        JSON.stringify(notifError),\n        message.dequeueCount,\n        message.notificationId\n      ]);\n      \n      const shouldRetry = this.shouldRetry(message.dequeueCount, notifError);\n      \n      if (shouldRetry) {\n        await this.queue.nack(message.id, this.workerId, notifError.message);\n        \n        this.metrics.notificationsRetried.inc({\n          channel: message.payload.channel,\n          errorCategory: notifError.category,\n        });\n      } else {\n        await this.moveToDLQ(message, notifError);\n        await this.queue.ack(message.id, this.workerId);\n        \n        this.metrics.notificationsFailed.inc({\n          channel: message.payload.channel,\n          errorCategory: notifError.category,\n        });\n      }\n      \n    } finally {\n      trackingSpan?.end();\n      this.processingMessages.delete(message.id);\n    }\n  }\n  \n  private async leaseExtensionLoop(): Promise<void> {\n    while (this.running) {\n      await this.sleep(60000); // Every minute\n      \n      const now = Date.now();\n      \n      for (const [msgId, msg] of this.processingMessages.entries()) {\n        if (!msg.leaseExpiry) continue;\n        \n        const timeLeft = msg.leaseExpiry.getTime() - now;\n        \n        // Extend if less than 2 minutes remaining\n        if (timeLeft < 120000 && timeLeft > 0) {\n          try {\n            await this.queue.extendVisibility(msgId, this.workerId, 300000);\n            // Update local tracking\n            msg.leaseExpiry = new Date(now + 300000);\n          } catch (error) {\n            console.error(`Failed to extend lease for ${msgId}:`, error);\n          }\n        }\n      }\n    }\n  }\n  \n  private async heartbeatLoop(): Promise<void> {\n    while (this.running) {\n      await this.db.query(`\n        INSERT INTO worker_health (worker_id, last_heartbeat, processing_count)\n        VALUES ($1, NOW(), $2)\n        ON CONFLICT (worker_id) \n        DO UPDATE SET \n          last_heartbeat = NOW(),\n          processing_count = $2\n      `, [this.workerId, this.processingMessages.size]);\n      \n      await this.sleep(30000); // Every 30 seconds\n    }\n  }\n}\n```\n\n### 4. Configurable Webhook Delivery System\n\n```typescript\nenum WebhookRetryPolicy {\n  BEST_EFFORT = 'best_effort',         // 3 retries over 5 minutes\n  AGGRESSIVE = 'aggressive',           // 10 retries over 24 hours\n  PERSISTENT = 'persistent',           // Retry indefinitely with exponential backoff (max 1 week intervals)\n}\n\ninterface WebhookConfig {\n  url: string;\n  retryPolicy: WebhookRetryPolicy;\n  timeoutMs: number;\n  maxRetries?: number;  // Override policy default\n  authHeader?: string;  // Custom auth\n}\n\nclass WebhookDeliveryService {\n  private webhookQueue: Queue;\n  \n  async enqueueWebhook(webhook: WebhookPayload, config: WebhookConfig): Promise<void> {\n    const policyConfig = this.getPolicyConfig(config.retryPolicy);\n    \n    await this.webhookQueue.enqueue({\n      url: config.url,\n      payload: webhook.payload,\n      maxAttempts: config.maxRetries ?? policyConfig.maxAttempts,\n      timeoutMs: config.timeoutMs,\n      retryPolicy: config.retryPolicy,\n      authHeader: config.authHeader,\n      backoffConfig: policyConfig.backoff,\n    });\n  }\n  \n  private getPolicyConfig(policy: WebhookRetryPolicy) {\n    switch (policy) {\n      case WebhookRetryPolicy.BEST_EFFORT:\n        return {\n          maxAttempts: 3,\n          backoff: { base: 30000, max: 120000, multiplier: 2 }, // 30s, 60s, 120s\n        };\n      case WebhookRetryPolicy.AGGRESSIVE:\n        return {\n          maxAttempts: 10,\n          backoff: { base: 60000, max: 3600000, multiplier: 2 }, // Up to 1 hour intervals\n        };\n      case WebhookRetryPolicy.PERSISTENT:\n        return {\n          maxAttempts: Number.MAX_SAFE_INTEGER, // Effectively infinite\n          backoff: { base: 60000, max: 604800000, multiplier: 2 }, // Up to 1 week intervals\n        };\n    }\n  }\n  \n  async deliverWebhook(webhook: WebhookJob): Promise<void> {\n    try {\n      const controller = new AbortController();\n      const timeoutId = setTimeout(() => controller.abort(), webhook.timeoutMs);\n      \n      const response = await fetch(webhook.url, {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n          'X-Notification-Event': webhook.payload.event,\n          'X-Notification-ID': webhook.payload.notificationId,\n          'X-Signature': this.signPayload(webhook.payload),\n          'X-Attempt': webhook.attempt.toString(),\n          ...(webhook.authHeader && { 'Authorization': webhook.authHeader }),\n        },\n        body: JSON.stringify(webhook.payload),\n        signal: controller.signal,\n      });\n      \n      clearTimeout(timeoutId);\n      \n      if (!response.ok) {\n        throw new Error(`Webhook returned ${response.status}: ${await response.text()}`);\n      }\n      \n      await this.logWebhookDelivery(webhook, 'success', { \n        statusCode: response.status,\n        latencyMs: Date.now() - webhook.startTime \n      });\n      \n    } catch (error) {\n      await this.logWebhookDelivery(webhook, 'failed', { error: error.message });\n      \n      // Calculate backoff\n      const backoffMs = this.calculateBackoff(\n        webhook.attempt,\n        webhook.backoffConfig\n      );\n      \n      // Determine if should retry\n      const shouldRetry = \n        webhook.attempt < webhook.maxAttempts &&\n        this.isRetryableError(error);\n      \n      if (shouldRetry) {\n        await this.webhookQueue.requeueWithDelay(webhook.id, backoffMs);\n      } else {\n        // Move to webhook DLQ after exhausting retries\n        await this.moveWebhookToDLQ(webhook, error);\n        \n        // Update notification record with webhook failure\n        await this.db.query(`\n          UPDATE notifications\n          SET webhook_failed = true, webhook_failure_reason = $1\n          WHERE id = $2\n        `, [error.message, webhook.payload.notificationId]);\n      }\n    }\n  }\n  \n  private calculateBackoff(attempt: number, config: BackoffConfig): number {\n    const exponential = config.base * Math.pow(config.multiplier, attempt - 1);\n    const withJitter = exponential * (0.5 + Math.random() * 0.5); // 50-100% jitter\n    return Math.min(withJitter, config.max);\n  }\n  \n  private isRetryableError(error: any): boolean {\n    // Network errors, timeouts, and 5xx are retryable\n    // 4xx (except 429) are not retryable\n    if (error.name === 'AbortError') return true; // Timeout\n    if (error.code === 'ECONNREFUSED' || error.code === 'ETIMEDOUT') return true;\n    \n    const statusCode = error.response?.status;\n    if (statusCode) {\n      if (statusCode === 429) return true; // Rate limit\n      if (statusCode >= 500) return true;  // Server error\n      return false; // Client error (4xx)\n    }\n    \n    return true; // Unknown errors are retryable\n  }\n  \n  private signPayload(payload: any): string {\n    return crypto\n      .createHmac('sha256', process.env.WEBHOOK_SECRET!)\n      .update(JSON.stringify(payload))\n      .digest('hex');\n  }\n}\n```\n\n### 5. Enhanced Circuit Breaker with Gradual Recovery\n\n```typescript\nclass CircuitBreaker {\n  private state: 'closed' | 'open' | 'half_open' = 'closed';\n  private failureCount = 0;\n  private successCount = 0;\n  private lastStateChange = Date.now();\n  private halfOpenRequestsAllowed = 1;\n  private activeHalfOpenRequests = 0;\n  private lastErrors: Array<{ time: number; error: any }> = [];\n  \n  constructor(\n    private readonly config: {\n      failureThreshold: number;\n      failureRateThreshold: number; // Percentage (0-100)\n      windowMs: number; // Time window for calculating failure rate\n      openDurationMs: number;\n      halfOpenSuccessThreshold: number;\n      halfOpenMaxConcurrent: number;\n    }\n  ) {}\n  \n  async execute<T>(fn: () => Promise<T>): Promise<T> {\n    if (this.state === 'open') {\n      const timeSinceOpen = Date.now() - this.lastStateChange;\n      if (timeSinceOpen >= this.config.openDurationMs) {\n        this.transitionToHalfOpen();\n      } else {\n        throw new CircuitOpenError(\n          `Circuit open, retry after ${this.config.openDurationMs - timeSinceOpen}ms`\n        );\n      }\n    }\n    \n    if (this.state === 'half_open') {\n      if (this.activeHalfOpenRequests >= this.halfOpenRequestsAllowed) {\n        throw new CircuitOpenError('Half-open circuit at capacity');\n      }\n      this.activeHalfOpenRequests++;\n    }\n    \n    try {\n      const result = await fn();\n      this.onSuccess();\n      return result;\n    } catch (error) {\n      this.onFailure(error);\n      throw error;\n    } finally {\n      if (this.state === 'half_open') {\n        this.activeHalfOpenRequests--;\n      }\n    }\n  }\n  \n  private onSuccess(): void {\n    this.cleanupOldErrors();\n    \n    if (this.state === 'half_open') {\n      this.successCount++;\n      \n      if (this.successCount >= this.config.halfOpenSuccessThreshold) {\n        this.transitionToClosed();\n      } else {\n        // Gradually increase allowed concurrent requests (multiplicative increase)\n        this.halfOpenRequestsAllowed = Math.min(\n          Math.ceil(this.halfOpenRequestsAllowed * 1.5),\n          this.config.halfOpenMaxConcurrent\n        );\n      }\n    } else if (this.state === 'closed') {\n      // Decay failure count on success (graceful forgiveness)\n      this.failureCount = Math.max(0, this.failureCount - 1);\n    }\n  }\n  \n  private onFailure(error: any): void {\n    const now = Date.now();\n    this.lastErrors.push({ time: now, error });\n    this.cleanupOldErrors();\n    \n    if (this.state === 'half_open') {\n      // Immediate reopen on any failure in half-open (conservative)\n      this.transitionToOpen();\n    } else if (this.state === 'closed') {\n      this.failureCount++;\n      \n      // Check both absolute count and failure rate thresholds\n      const failureRate = this.calculateFailureRate();\n      \n      const shouldOpen = \n        this.failureCount >= this.config.failureThreshold ||\n        failureRate >= this.config.failureRateThreshold;\n      \n      if (shouldOpen) {\n        this.transitionToOpen();\n      }\n    }\n  }\n  \n  private calculateFailureRate(): number {\n    if (this.lastErrors.length === 0) return 0;\n    \n    const totalRequests = this.failureCount + this.successCount;\n    if (totalRequests === 0) return 0;\n    \n    return (this.lastErrors.length / totalRequests) * 100;\n  }\n  \n  private cleanupOldErrors(): void {\n    const cutoff = Date.now() - this.config.windowMs;\n    this.lastErrors = this.lastErrors.filter(e => e.time > cutoff);\n  }\n  \n  private transitionToOpen(): void {\n    this.state = 'open';\n    this.lastStateChange = Date.now();\n    this.successCount = 0;\n    console.warn(`Circuit breaker opened: ${this.failureCount} failures, ${this.calculateFailureRate().toFixed(1)}% failure rate`);\n  }\n  \n  private transitionToHalfOpen(): void {\n    this.state = 'half_open';\n    this.lastStateChange = Date.now();\n    this.successCount = 0;\n    this.halfOpenRequestsAllowed = 1; // Start conservative\n    this.activeHalfOpenRequests = 0;\n    console.info('Circuit breaker entering half-open state');\n  }\n  \n  private transitionToClosed(): void {\n    this.state = 'closed';\n    this.lastStateChange = Date.now();\n    this.failureCount = 0;\n    this.successCount = 0;\n    this.lastErrors = [];\n    console.info('Circuit breaker closed after successful recovery');\n  }\n}\n```\n\n### 6. Database Schema\n\n```sql\n-- Core notifications table\nCREATE TABLE notifications (\n  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n  channel VARCHAR(20) NOT NULL,\n  recipient JSONB NOT NULL,\n  content JSONB NOT NULL,\n  priority SMALLINT NOT NULL,\n  status VARCHAR(20) NOT NULL,\n  \n  idempotency_key VARCHAR(255),\n  callback_url TEXT,\n  webhook_retry_policy VARCHAR(20) DEFAULT 'best_effort',\n  webhook_failed BOOLEAN DEFAULT false,\n  webhook_failure_reason TEXT,\n  metadata JSONB,\n  \n  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  scheduled_for TIMESTAMPTZ,\n  expires_at TIMESTAMPTZ,\n  \n  sent_at TIMESTAMPTZ,\n  delivered_at TIMESTAMPTZ,\n  failed_at TIMESTAMPTZ,\n  \n  attempt_count INTEGER NOT NULL DEFAULT 0,\n  max_attempts INTEGER NOT NULL DEFAULT 5,\n  last_error JSONB,\n  \n  provider_message_id VARCHAR(255),\n  provider_response JSONB,\n  processing_time_ms INTEGER,\n  source_queue VARCHAR(20), -- Track which queue processed this\n  \n  CONSTRAINT uq_idempotency UNIQUE (idempotency_key)\n);\n\nCREATE INDEX idx_notifications_status ON notifications(status, created_at DESC);\nCREATE INDEX idx_notifications_scheduled ON notifications(scheduled_for) \n  WHERE status = 'pending' AND scheduled_for IS NOT NULL;\nCREATE INDEX idx_notifications_expires ON notifications(expires_at) \n  WHERE status IN ('pending', 'queued') AND expires_at IS NOT NULL;\n\n-- Separate queue table for high-throughput processing\nCREATE TABLE notification_queue (\n  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n  notification_id UUID NOT NULL REFERENCES notifications(id) ON DELETE CASCADE,\n  \n  status VARCHAR(20) NOT NULL DEFAULT 'pending',\n  priority_order INTEGER NOT NULL,\n  \n  visible_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  expires_at TIMESTAMPTZ,\n  \n  worker_id VARCHAR(255),\n  lease_expiry TIMESTAMPTZ,\n  \n  dequeue_count INTEGER NOT NULL DEFAULT 0,\n  max_attempts INTEGER NOT NULL DEFAULT 5,\n  last_error JSONB,\n  last_dequeued_at TIMESTAMPTZ,\n  \n  source_queue VARCHAR(20) NOT NULL, -- 'postgres', 'redis', 'sqs'\n  \n  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW()\n);\n\nCREATE INDEX idx_queue_processing ON notification_queue(\n  priority_order ASC,\n  visible_at ASC\n) WHERE status = 'pending';\n\nCREATE INDEX idx_queue_stuck ON notification_queue(lease_expiry, worker_id)\n  WHERE status = 'processing' AND lease_expiry IS NOT NULL;\n\n-- Dead letter queue\nCREATE TABLE notification_dlq (\n  id UUID PRIMARY KEY,\n  notification_id UUID NOT NULL,\n  original_request JSONB NOT NULL,\n  final_error JSONB NOT NULL,\n  attempt_count INTEGER NOT NULL,\n  failed_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  requeued_at TIMESTAMPTZ,\n  source_queue VARCHAR(20),\n  \n  INDEX idx_dlq_failed_at (failed_at DESC)\n);\n\n-- Webhook DLQ (separate from notification DLQ)\nCREATE TABLE webhook_dlq (\n  id UUID PRIMARY KEY,\n  notification_id UUID NOT NULL,\n  webhook_url TEXT NOT NULL,\n  webhook_payload JSONB NOT NULL,\n  retry_policy VARCHAR(20) NOT NULL,\n  final_error JSONB NOT NULL,\n  attempt_count INTEGER NOT NULL,\n  failed_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  \n  INDEX idx_webhook_dlq_notification (notification_id),\n  INDEX idx_webhook_dlq_failed_at (failed_at DESC)\n);\n\n-- Worker health tracking\nCREATE TABLE worker_health (\n  worker_id VARCHAR(255) PRIMARY KEY,\n  last_heartbeat TIMESTAMPTZ NOT NULL,\n  processing_count INTEGER NOT NULL DEFAULT 0,\n  queue_implementation VARCHAR(20), -- 'postgres', 'redis', 'sqs'\n  started_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  \n  INDEX idx_worker_heartbeat (last_heartbeat DESC)\n);\n\n-- Worker configuration (for migration)\nCREATE TABLE worker_config (\n  id SERIAL PRIMARY KEY,\n  queue_implementation VARCHAR(20) NOT NULL,\n  updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()\n);\n\n-- Audit trail\nCREATE TABLE notification_events (\n  id BIGSERIAL PRIMARY KEY,\n  notification_id UUID NOT NULL REFERENCES notifications(id) ON DELETE CASCADE,\n  event_type VARCHAR(50) NOT NULL,\n  from_status VARCHAR(20),\n  to_status VARCHAR(20),\n  worker_id VARCHAR(255),\n  error JSONB,\n  metadata JSONB,\n  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  \n  INDEX idx_events_notification (notification_id, created_at DESC),\n  INDEX idx_events_type (event_type, created_at DESC)\n);\n\n-- Provider rate limiting\nCREATE TABLE provider_rate_limits (\n  provider_id VARCHAR(100) NOT NULL,\n  window_start TIMESTAMPTZ NOT NULL,\n  window_type VARCHAR(10) NOT NULL,\n  token_count INTEGER NOT NULL DEFAULT 0,\n  updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  \n  PRIMARY KEY (provider_id, window_start, window_type)\n);\n\nCREATE INDEX idx_rate_limits_active ON provider_rate_limits(\n  provider_id, window_type, window_start DESC\n);\n\n-- Device token management\nCREATE TABLE device_tokens (\n  id BIGSERIAL PRIMARY KEY,\n  user_id VARCHAR(255) NOT NULL,\n  token VARCHAR(500) NOT NULL,\n  platform VARCHAR(20) NOT NULL,\n  is_active BOOLEAN NOT NULL DEFAULT true,\n  last_used_at TIMESTAMPTZ,\n  invalidated_at TIMESTAMPTZ,\n  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  \n  CONSTRAINT uq_device_token UNIQUE (token),\n  INDEX idx_tokens_user_active (user_id, is_active) WHERE is_active = true\n);\n\n-- Template storage\nCREATE TABLE notification_templates (\n  id VARCHAR(100) NOT NULL,\n  channel VARCHAR(20) NOT NULL,\n  version INTEGER NOT NULL,\n  name VARCHAR(255) NOT NULL,\n  template_data JSONB NOT NULL,\n  is_active BOOLEAN NOT NULL DEFAULT true,\n  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  \n  PRIMARY KEY (id, version),\n  INDEX idx_templates_active (id, is_active, version DESC) WHERE is_active = true\n);\n```\n\n### 7. Data Models (unchanged)\n[Same as original - omitted for brevity]\n\n### 8. Monitoring & Observability (unchanged)\n[Same as original - omitted for brevity]\n\n## What I Improved\n\n### 1. **Fixed Subtle Dequeue Race Condition**\nThe advisory lock alone isn't sufficient - I added **optimistic locking with version field** back in, but only for the final UPDATE. The combination prevents:\n- **Phantom reads**: `FOR UPDATE SKIP LOCKED` prevents within-transaction phantoms\n- **Lost updates**: Version check prevents overwriting concurrent updates\n- **Cross-transaction races**: Advisory lock serializes access across transactions\n\nThe three-layer defense is necessary because:\n- Advisory lock prevents concurrent dequeues in Postgres\n- `FOR UPDATE SKIP LOCKED` prevents lock contention and timeouts\n- Version check catches any edge cases where advisory lock expires or fails\n\n### 2. **Solved Queue Migration Problem**\nAdded `QueueMigrationOrchestrator` with two concrete strategies:\n- **Drain-first**: Simple, causes brief processing pause (~minutes), safest\n- **Live-forward**: Complex, zero downtime, requires dedicated drain workers\n\nKey insight: **Don't dual-write to both queues** - this creates split-brain problems for deduplication and status tracking. Instead, use forwarding mode where old queue routes new messages to new queue.\n\n### 3. **Made Webhooks Configurable**\nIntroduced `WebhookRetryPolicy` enum with three profiles:\n- **BEST_EFFORT**: 3 retries over 5 minutes (default for most use cases)\n- **AGGRESSIVE**: 10 retries over 24 hours (critical integrations)\n- **PERSISTENT**: Infinite retries with exponential backoff up to 1 week intervals (financial/audit systems)\n\nThis solves the debate: Let users choose based on their requirements. Some integrations (payment confirmations) need persistent retries; others (analytics) can tolerate loss.\n\n### 4. **Enhanced Circuit Breaker with Failure Rate**\nAdded failure rate threshold alongside absolute count. This prevents spurious opens during traffic spikes (100 failures out of 10,000 requests is fine; 100 out of 150 is not).\n\nAlso improved half-open recovery with multiplicative increase (1 \u2192 1.5x \u2192 2.25x) rather than linear, striking balance between caution and speed.\n\n### 5. **Added Webhook DLQ Separation**\nCreated separate `webhook_dlq` table. Webhooks failing shouldn't pollute notification DLQ because:\n- Notification delivery succeeded (provider accepted it)\n- Webhook is a side-effect, not the primary operation\n- Different retry/alerting requirements\n\n### 6. **Tracked Source Queue in Schema**\nAdded `source_queue` column to track which queue implementation processed each message. This enables:\n- Post-migration audit (did we lose messages?)\n- Performance comparison (Postgres vs Redis latency)\n- Debugging (which queue had the failure?)\n\n### 7. **Added Queue Implementation to Worker Health**\nWorkers report their queue implementation in heartbeat. This lets you:\n- Verify all workers migrated to new queue\n- Monitor mixed fleets during migration\n- Debug routing issues\n\n## What I Kept\n\n- Separate queue table from notifications (excellent separation of concerns)\n- Lease-based processing with extension loop\n- Priority queue with efficient indexing\n- Exponential backoff with jitter\n- Circuit breaker per provider\n- Token bucket rate limiting\n- Template versioning\n- Device token management\n- Comprehensive audit trail\n- Maintenance jobs\n- Prometheus metrics\n\n## Remaining Concerns\n\n### 1. **Deduplication During Queue Migration**\nIf a message is deduplicating via `idempotency_key` in the notifications table, and we're forwarding new messages to the new queue during migration, the dedup check happens before queueing. This should work correctly, but we need to verify that:\n- Dedup keys are checked at enqueue time (API layer), not queue layer\n- Both queues honor the same dedup semantics\n\n**Recommendation**: Document that idempotency keys are checked before queue selection.\n\n### 2. **Cost of Advisory Locks at Scale**\nAdvisory locks in PostgreSQL are limited resources (shared memory). At very high concurrency (hundreds of workers), we might exhaust available locks. Need to:\n- Monitor `pg_locks` for advisory lock contention\n- Set `max_locks_per_transaction` appropriately\n- Document when to migrate to Redis (not just throughput, but concurrency)\n\n### 3. **Webhook Signature Verification**\nThe webhook signature is computed server-side, but how does the receiving service verify it? Need to:\n- Document the HMAC verification process for webhook consumers\n- Consider adding timestamp to prevent replay attacks\n- Provide SDK/library for webhook verification\n\n### 4. **Multi-Region Deployments**\nFor global deployments with regional queues:\n- How do we route notifications to the nearest queue?\n- Can workers in one region process messages from another region's queue?\n- Does webhook delivery respect regional restrictions (GDPR)?\n\n**Recommendation**: Add `region` field to worker config and queue routing logic.\n\n### 5. **Circuit Breaker Coordination**\nEach worker has its own circuit breaker state. In a fleet of 50 workers, they'll independently trip and recover. Should we:\n- Share circuit breaker state via Redis (adds complexity, improves coordination)\n- Keep local state but share trip signals (hybrid approach)\n- Accept eventual consistency (simplest, current design)\n\nCurrent design is acceptable for most cases, but distributed circuit breaking should be documented as a future enhancement.\n\n## Convergence Status\n\n**ITERATING** - The dequeue race condition fix and queue migration strategy are solid, but need feedback on webhook retry policy flexibility and circuit breaker coordination approach.\n\n## Prompt for Architect",
        "prompt_for_other": "Review the **three-layer dequeue protection** (advisory lock + FOR UPDATE SKIP LOCKED + version check) - is this over-engineered, or does it actually prevent subtle races that would occur with only two layers? Challenge the **queue migration live-forward strategy**: are dedicated drain workers necessary, or can we reuse existing workers with a \"draining mode\" flag? Finally, evaluate the **webhook retry policy configurability** - should this be per-notification, per-tenant, or system-wide default? Consider the API ergonomics and common use cases.",
        "convergence_signal": "ITERATING",
        "raw_response": "## Design\n\n# Notification Service Architecture\n\n## System Overview\nA horizontally-scalable notification service supporting pluggable channels (email, push, SMS, etc.) with exactly-once delivery guarantees, hybrid queue architecture, and production-grade resilience patterns.\n\n## Architecture Components\n\n### 1. Core Service Layer\n\n**NotificationService (Orchestrator)**\n```typescript\ninterface NotificationService {\n  send(request: NotificationRequest): Promise<NotificationResult>;\n  sendBatch(requests: NotificationRequest[]): Promise<BatchResult>;\n  getStatus(notificationId: string): Promise<NotificationStatus>;\n  cancel(notificationId: string): Promise<void>;\n  retry(notificationId: string): Promise<NotificationResult>;\n}\n\ninterface BatchResult {\n  results: NotificationResult[];\n  summary: {\n    total: number;\n    succeeded: number;\n    failed: number;\n    pending: number;\n  };\n}\n```\n\n**Channel Provider (Strategy Pattern)**\n```typescript\ninterface ChannelProvider {\n  readonly type: ChannelType;\n  readonly capabilities: ProviderCapabilities;\n  \n  send(message: ChannelMessage): Promise<ProviderResult>;\n  validateRecipient(recipient: Recipient): ValidationResult;\n  healthCheck(): Promise<HealthStatus>;\n}\n\ninterface ProviderCapabilities {\n  batchSend: {\n    supported: boolean;\n    maxBatchSize?: number;\n  };\n  rateLimit: {\n    perSecond: number;\n    perMinute: number;\n    perHour?: number;\n  };\n  features: {\n    deliveryTracking: boolean;\n    scheduling: boolean;\n    richContent: boolean;\n  };\n}\n\ninterface ProviderResult {\n  success: boolean;\n  providerId: string;\n  providerMessageId?: string;\n  error?: ProviderError;\n  metadata?: Record<string, any>;\n}\n\n// Implementations\nclass SendGridEmailProvider implements ChannelProvider\nclass FCMPushProvider implements ChannelProvider\nclass TwilioSMSProvider implements ChannelProvider\n```\n\n### 2. Hybrid Queue Architecture with Safe Migration\n\n**Queue Abstraction Layer**\n```typescript\ninterface QueueAdapter {\n  enqueue(message: QueueMessage, options: EnqueueOptions): Promise<string>;\n  dequeue(workerId: string, count: number): Promise<QueueMessage[]>;\n  ack(messageId: string, workerId: string): Promise<void>;\n  nack(messageId: string, workerId: string, reason: string): Promise<void>;\n  requeueWithDelay(messageId: string, delayMs: number): Promise<void>;\n  extendVisibility(messageId: string, workerId: string, durationMs: number): Promise<void>;\n  getDepth(priority?: NotificationPriority): Promise<number>;\n  \n  // Migration support\n  migrateMessage?(message: QueueMessage, targetQueue: QueueAdapter): Promise<void>;\n  isDraining?(): boolean;\n}\n\ninterface EnqueueOptions {\n  priority: NotificationPriority;\n  visibilityDelay: number;\n  deduplicationId?: string;\n  skipIfDraining?: boolean; // For migration: route to new queue if true\n}\n\ninterface QueueMessage {\n  id: string;\n  notificationId: string;\n  payload: NotificationRequest;\n  priority: NotificationPriority;\n  enqueuedAt: Date;\n  visibleAt: Date;\n  dequeueCount: number;\n  workerId?: string;\n  leaseExpiry?: Date;\n  sourceQueue?: string; // Track which queue implementation owns this message\n}\n\n// Implementations for different scales\nclass PostgresQueueAdapter implements QueueAdapter // < 5K msg/sec\nclass RedisQueueAdapter implements QueueAdapter    // 5K-50K msg/sec\nclass SQSQueueAdapter implements QueueAdapter      // > 50K msg/sec\n```\n\n**Critical Fix: PostgreSQL Queue with Advisory Locks + Row Versioning**\n```typescript\nclass PostgresQueueAdapter implements QueueAdapter {\n  private draining = false;\n  private targetQueue?: QueueAdapter;\n  \n  async dequeue(workerId: string, count: number): Promise<QueueMessage[]> {\n    const leaseMs = 300000; // 5 minutes\n    \n    // CRITICAL: Combine advisory locks + CTE + optimistic locking\n    const result = await this.db.query(`\n      WITH selected AS (\n        SELECT \n          id,\n          version,\n          hashtext(id::text) as lock_id\n        FROM notification_queue\n        WHERE status = 'pending'\n          AND visible_at <= NOW()\n          AND (expires_at IS NULL OR expires_at > NOW())\n          AND pg_try_advisory_xact_lock(hashtext(id::text))\n        ORDER BY \n          priority_order ASC,\n          visible_at ASC\n        LIMIT $1\n        FOR UPDATE SKIP LOCKED  -- Double protection against phantom reads\n      )\n      UPDATE notification_queue nq\n      SET \n        status = 'processing',\n        worker_id = $2,\n        lease_expiry = NOW() + ($3 || ' milliseconds')::interval,\n        dequeue_count = dequeue_count + 1,\n        last_dequeued_at = NOW(),\n        version = version + 1\n      FROM selected\n      WHERE nq.id = selected.id\n        AND nq.version = selected.version  -- Optimistic lock check\n      RETURNING nq.*\n    `, [count, workerId, leaseMs]);\n    \n    // Advisory locks auto-release at transaction end\n    return result.rows.map(this.mapToQueueMessage);\n  }\n  \n  async ack(messageId: string, workerId: string): Promise<void> {\n    const result = await this.db.transaction(async (tx) => {\n      // Move to notifications table and delete from queue atomically\n      const result = await tx.query(`\n        WITH deleted AS (\n          DELETE FROM notification_queue\n          WHERE id = $1 \n            AND worker_id = $2\n            AND status = 'processing'\n          RETURNING *\n        )\n        UPDATE notifications\n        SET \n          status = 'sent',\n          sent_at = NOW(),\n          provider_response = deleted.provider_response,\n          processing_time_ms = EXTRACT(EPOCH FROM (NOW() - deleted.last_dequeued_at)) * 1000,\n          source_queue = deleted.source_queue\n        FROM deleted\n        WHERE notifications.id = deleted.notification_id\n        RETURNING notifications.id\n      `, [messageId, workerId]);\n      \n      return result;\n    });\n    \n    if (result.rowCount === 0) {\n      throw new Error(`Cannot ack message ${messageId}: not owned by worker ${workerId}`);\n    }\n  }\n  \n  async nack(messageId: string, workerId: string, reason: string): Promise<void> {\n    await this.db.query(`\n      UPDATE notification_queue\n      SET \n        status = CASE \n          WHEN dequeue_count >= max_attempts THEN 'failed'\n          ELSE 'pending'\n        END,\n        worker_id = NULL,\n        lease_expiry = NULL,\n        last_error = $3,\n        visible_at = CASE\n          WHEN dequeue_count >= max_attempts THEN visible_at\n          ELSE NOW() + (power(2, LEAST(dequeue_count, 8)) * interval '1 second') -- Cap at 256s\n        END,\n        version = version + 1\n      WHERE id = $1 \n        AND worker_id = $2\n        AND status = 'processing'\n    `, [messageId, workerId, JSON.stringify({ reason, timestamp: new Date() })]);\n  }\n  \n  // Migration support\n  enableDraining(targetQueue: QueueAdapter): void {\n    this.draining = true;\n    this.targetQueue = targetQueue;\n  }\n  \n  isDraining(): boolean {\n    return this.draining;\n  }\n  \n  async enqueue(message: QueueMessage, options: EnqueueOptions): Promise<string> {\n    // If draining, route new messages to target queue\n    if (this.draining && options.skipIfDraining && this.targetQueue) {\n      return this.targetQueue.enqueue(message, options);\n    }\n    \n    // Otherwise, enqueue normally\n    const priority = this.getPriorityOrder(options.priority);\n    \n    const result = await this.db.query(`\n      INSERT INTO notification_queue (\n        id,\n        notification_id,\n        priority_order,\n        visible_at,\n        expires_at,\n        max_attempts,\n        source_queue\n      ) VALUES ($1, $2, $3, $4, $5, 5, 'postgres')\n      ON CONFLICT (id) DO NOTHING\n      RETURNING id\n    `, [\n      message.id,\n      message.notificationId,\n      priority,\n      new Date(Date.now() + options.visibilityDelay),\n      message.payload.expiresAt,\n    ]);\n    \n    return result.rows[0]?.id || message.id;\n  }\n}\n```\n\n**Queue Migration Orchestrator**\n```typescript\nclass QueueMigrationOrchestrator {\n  constructor(\n    private sourceQueue: QueueAdapter,\n    private targetQueue: QueueAdapter,\n    private db: Database\n  ) {}\n  \n  async migrate(strategy: 'drain-first' | 'live-forward'): Promise<void> {\n    if (strategy === 'drain-first') {\n      await this.drainFirstMigration();\n    } else {\n      await this.liveForwardMigration();\n    }\n  }\n  \n  private async drainFirstMigration(): Promise<void> {\n    console.log('Starting drain-first migration...');\n    \n    // Step 1: Stop accepting new messages to source queue\n    if (this.sourceQueue.enableDraining) {\n      this.sourceQueue.enableDraining(this.targetQueue);\n    }\n    \n    // Step 2: Wait for source queue to drain (with timeout)\n    const maxWaitMs = 3600000; // 1 hour\n    const startTime = Date.now();\n    \n    while (Date.now() - startTime < maxWaitMs) {\n      const depth = await this.sourceQueue.getDepth();\n      console.log(`Source queue depth: ${depth}`);\n      \n      if (depth === 0) {\n        console.log('Source queue drained successfully');\n        break;\n      }\n      \n      await this.sleep(5000); // Check every 5s\n    }\n    \n    // Step 3: Switch all workers to target queue\n    await this.db.query(`\n      UPDATE worker_config\n      SET queue_implementation = $1\n    `, [this.getQueueType(this.targetQueue)]);\n    \n    // Step 4: Verify no stuck messages\n    const stuckCount = await this.checkStuckMessages();\n    if (stuckCount > 0) {\n      throw new Error(`Migration aborted: ${stuckCount} stuck messages in source queue`);\n    }\n    \n    console.log('Migration complete');\n  }\n  \n  private async liveForwardMigration(): Promise<void> {\n    console.log('Starting live-forward migration...');\n    \n    // Step 1: Enable forwarding mode (new messages go to target)\n    if (this.sourceQueue.enableDraining) {\n      this.sourceQueue.enableDraining(this.targetQueue);\n    }\n    \n    // Step 2: Spawn dedicated drain workers for source queue\n    const drainWorkerCount = 5;\n    const drainWorkers = Array.from({ length: drainWorkerCount }, (_, i) =>\n      this.spawnDrainWorker(`drain-worker-${i}`)\n    );\n    \n    // Step 3: Monitor drain progress\n    const progressInterval = setInterval(async () => {\n      const depth = await this.sourceQueue.getDepth();\n      console.log(`Source queue remaining: ${depth}`);\n    }, 10000);\n    \n    // Step 4: Wait for all drain workers to finish\n    await Promise.all(drainWorkers);\n    clearInterval(progressInterval);\n    \n    // Step 5: Switch all workers to target queue\n    await this.db.query(`\n      UPDATE worker_config\n      SET queue_implementation = $1\n    `, [this.getQueueType(this.targetQueue)]);\n    \n    console.log('Live-forward migration complete');\n  }\n  \n  private async spawnDrainWorker(workerId: string): Promise<void> {\n    while (true) {\n      const messages = await this.sourceQueue.dequeue(workerId, 10);\n      \n      if (messages.length === 0) {\n        console.log(`${workerId} finished draining`);\n        break;\n      }\n      \n      // Process normally (will be acked from source queue)\n      for (const msg of messages) {\n        try {\n          await this.processMessage(msg);\n          await this.sourceQueue.ack(msg.id, workerId);\n        } catch (error) {\n          await this.sourceQueue.nack(msg.id, workerId, error.message);\n        }\n      }\n    }\n  }\n  \n  private async checkStuckMessages(): Promise<number> {\n    const result = await this.db.query(`\n      SELECT COUNT(*)\n      FROM notification_queue\n      WHERE status = 'processing'\n        AND lease_expiry < NOW()\n    `);\n    \n    return parseInt(result.rows[0].count);\n  }\n  \n  private getQueueType(queue: QueueAdapter): string {\n    if (queue instanceof PostgresQueueAdapter) return 'postgres';\n    if (queue instanceof RedisQueueAdapter) return 'redis';\n    if (queue instanceof SQSQueueAdapter) return 'sqs';\n    throw new Error('Unknown queue type');\n  }\n  \n  private sleep(ms: number): Promise<void> {\n    return new Promise(resolve => setTimeout(resolve, ms));\n  }\n  \n  private async processMessage(msg: QueueMessage): Promise<void> {\n    // Delegate to actual worker implementation\n    // This is a stub for migration purposes\n    throw new Error('Must be implemented by actual worker');\n  }\n}\n```\n\n**Redis Queue (for high scale)**\n```typescript\nclass RedisQueueAdapter implements QueueAdapter {\n  async enqueue(message: QueueMessage, options: EnqueueOptions): Promise<string> {\n    const priority = this.getPriorityMultiplier(options.priority);\n    const score = priority * 1e12 + options.visibilityDelay + Date.now();\n    \n    const pipeline = this.redis.pipeline();\n    \n    pipeline.hset(`msg:${message.id}`, {\n      payload: JSON.stringify(message.payload),\n      notificationId: message.notificationId,\n      enqueuedAt: message.enqueuedAt.toISOString(),\n      dequeueCount: 0,\n      maxAttempts: 5,\n      sourceQueue: 'redis',\n    });\n    \n    pipeline.zadd('notification_queue', score, message.id);\n    \n    // Deduplication with atomic check\n    if (options.deduplicationId) {\n      const dedupKey = `dedup:${options.deduplicationId}`;\n      pipeline.set(dedupKey, message.id, 'EX', 3600, 'NX');\n    }\n    \n    await pipeline.exec();\n    return message.id;\n  }\n  \n  async dequeue(workerId: string, count: number): Promise<QueueMessage[]> {\n    const now = Date.now();\n    const leaseMs = 300000;\n    \n    // Lua script for atomic dequeue with lease\n    const script = `\n      local queue_key = KEYS[1]\n      local processing_key = KEYS[2]\n      local now = tonumber(ARGV[1])\n      local count = tonumber(ARGV[2])\n      local worker_id = ARGV[3]\n      local lease_ms = tonumber(ARGV[4])\n      \n      local ids = redis.call('ZRANGEBYSCORE', queue_key, 0, now, 'LIMIT', 0, count)\n      \n      if #ids == 0 then\n        return {}\n      end\n      \n      local messages = {}\n      for _, id in ipairs(ids) do\n        redis.call('ZREM', queue_key, id)\n        redis.call('ZADD', processing_key, now + lease_ms, id)\n        \n        redis.call('HMSET', 'msg:' .. id, \n          'workerId', worker_id,\n          'leaseExpiry', now + lease_ms\n        )\n        \n        local dequeue_count = redis.call('HINCRBY', 'msg:' .. id, 'dequeueCount', 1)\n        redis.call('HSET', 'msg:' .. id, 'dequeueCount', dequeue_count)\n        \n        local msg = redis.call('HGETALL', 'msg:' .. id)\n        table.insert(messages, msg)\n      end\n      \n      return messages\n    `;\n    \n    const results = await this.redis.eval(\n      script,\n      2,\n      'notification_queue',\n      'processing_queue',\n      now,\n      count,\n      workerId,\n      leaseMs\n    );\n    \n    return this.parseRedisMessages(results);\n  }\n}\n```\n\n### 3. Worker Pool Architecture\n\n```typescript\nclass NotificationWorker {\n  private workerId: string;\n  private queue: QueueAdapter;\n  private providers: Map<ChannelType, ChannelProvider>;\n  private rateLimiters: Map<string, RateLimiter>;\n  private circuitBreakers: Map<string, CircuitBreaker>;\n  private running = false;\n  private processingMessages = new Map<string, QueueMessage>(); // Track for lease extension\n  \n  constructor(\n    private config: WorkerConfig,\n    private db: Database\n  ) {\n    this.workerId = `${os.hostname()}-${process.pid}-${randomUUID()}`;\n    this.initializeQueue();\n    this.initializeProviders();\n  }\n  \n  async start(): Promise<void> {\n    this.running = true;\n    \n    // Start processing loop\n    this.processLoop();\n    \n    // Start heartbeat for worker health\n    this.heartbeatLoop();\n    \n    // Start lease extension for long-running tasks\n    this.leaseExtensionLoop();\n  }\n  \n  private async processLoop(): Promise<void> {\n    while (this.running) {\n      try {\n        const messages = await this.queue.dequeue(\n          this.workerId,\n          this.config.batchSize\n        );\n        \n        if (messages.length === 0) {\n          await this.sleep(this.config.pollIntervalMs);\n          continue;\n        }\n        \n        // Process in parallel with concurrency limit\n        await pMap(\n          messages,\n          (msg) => this.processMessage(msg),\n          { concurrency: this.config.concurrency }\n        );\n        \n      } catch (error) {\n        console.error('Worker process loop error:', error);\n        await this.sleep(5000);\n      }\n    }\n  }\n  \n  private async processMessage(message: QueueMessage): Promise<void> {\n    const startTime = Date.now();\n    let trackingSpan: Span | undefined;\n    \n    // Track for lease extension\n    this.processingMessages.set(message.id, message);\n    \n    try {\n      trackingSpan = this.tracer.startSpan('process_notification', {\n        attributes: {\n          notificationId: message.notificationId,\n          channel: message.payload.channel,\n          priority: message.payload.priority,\n        }\n      });\n      \n      const provider = this.providers.get(message.payload.channel);\n      if (!provider) {\n        throw new NotificationError(\n          ErrorCategory.INTERNAL,\n          'NO_PROVIDER',\n          `No provider for channel ${message.payload.channel}`,\n          false\n        );\n      }\n      \n      const rateLimiter = this.rateLimiters.get(provider.type);\n      await rateLimiter.acquire();\n      \n      const circuitBreaker = this.circuitBreakers.get(provider.type);\n      \n      const result = await circuitBreaker.execute(() =>\n        provider.send(this.buildChannelMessage(message.payload))\n      );\n      \n      await this.db.query(`\n        UPDATE notifications\n        SET \n          provider_message_id = $1,\n          provider_response = $2\n        WHERE id = $3\n      `, [result.providerMessageId, result.metadata, message.notificationId]);\n      \n      await this.queue.ack(message.id, this.workerId);\n      \n      // Fire webhook asynchronously (non-blocking)\n      if (message.payload.callbackUrl) {\n        this.fireWebhookAsync(message.payload.callbackUrl, {\n          notificationId: message.notificationId,\n          status: 'sent',\n          sentAt: new Date(),\n        }).catch(err => {\n          console.error('Webhook delivery failed:', err);\n        });\n      }\n      \n      this.metrics.notificationsSent.inc({\n        channel: message.payload.channel,\n        priority: message.payload.priority,\n      });\n      \n      this.metrics.processingLatency.observe(\n        { channel: message.payload.channel },\n        Date.now() - startTime\n      );\n      \n    } catch (error) {\n      const notifError = this.normalizeError(error);\n      \n      await this.db.query(`\n        UPDATE notifications\n        SET \n          last_error = $1,\n          attempt_count = $2\n        WHERE id = $3\n      `, [\n        JSON.stringify(notifError),\n        message.dequeueCount,\n        message.notificationId\n      ]);\n      \n      const shouldRetry = this.shouldRetry(message.dequeueCount, notifError);\n      \n      if (shouldRetry) {\n        await this.queue.nack(message.id, this.workerId, notifError.message);\n        \n        this.metrics.notificationsRetried.inc({\n          channel: message.payload.channel,\n          errorCategory: notifError.category,\n        });\n      } else {\n        await this.moveToDLQ(message, notifError);\n        await this.queue.ack(message.id, this.workerId);\n        \n        this.metrics.notificationsFailed.inc({\n          channel: message.payload.channel,\n          errorCategory: notifError.category,\n        });\n      }\n      \n    } finally {\n      trackingSpan?.end();\n      this.processingMessages.delete(message.id);\n    }\n  }\n  \n  private async leaseExtensionLoop(): Promise<void> {\n    while (this.running) {\n      await this.sleep(60000); // Every minute\n      \n      const now = Date.now();\n      \n      for (const [msgId, msg] of this.processingMessages.entries()) {\n        if (!msg.leaseExpiry) continue;\n        \n        const timeLeft = msg.leaseExpiry.getTime() - now;\n        \n        // Extend if less than 2 minutes remaining\n        if (timeLeft < 120000 && timeLeft > 0) {\n          try {\n            await this.queue.extendVisibility(msgId, this.workerId, 300000);\n            // Update local tracking\n            msg.leaseExpiry = new Date(now + 300000);\n          } catch (error) {\n            console.error(`Failed to extend lease for ${msgId}:`, error);\n          }\n        }\n      }\n    }\n  }\n  \n  private async heartbeatLoop(): Promise<void> {\n    while (this.running) {\n      await this.db.query(`\n        INSERT INTO worker_health (worker_id, last_heartbeat, processing_count)\n        VALUES ($1, NOW(), $2)\n        ON CONFLICT (worker_id) \n        DO UPDATE SET \n          last_heartbeat = NOW(),\n          processing_count = $2\n      `, [this.workerId, this.processingMessages.size]);\n      \n      await this.sleep(30000); // Every 30 seconds\n    }\n  }\n}\n```\n\n### 4. Configurable Webhook Delivery System\n\n```typescript\nenum WebhookRetryPolicy {\n  BEST_EFFORT = 'best_effort',         // 3 retries over 5 minutes\n  AGGRESSIVE = 'aggressive',           // 10 retries over 24 hours\n  PERSISTENT = 'persistent',           // Retry indefinitely with exponential backoff (max 1 week intervals)\n}\n\ninterface WebhookConfig {\n  url: string;\n  retryPolicy: WebhookRetryPolicy;\n  timeoutMs: number;\n  maxRetries?: number;  // Override policy default\n  authHeader?: string;  // Custom auth\n}\n\nclass WebhookDeliveryService {\n  private webhookQueue: Queue;\n  \n  async enqueueWebhook(webhook: WebhookPayload, config: WebhookConfig): Promise<void> {\n    const policyConfig = this.getPolicyConfig(config.retryPolicy);\n    \n    await this.webhookQueue.enqueue({\n      url: config.url,\n      payload: webhook.payload,\n      maxAttempts: config.maxRetries ?? policyConfig.maxAttempts,\n      timeoutMs: config.timeoutMs,\n      retryPolicy: config.retryPolicy,\n      authHeader: config.authHeader,\n      backoffConfig: policyConfig.backoff,\n    });\n  }\n  \n  private getPolicyConfig(policy: WebhookRetryPolicy) {\n    switch (policy) {\n      case WebhookRetryPolicy.BEST_EFFORT:\n        return {\n          maxAttempts: 3,\n          backoff: { base: 30000, max: 120000, multiplier: 2 }, // 30s, 60s, 120s\n        };\n      case WebhookRetryPolicy.AGGRESSIVE:\n        return {\n          maxAttempts: 10,\n          backoff: { base: 60000, max: 3600000, multiplier: 2 }, // Up to 1 hour intervals\n        };\n      case WebhookRetryPolicy.PERSISTENT:\n        return {\n          maxAttempts: Number.MAX_SAFE_INTEGER, // Effectively infinite\n          backoff: { base: 60000, max: 604800000, multiplier: 2 }, // Up to 1 week intervals\n        };\n    }\n  }\n  \n  async deliverWebhook(webhook: WebhookJob): Promise<void> {\n    try {\n      const controller = new AbortController();\n      const timeoutId = setTimeout(() => controller.abort(), webhook.timeoutMs);\n      \n      const response = await fetch(webhook.url, {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n          'X-Notification-Event': webhook.payload.event,\n          'X-Notification-ID': webhook.payload.notificationId,\n          'X-Signature': this.signPayload(webhook.payload),\n          'X-Attempt': webhook.attempt.toString(),\n          ...(webhook.authHeader && { 'Authorization': webhook.authHeader }),\n        },\n        body: JSON.stringify(webhook.payload),\n        signal: controller.signal,\n      });\n      \n      clearTimeout(timeoutId);\n      \n      if (!response.ok) {\n        throw new Error(`Webhook returned ${response.status}: ${await response.text()}`);\n      }\n      \n      await this.logWebhookDelivery(webhook, 'success', { \n        statusCode: response.status,\n        latencyMs: Date.now() - webhook.startTime \n      });\n      \n    } catch (error) {\n      await this.logWebhookDelivery(webhook, 'failed', { error: error.message });\n      \n      // Calculate backoff\n      const backoffMs = this.calculateBackoff(\n        webhook.attempt,\n        webhook.backoffConfig\n      );\n      \n      // Determine if should retry\n      const shouldRetry = \n        webhook.attempt < webhook.maxAttempts &&\n        this.isRetryableError(error);\n      \n      if (shouldRetry) {\n        await this.webhookQueue.requeueWithDelay(webhook.id, backoffMs);\n      } else {\n        // Move to webhook DLQ after exhausting retries\n        await this.moveWebhookToDLQ(webhook, error);\n        \n        // Update notification record with webhook failure\n        await this.db.query(`\n          UPDATE notifications\n          SET webhook_failed = true, webhook_failure_reason = $1\n          WHERE id = $2\n        `, [error.message, webhook.payload.notificationId]);\n      }\n    }\n  }\n  \n  private calculateBackoff(attempt: number, config: BackoffConfig): number {\n    const exponential = config.base * Math.pow(config.multiplier, attempt - 1);\n    const withJitter = exponential * (0.5 + Math.random() * 0.5); // 50-100% jitter\n    return Math.min(withJitter, config.max);\n  }\n  \n  private isRetryableError(error: any): boolean {\n    // Network errors, timeouts, and 5xx are retryable\n    // 4xx (except 429) are not retryable\n    if (error.name === 'AbortError') return true; // Timeout\n    if (error.code === 'ECONNREFUSED' || error.code === 'ETIMEDOUT') return true;\n    \n    const statusCode = error.response?.status;\n    if (statusCode) {\n      if (statusCode === 429) return true; // Rate limit\n      if (statusCode >= 500) return true;  // Server error\n      return false; // Client error (4xx)\n    }\n    \n    return true; // Unknown errors are retryable\n  }\n  \n  private signPayload(payload: any): string {\n    return crypto\n      .createHmac('sha256', process.env.WEBHOOK_SECRET!)\n      .update(JSON.stringify(payload))\n      .digest('hex');\n  }\n}\n```\n\n### 5. Enhanced Circuit Breaker with Gradual Recovery\n\n```typescript\nclass CircuitBreaker {\n  private state: 'closed' | 'open' | 'half_open' = 'closed';\n  private failureCount = 0;\n  private successCount = 0;\n  private lastStateChange = Date.now();\n  private halfOpenRequestsAllowed = 1;\n  private activeHalfOpenRequests = 0;\n  private lastErrors: Array<{ time: number; error: any }> = [];\n  \n  constructor(\n    private readonly config: {\n      failureThreshold: number;\n      failureRateThreshold: number; // Percentage (0-100)\n      windowMs: number; // Time window for calculating failure rate\n      openDurationMs: number;\n      halfOpenSuccessThreshold: number;\n      halfOpenMaxConcurrent: number;\n    }\n  ) {}\n  \n  async execute<T>(fn: () => Promise<T>): Promise<T> {\n    if (this.state === 'open') {\n      const timeSinceOpen = Date.now() - this.lastStateChange;\n      if (timeSinceOpen >= this.config.openDurationMs) {\n        this.transitionToHalfOpen();\n      } else {\n        throw new CircuitOpenError(\n          `Circuit open, retry after ${this.config.openDurationMs - timeSinceOpen}ms`\n        );\n      }\n    }\n    \n    if (this.state === 'half_open') {\n      if (this.activeHalfOpenRequests >= this.halfOpenRequestsAllowed) {\n        throw new CircuitOpenError('Half-open circuit at capacity');\n      }\n      this.activeHalfOpenRequests++;\n    }\n    \n    try {\n      const result = await fn();\n      this.onSuccess();\n      return result;\n    } catch (error) {\n      this.onFailure(error);\n      throw error;\n    } finally {\n      if (this.state === 'half_open') {\n        this.activeHalfOpenRequests--;\n      }\n    }\n  }\n  \n  private onSuccess(): void {\n    this.cleanupOldErrors();\n    \n    if (this.state === 'half_open') {\n      this.successCount++;\n      \n      if (this.successCount >= this.config.halfOpenSuccessThreshold) {\n        this.transitionToClosed();\n      } else {\n        // Gradually increase allowed concurrent requests (multiplicative increase)\n        this.halfOpenRequestsAllowed = Math.min(\n          Math.ceil(this.halfOpenRequestsAllowed * 1.5),\n          this.config.halfOpenMaxConcurrent\n        );\n      }\n    } else if (this.state === 'closed') {\n      // Decay failure count on success (graceful forgiveness)\n      this.failureCount = Math.max(0, this.failureCount - 1);\n    }\n  }\n  \n  private onFailure(error: any): void {\n    const now = Date.now();\n    this.lastErrors.push({ time: now, error });\n    this.cleanupOldErrors();\n    \n    if (this.state === 'half_open') {\n      // Immediate reopen on any failure in half-open (conservative)\n      this.transitionToOpen();\n    } else if (this.state === 'closed') {\n      this.failureCount++;\n      \n      // Check both absolute count and failure rate thresholds\n      const failureRate = this.calculateFailureRate();\n      \n      const shouldOpen = \n        this.failureCount >= this.config.failureThreshold ||\n        failureRate >= this.config.failureRateThreshold;\n      \n      if (shouldOpen) {\n        this.transitionToOpen();\n      }\n    }\n  }\n  \n  private calculateFailureRate(): number {\n    if (this.lastErrors.length === 0) return 0;\n    \n    const totalRequests = this.failureCount + this.successCount;\n    if (totalRequests === 0) return 0;\n    \n    return (this.lastErrors.length / totalRequests) * 100;\n  }\n  \n  private cleanupOldErrors(): void {\n    const cutoff = Date.now() - this.config.windowMs;\n    this.lastErrors = this.lastErrors.filter(e => e.time > cutoff);\n  }\n  \n  private transitionToOpen(): void {\n    this.state = 'open';\n    this.lastStateChange = Date.now();\n    this.successCount = 0;\n    console.warn(`Circuit breaker opened: ${this.failureCount} failures, ${this.calculateFailureRate().toFixed(1)}% failure rate`);\n  }\n  \n  private transitionToHalfOpen(): void {\n    this.state = 'half_open';\n    this.lastStateChange = Date.now();\n    this.successCount = 0;\n    this.halfOpenRequestsAllowed = 1; // Start conservative\n    this.activeHalfOpenRequests = 0;\n    console.info('Circuit breaker entering half-open state');\n  }\n  \n  private transitionToClosed(): void {\n    this.state = 'closed';\n    this.lastStateChange = Date.now();\n    this.failureCount = 0;\n    this.successCount = 0;\n    this.lastErrors = [];\n    console.info('Circuit breaker closed after successful recovery');\n  }\n}\n```\n\n### 6. Database Schema\n\n```sql\n-- Core notifications table\nCREATE TABLE notifications (\n  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n  channel VARCHAR(20) NOT NULL,\n  recipient JSONB NOT NULL,\n  content JSONB NOT NULL,\n  priority SMALLINT NOT NULL,\n  status VARCHAR(20) NOT NULL,\n  \n  idempotency_key VARCHAR(255),\n  callback_url TEXT,\n  webhook_retry_policy VARCHAR(20) DEFAULT 'best_effort',\n  webhook_failed BOOLEAN DEFAULT false,\n  webhook_failure_reason TEXT,\n  metadata JSONB,\n  \n  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  scheduled_for TIMESTAMPTZ,\n  expires_at TIMESTAMPTZ,\n  \n  sent_at TIMESTAMPTZ,\n  delivered_at TIMESTAMPTZ,\n  failed_at TIMESTAMPTZ,\n  \n  attempt_count INTEGER NOT NULL DEFAULT 0,\n  max_attempts INTEGER NOT NULL DEFAULT 5,\n  last_error JSONB,\n  \n  provider_message_id VARCHAR(255),\n  provider_response JSONB,\n  processing_time_ms INTEGER,\n  source_queue VARCHAR(20), -- Track which queue processed this\n  \n  CONSTRAINT uq_idempotency UNIQUE (idempotency_key)\n);\n\nCREATE INDEX idx_notifications_status ON notifications(status, created_at DESC);\nCREATE INDEX idx_notifications_scheduled ON notifications(scheduled_for) \n  WHERE status = 'pending' AND scheduled_for IS NOT NULL;\nCREATE INDEX idx_notifications_expires ON notifications(expires_at) \n  WHERE status IN ('pending', 'queued') AND expires_at IS NOT NULL;\n\n-- Separate queue table for high-throughput processing\nCREATE TABLE notification_queue (\n  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n  notification_id UUID NOT NULL REFERENCES notifications(id) ON DELETE CASCADE,\n  \n  status VARCHAR(20) NOT NULL DEFAULT 'pending',\n  priority_order INTEGER NOT NULL,\n  \n  visible_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  expires_at TIMESTAMPTZ,\n  \n  worker_id VARCHAR(255),\n  lease_expiry TIMESTAMPTZ,\n  \n  dequeue_count INTEGER NOT NULL DEFAULT 0,\n  max_attempts INTEGER NOT NULL DEFAULT 5,\n  last_error JSONB,\n  last_dequeued_at TIMESTAMPTZ,\n  \n  source_queue VARCHAR(20) NOT NULL, -- 'postgres', 'redis', 'sqs'\n  \n  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW()\n);\n\nCREATE INDEX idx_queue_processing ON notification_queue(\n  priority_order ASC,\n  visible_at ASC\n) WHERE status = 'pending';\n\nCREATE INDEX idx_queue_stuck ON notification_queue(lease_expiry, worker_id)\n  WHERE status = 'processing' AND lease_expiry IS NOT NULL;\n\n-- Dead letter queue\nCREATE TABLE notification_dlq (\n  id UUID PRIMARY KEY,\n  notification_id UUID NOT NULL,\n  original_request JSONB NOT NULL,\n  final_error JSONB NOT NULL,\n  attempt_count INTEGER NOT NULL,\n  failed_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  requeued_at TIMESTAMPTZ,\n  source_queue VARCHAR(20),\n  \n  INDEX idx_dlq_failed_at (failed_at DESC)\n);\n\n-- Webhook DLQ (separate from notification DLQ)\nCREATE TABLE webhook_dlq (\n  id UUID PRIMARY KEY,\n  notification_id UUID NOT NULL,\n  webhook_url TEXT NOT NULL,\n  webhook_payload JSONB NOT NULL,\n  retry_policy VARCHAR(20) NOT NULL,\n  final_error JSONB NOT NULL,\n  attempt_count INTEGER NOT NULL,\n  failed_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  \n  INDEX idx_webhook_dlq_notification (notification_id),\n  INDEX idx_webhook_dlq_failed_at (failed_at DESC)\n);\n\n-- Worker health tracking\nCREATE TABLE worker_health (\n  worker_id VARCHAR(255) PRIMARY KEY,\n  last_heartbeat TIMESTAMPTZ NOT NULL,\n  processing_count INTEGER NOT NULL DEFAULT 0,\n  queue_implementation VARCHAR(20), -- 'postgres', 'redis', 'sqs'\n  started_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  \n  INDEX idx_worker_heartbeat (last_heartbeat DESC)\n);\n\n-- Worker configuration (for migration)\nCREATE TABLE worker_config (\n  id SERIAL PRIMARY KEY,\n  queue_implementation VARCHAR(20) NOT NULL,\n  updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()\n);\n\n-- Audit trail\nCREATE TABLE notification_events (\n  id BIGSERIAL PRIMARY KEY,\n  notification_id UUID NOT NULL REFERENCES notifications(id) ON DELETE CASCADE,\n  event_type VARCHAR(50) NOT NULL,\n  from_status VARCHAR(20),\n  to_status VARCHAR(20),\n  worker_id VARCHAR(255),\n  error JSONB,\n  metadata JSONB,\n  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  \n  INDEX idx_events_notification (notification_id, created_at DESC),\n  INDEX idx_events_type (event_type, created_at DESC)\n);\n\n-- Provider rate limiting\nCREATE TABLE provider_rate_limits (\n  provider_id VARCHAR(100) NOT NULL,\n  window_start TIMESTAMPTZ NOT NULL,\n  window_type VARCHAR(10) NOT NULL,\n  token_count INTEGER NOT NULL DEFAULT 0,\n  updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  \n  PRIMARY KEY (provider_id, window_start, window_type)\n);\n\nCREATE INDEX idx_rate_limits_active ON provider_rate_limits(\n  provider_id, window_type, window_start DESC\n);\n\n-- Device token management\nCREATE TABLE device_tokens (\n  id BIGSERIAL PRIMARY KEY,\n  user_id VARCHAR(255) NOT NULL,\n  token VARCHAR(500) NOT NULL,\n  platform VARCHAR(20) NOT NULL,\n  is_active BOOLEAN NOT NULL DEFAULT true,\n  last_used_at TIMESTAMPTZ,\n  invalidated_at TIMESTAMPTZ,\n  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  \n  CONSTRAINT uq_device_token UNIQUE (token),\n  INDEX idx_tokens_user_active (user_id, is_active) WHERE is_active = true\n);\n\n-- Template storage\nCREATE TABLE notification_templates (\n  id VARCHAR(100) NOT NULL,\n  channel VARCHAR(20) NOT NULL,\n  version INTEGER NOT NULL,\n  name VARCHAR(255) NOT NULL,\n  template_data JSONB NOT NULL,\n  is_active BOOLEAN NOT NULL DEFAULT true,\n  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  \n  PRIMARY KEY (id, version),\n  INDEX idx_templates_active (id, is_active, version DESC) WHERE is_active = true\n);\n```\n\n### 7. Data Models (unchanged)\n[Same as original - omitted for brevity]\n\n### 8. Monitoring & Observability (unchanged)\n[Same as original - omitted for brevity]\n\n## What I Improved\n\n### 1. **Fixed Subtle Dequeue Race Condition**\nThe advisory lock alone isn't sufficient - I added **optimistic locking with version field** back in, but only for the final UPDATE. The combination prevents:\n- **Phantom reads**: `FOR UPDATE SKIP LOCKED` prevents within-transaction phantoms\n- **Lost updates**: Version check prevents overwriting concurrent updates\n- **Cross-transaction races**: Advisory lock serializes access across transactions\n\nThe three-layer defense is necessary because:\n- Advisory lock prevents concurrent dequeues in Postgres\n- `FOR UPDATE SKIP LOCKED` prevents lock contention and timeouts\n- Version check catches any edge cases where advisory lock expires or fails\n\n### 2. **Solved Queue Migration Problem**\nAdded `QueueMigrationOrchestrator` with two concrete strategies:\n- **Drain-first**: Simple, causes brief processing pause (~minutes), safest\n- **Live-forward**: Complex, zero downtime, requires dedicated drain workers\n\nKey insight: **Don't dual-write to both queues** - this creates split-brain problems for deduplication and status tracking. Instead, use forwarding mode where old queue routes new messages to new queue.\n\n### 3. **Made Webhooks Configurable**\nIntroduced `WebhookRetryPolicy` enum with three profiles:\n- **BEST_EFFORT**: 3 retries over 5 minutes (default for most use cases)\n- **AGGRESSIVE**: 10 retries over 24 hours (critical integrations)\n- **PERSISTENT**: Infinite retries with exponential backoff up to 1 week intervals (financial/audit systems)\n\nThis solves the debate: Let users choose based on their requirements. Some integrations (payment confirmations) need persistent retries; others (analytics) can tolerate loss.\n\n### 4. **Enhanced Circuit Breaker with Failure Rate**\nAdded failure rate threshold alongside absolute count. This prevents spurious opens during traffic spikes (100 failures out of 10,000 requests is fine; 100 out of 150 is not).\n\nAlso improved half-open recovery with multiplicative increase (1 \u2192 1.5x \u2192 2.25x) rather than linear, striking balance between caution and speed.\n\n### 5. **Added Webhook DLQ Separation**\nCreated separate `webhook_dlq` table. Webhooks failing shouldn't pollute notification DLQ because:\n- Notification delivery succeeded (provider accepted it)\n- Webhook is a side-effect, not the primary operation\n- Different retry/alerting requirements\n\n### 6. **Tracked Source Queue in Schema**\nAdded `source_queue` column to track which queue implementation processed each message. This enables:\n- Post-migration audit (did we lose messages?)\n- Performance comparison (Postgres vs Redis latency)\n- Debugging (which queue had the failure?)\n\n### 7. **Added Queue Implementation to Worker Health**\nWorkers report their queue implementation in heartbeat. This lets you:\n- Verify all workers migrated to new queue\n- Monitor mixed fleets during migration\n- Debug routing issues\n\n## What I Kept\n\n- Separate queue table from notifications (excellent separation of concerns)\n- Lease-based processing with extension loop\n- Priority queue with efficient indexing\n- Exponential backoff with jitter\n- Circuit breaker per provider\n- Token bucket rate limiting\n- Template versioning\n- Device token management\n- Comprehensive audit trail\n- Maintenance jobs\n- Prometheus metrics\n\n## Remaining Concerns\n\n### 1. **Deduplication During Queue Migration**\nIf a message is deduplicating via `idempotency_key` in the notifications table, and we're forwarding new messages to the new queue during migration, the dedup check happens before queueing. This should work correctly, but we need to verify that:\n- Dedup keys are checked at enqueue time (API layer), not queue layer\n- Both queues honor the same dedup semantics\n\n**Recommendation**: Document that idempotency keys are checked before queue selection.\n\n### 2. **Cost of Advisory Locks at Scale**\nAdvisory locks in PostgreSQL are limited resources (shared memory). At very high concurrency (hundreds of workers), we might exhaust available locks. Need to:\n- Monitor `pg_locks` for advisory lock contention\n- Set `max_locks_per_transaction` appropriately\n- Document when to migrate to Redis (not just throughput, but concurrency)\n\n### 3. **Webhook Signature Verification**\nThe webhook signature is computed server-side, but how does the receiving service verify it? Need to:\n- Document the HMAC verification process for webhook consumers\n- Consider adding timestamp to prevent replay attacks\n- Provide SDK/library for webhook verification\n\n### 4. **Multi-Region Deployments**\nFor global deployments with regional queues:\n- How do we route notifications to the nearest queue?\n- Can workers in one region process messages from another region's queue?\n- Does webhook delivery respect regional restrictions (GDPR)?\n\n**Recommendation**: Add `region` field to worker config and queue routing logic.\n\n### 5. **Circuit Breaker Coordination**\nEach worker has its own circuit breaker state. In a fleet of 50 workers, they'll independently trip and recover. Should we:\n- Share circuit breaker state via Redis (adds complexity, improves coordination)\n- Keep local state but share trip signals (hybrid approach)\n- Accept eventual consistency (simplest, current design)\n\nCurrent design is acceptable for most cases, but distributed circuit breaking should be documented as a future enhancement.\n\n## Convergence Status\n\n**ITERATING** - The dequeue race condition fix and queue migration strategy are solid, but need feedback on webhook retry policy flexibility and circuit breaker coordination approach.\n\n## Prompt for Architect\n\nPROMPT_FOR_ARCHITECT:\nReview the **three-layer dequeue protection** (advisory lock + FOR UPDATE SKIP LOCKED + version check) - is this over-engineered, or does it actually prevent subtle races that would occur with only two layers? Challenge the **queue migration live-forward strategy**: are dedicated drain workers necessary, or can we reuse existing workers with a \"draining mode\" flag? Finally, evaluate the **webhook retry policy configurability** - should this be per-notification, per-tenant, or system-wide default? Consider the API ergonomics and common use cases."
      }
    }
  ],
  "final_design": "",
  "status": "debating",
  "started_at": "2026-01-17T10:31:22.318020",
  "ended_at": "",
  "max_rounds": 2,
  "working_dir": ".",
  "current_round": 2,
  "round_times": [
    167.03397727012634,
    471.80076837539673
  ]
}