{
  "initial_prompt": "Design a webhook delivery system with retries",
  "rounds": [
    {
      "round_number": 1,
      "agent_a": {
        "content": "## Design\n\n# Webhook Delivery System with Retries\n\n## Architecture Overview\n\nA distributed, scalable webhook delivery system that guarantees reliable event delivery through exponential backoff retries, dead-letter queues, and observability.\n\n### System Components\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Event Source   \u2502\n\u2502   (Producer)    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Ingestion API  \u2502\n\u2502   (REST/gRPC)   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Message Queue  \u2502\u2500\u2500\u2500\u2500\u2500\u25b6\u2502  Dead Letter Q   \u2502\n\u2502  (Primary)      \u2502      \u2502  (Failed Events) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Delivery Worker \u2502\n\u2502   (Scalable)    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Webhook Target  \u2502\n\u2502  (Customer)     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n## Core Components\n\n### 1. Ingestion API\n**Responsibility**: Accept webhook events from producers\n\n**Interface**:\n```typescript\ninterface IngestionAPI {\n  // Submit a webhook event for delivery\n  POST /v1/webhooks\n  \n  Request:\n  {\n    subscriptionId: string;      // Target webhook subscription\n    eventType: string;            // e.g., \"order.created\"\n    payload: object;              // Event data\n    idempotencyKey?: string;      // Prevent duplicates\n    metadata?: Record<string, string>;\n  }\n  \n  Response:\n  {\n    eventId: string;              // Unique event identifier\n    status: \"queued\" | \"rejected\";\n    queuedAt: timestamp;\n  }\n}\n```\n\n**Responsibilities**:\n- Validate event schema\n- Check subscription exists and is active\n- Deduplicate using idempotencyKey\n- Persist event to database\n- Enqueue to message queue\n- Return immediately (async processing)\n\n### 2. Subscription Management\n\n**Data Model**:\n```typescript\ninterface WebhookSubscription {\n  id: string;\n  organizationId: string;\n  url: string;                    // Target endpoint\n  eventTypes: string[];           // Subscribed events\n  active: boolean;\n  createdAt: timestamp;\n  updatedAt: timestamp;\n  \n  // Delivery configuration\n  deliveryConfig: {\n    timeoutMs: number;            // Default: 15000\n    retryStrategy: RetryStrategy;\n    headers?: Record<string, string>; // Custom headers\n    signingSecret: string;        // For HMAC signature\n  };\n  \n  // Rate limiting\n  rateLimitConfig?: {\n    maxRequestsPerSecond: number;\n    maxConcurrentRequests: number;\n  };\n}\n\ninterface RetryStrategy {\n  maxAttempts: number;            // Default: 5\n  backoffType: \"exponential\" | \"linear\" | \"fixed\";\n  initialDelayMs: number;         // Default: 1000\n  maxDelayMs: number;             // Default: 3600000 (1 hour)\n  multiplier?: number;            // For exponential: 2\n}\n```\n\n**API**:\n```typescript\ninterface SubscriptionAPI {\n  POST /v1/subscriptions        // Create subscription\n  GET /v1/subscriptions/:id     // Get details\n  PATCH /v1/subscriptions/:id   // Update config\n  DELETE /v1/subscriptions/:id  // Deactivate\n  GET /v1/subscriptions/:id/events  // List events\n}\n```\n\n### 3. Event Storage (Database)\n\n**Schema**:\n```sql\nCREATE TABLE webhook_events (\n  id UUID PRIMARY KEY,\n  subscription_id UUID NOT NULL,\n  event_type VARCHAR(255) NOT NULL,\n  payload JSONB NOT NULL,\n  idempotency_key VARCHAR(255) UNIQUE,\n  metadata JSONB,\n  status VARCHAR(50) NOT NULL, -- queued, delivering, delivered, failed, dead_letter\n  \n  -- Delivery tracking\n  attempt_count INTEGER DEFAULT 0,\n  max_attempts INTEGER NOT NULL,\n  next_attempt_at TIMESTAMP,\n  last_attempt_at TIMESTAMP,\n  delivered_at TIMESTAMP,\n  failed_at TIMESTAMP,\n  \n  -- Timing\n  created_at TIMESTAMP NOT NULL,\n  updated_at TIMESTAMP NOT NULL,\n  \n  -- Indexing\n  INDEX idx_subscription_created (subscription_id, created_at),\n  INDEX idx_status_next_attempt (status, next_attempt_at),\n  INDEX idx_idempotency (idempotency_key)\n);\n\nCREATE TABLE webhook_delivery_attempts (\n  id UUID PRIMARY KEY,\n  event_id UUID NOT NULL,\n  attempt_number INTEGER NOT NULL,\n  \n  -- Request details\n  request_url TEXT NOT NULL,\n  request_headers JSONB,\n  request_body JSONB,\n  \n  -- Response details\n  response_status_code INTEGER,\n  response_headers JSONB,\n  response_body TEXT,\n  response_time_ms INTEGER,\n  \n  -- Error tracking\n  error_type VARCHAR(100), -- timeout, connection_error, http_error, etc.\n  error_message TEXT,\n  \n  attempted_at TIMESTAMP NOT NULL,\n  \n  INDEX idx_event_attempt (event_id, attempt_number)\n);\n```\n\n### 4. Message Queue\n\n**Queue Structure**:\n- **Primary Queue**: `webhook-delivery-queue`\n  - Messages ready for immediate delivery\n  - FIFO per subscription (maintain ordering)\n  \n- **Retry Queues**: `webhook-retry-queue-{delay}`\n  - Delayed queues for retry scheduling\n  - Messages move here after failed attempts\n  \n- **Dead Letter Queue**: `webhook-dead-letter-queue`\n  - Events that exhausted all retries\n  - Requires manual intervention or replay\n\n**Message Format**:\n```typescript\ninterface DeliveryMessage {\n  eventId: string;\n  subscriptionId: string;\n  attemptNumber: number;\n  scheduledFor: timestamp;\n  payload: {\n    eventType: string;\n    data: object;\n    metadata: Record<string, string>;\n  };\n}\n```\n\n### 5. Delivery Worker\n\n**Core Logic**:\n```typescript\nclass WebhookDeliveryWorker {\n  async processMessage(message: DeliveryMessage): Promise<void> {\n    const event = await db.getEvent(message.eventId);\n    const subscription = await db.getSubscription(message.subscriptionId);\n    \n    // Check if subscription is still active\n    if (!subscription.active) {\n      await this.markEventAsCancelled(event);\n      return;\n    }\n    \n    // Apply rate limiting\n    await this.acquireRateLimit(subscription);\n    \n    try {\n      // Prepare request\n      const request = this.buildRequest(event, subscription);\n      \n      // Sign request\n      const signature = this.generateSignature(\n        request.body, \n        subscription.deliveryConfig.signingSecret\n      );\n      request.headers['X-Webhook-Signature'] = signature;\n      request.headers['X-Webhook-Event-Id'] = event.id;\n      request.headers['X-Webhook-Attempt'] = message.attemptNumber.toString();\n      \n      // Execute delivery with timeout\n      const startTime = Date.now();\n      const response = await this.httpClient.post(\n        subscription.url,\n        request.body,\n        {\n          headers: request.headers,\n          timeout: subscription.deliveryConfig.timeoutMs\n        }\n      );\n      const responseTime = Date.now() - startTime;\n      \n      // Record attempt\n      await this.recordAttempt(event, message.attemptNumber, {\n        request,\n        response,\n        responseTime,\n        success: this.isSuccessStatus(response.status)\n      });\n      \n      // Handle response\n      if (this.isSuccessStatus(response.status)) {\n        await this.markEventAsDelivered(event);\n      } else {\n        await this.scheduleRetry(event, message, response);\n      }\n      \n    } catch (error) {\n      // Handle delivery failure\n      await this.recordAttempt(event, message.attemptNumber, {\n        request,\n        error,\n        success: false\n      });\n      \n      await this.scheduleRetry(event, message, error);\n    }\n  }\n  \n  private async scheduleRetry(\n    event: WebhookEvent, \n    message: DeliveryMessage,\n    failureContext: any\n  ): Promise<void> {\n    const subscription = await db.getSubscription(event.subscriptionId);\n    const nextAttempt = message.attemptNumber + 1;\n    \n    if (nextAttempt >= subscription.deliveryConfig.retryStrategy.maxAttempts) {\n      // Move to dead letter queue\n      await this.moveToDeadLetter(event, failureContext);\n      await db.updateEvent(event.id, {\n        status: 'dead_letter',\n        failed_at: new Date()\n      });\n      return;\n    }\n    \n    // Calculate retry delay\n    const delay = this.calculateBackoff(\n      subscription.deliveryConfig.retryStrategy,\n      nextAttempt\n    );\n    \n    const nextAttemptTime = new Date(Date.now() + delay);\n    \n    // Update event\n    await db.updateEvent(event.id, {\n      status: 'queued',\n      attempt_count: nextAttempt,\n      next_attempt_at: nextAttemptTime\n    });\n    \n    // Enqueue to retry queue\n    await messageQueue.publish('webhook-retry-queue', {\n      ...message,\n      attemptNumber: nextAttempt,\n      scheduledFor: nextAttemptTime\n    }, { delayMs: delay });\n  }\n  \n  private calculateBackoff(strategy: RetryStrategy, attempt: number): number {\n    let delay: number;\n    \n    switch (strategy.backoffType) {\n      case 'exponential':\n        delay = strategy.initialDelayMs * Math.pow(strategy.multiplier || 2, attempt - 1);\n        break;\n      case 'linear':\n        delay = strategy.initialDelayMs * attempt;\n        break;\n      case 'fixed':\n        delay = strategy.initialDelayMs;\n        break;\n    }\n    \n    // Apply jitter (\u00b125%)\n    const jitter = delay * 0.25 * (Math.random() - 0.5) * 2;\n    delay += jitter;\n    \n    // Cap at max delay\n    return Math.min(delay, strategy.maxDelayMs);\n  }\n  \n  private isSuccessStatus(statusCode: number): boolean {\n    return statusCode >= 200 && statusCode < 300;\n  }\n  \n  private generateSignature(payload: string, secret: string): string {\n    return crypto\n      .createHmac('sha256', secret)\n      .update(payload)\n      .digest('hex');\n  }\n}\n```\n\n### 6. Retry Scheduler\n\n**Purpose**: Move delayed retry messages back to primary queue when ready\n\n```typescript\nclass RetryScheduler {\n  async run(): Promise<void> {\n    while (true) {\n      // Find events ready for retry\n      const events = await db.query(`\n        SELECT * FROM webhook_events\n        WHERE status = 'queued'\n          AND next_attempt_at <= NOW()\n        ORDER BY next_attempt_at\n        LIMIT 1000\n      `);\n      \n      for (const event of events) {\n        await messageQueue.publish('webhook-delivery-queue', {\n          eventId: event.id,\n          subscriptionId: event.subscription_id,\n          attemptNumber: event.attempt_count,\n          scheduledFor: new Date(),\n          payload: event.payload\n        });\n        \n        await db.updateEvent(event.id, { status: 'delivering' });\n      }\n      \n      await sleep(5000); // Poll every 5 seconds\n    }\n  }\n}\n```\n\n## Error Handling Strategy\n\n### HTTP Status Code Handling\n\n| Status Code Range | Action | Retry? |\n|------------------|--------|--------|\n| 2xx (Success) | Mark delivered | No |\n| 3xx (Redirect) | Follow redirect (max 3 hops) | No |\n| 4xx (Client Error) | Move to dead letter (except 408, 429) | No |\n| 408 (Timeout) | Retry with backoff | Yes |\n| 429 (Rate Limited) | Retry with exponential backoff | Yes |\n| 5xx (Server Error) | Retry with backoff | Yes |\n| Network Errors | Retry with backoff | Yes |\n| Timeout | Retry with backoff | Yes |\n\n### Dead Letter Queue Processing\n\n```typescript\ninterface DeadLetterEvent {\n  eventId: string;\n  subscriptionId: string;\n  failureReason: string;\n  lastAttempt: DeliveryAttempt;\n  retriesExhausted: boolean;\n  deadLetteredAt: timestamp;\n}\n\n// API for dead letter management\ninterface DeadLetterAPI {\n  GET /v1/dead-letters                    // List failed events\n  GET /v1/dead-letters/:eventId           // Get details\n  POST /v1/dead-letters/:eventId/replay   // Retry manually\n  DELETE /v1/dead-letters/:eventId        // Discard permanently\n}\n```\n\n## Observability & Monitoring\n\n### Metrics\n```typescript\ninterface WebhookMetrics {\n  // Throughput\n  events_ingested_total: Counter;\n  events_delivered_total: Counter;\n  events_failed_total: Counter;\n  \n  // Latency\n  delivery_duration_seconds: Histogram;\n  queue_wait_time_seconds: Histogram;\n  \n  // Retry tracking\n  retry_attempts_total: Counter;\n  dead_letter_events_total: Counter;\n  \n  // Subscription health\n  subscription_success_rate: Gauge;\n  subscription_error_rate: Gauge;\n  \n  // Queue depth\n  queue_size: Gauge;\n  retry_queue_size: Gauge;\n  dead_letter_queue_size: Gauge;\n}\n```\n\n### Logging\n```typescript\ninterface DeliveryLog {\n  timestamp: string;\n  level: \"info\" | \"warn\" | \"error\";\n  eventId: string;\n  subscriptionId: string;\n  attemptNumber: number;\n  \n  // Contextual data\n  requestUrl: string;\n  responseStatus?: number;\n  responseTimeMs?: number;\n  errorType?: string;\n  errorMessage?: string;\n  \n  // Tracing\n  traceId: string;\n  spanId: string;\n}\n```\n\n### Alerting Rules\n- Dead letter queue size > 1000\n- Subscription error rate > 50% over 5 minutes\n- Average delivery latency > 30 seconds\n- Queue depth growing consistently (indicates worker lag)\n\n## Security Considerations\n\n### Request Signing\n- HMAC-SHA256 signature in `X-Webhook-Signature` header\n- Include timestamp to prevent replay attacks\n- Rotate secrets via API\n\n### Rate Limiting\n- Per-subscription rate limits\n- Global system rate limits\n- Backpressure mechanisms\n\n### Data Privacy\n- Encrypt sensitive payload data at rest\n- TLS 1.3 for all webhook deliveries\n- Option to exclude sensitive fields from logs\n\n## Scalability Considerations\n\n### Horizontal Scaling\n- Stateless delivery workers (scale to N instances)\n- Message queue handles distribution\n- Database sharding by subscription_id\n\n### Performance Optimizations\n- Connection pooling for HTTP clients\n- Keep-alive connections to frequently hit endpoints\n- Batch database operations\n- Cache subscription configurations\n\n### Capacity Planning\n- Worker instances: 1 instance per 1000 req/sec\n- Database: Partition by time (monthly tables)\n- Queue: Use multiple partitions for high throughput\n\n## Rationale\n\n**Message Queue as Central Hub**: Using a message queue (e.g., RabbitMQ, SQS, Kafka) ensures reliable, asynchronous delivery with natural retry scheduling through delayed queues. This decouples ingestion from delivery.\n\n**Database as Source of Truth**: Persisting events to a database before queuing provides durability, audit trails, and the ability to replay or query historical events. The queue is ephemeral; the database is permanent.\n\n**Exponential Backoff with Jitter**: Prevents thundering herd problems when services recover. Jitter distributes retry attempts over time to avoid synchronized retries.\n\n**Per-Subscription Rate Limiting**: Protects customer endpoints from overload while allowing the system to maintain high throughput for other subscriptions.\n\n**Dead Letter Queue**: Manual intervention path for events that can't be delivered automatically. Prevents infinite retry loops and allows investigation of persistent failures.\n\n**HMAC Signing**: Standard webhook security practice. Allows receivers to verify authenticity and integrity of webhooks without requiring mutual TLS.\n\n**Separate Delivery Attempts Table**: Keeps audit trail without bloating the events table. Essential for debugging and SLA reporting.\n\n## What I Changed\n\nThis is the initial design, so nothing changed yet.\n\n## What I Kept\n\nN/A - initial proposal.\n\n## Open Questions\n\n1. **Ordering Guarantees**: Should we guarantee strict ordering of events per subscription, or allow parallel delivery for better throughput?\n\n2. **Webhook Format**: Should we support multiple webhook formats (Standard Webhooks spec, CloudEvents, custom)?\n\n3. **Replay Strategy**: When replaying from dead letter queue, should we reset retry count or continue from where it failed?\n\n4. **Circuit Breaker**: Should we implement a circuit breaker to temporarily pause deliveries to consistently failing endpoints?\n\n5. **Batch Delivery**: Should we support batching multiple events into a single webhook call for high-volume subscriptions?\n\n## Convergence Status\n- **ITERATING**: This is the initial design and requires review and refinement.",
        "prompt_for_other": "Please review this design with particular focus on:\n1. **Failure scenarios**: Are there edge cases in retry logic or error handling that could cause data loss or infinite loops?\n2. **Scalability bottlenecks**: Will this architecture handle 100K+ webhooks/second? Where are the bottlenecks?\n3. **Operational complexity**: Is this system too complex to operate and debug in production?",
        "convergence_signal": "ITERATING",
        "raw_response": "## Design\n\n# Webhook Delivery System with Retries\n\n## Architecture Overview\n\nA distributed, scalable webhook delivery system that guarantees reliable event delivery through exponential backoff retries, dead-letter queues, and observability.\n\n### System Components\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Event Source   \u2502\n\u2502   (Producer)    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Ingestion API  \u2502\n\u2502   (REST/gRPC)   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Message Queue  \u2502\u2500\u2500\u2500\u2500\u2500\u25b6\u2502  Dead Letter Q   \u2502\n\u2502  (Primary)      \u2502      \u2502  (Failed Events) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Delivery Worker \u2502\n\u2502   (Scalable)    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Webhook Target  \u2502\n\u2502  (Customer)     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n## Core Components\n\n### 1. Ingestion API\n**Responsibility**: Accept webhook events from producers\n\n**Interface**:\n```typescript\ninterface IngestionAPI {\n  // Submit a webhook event for delivery\n  POST /v1/webhooks\n  \n  Request:\n  {\n    subscriptionId: string;      // Target webhook subscription\n    eventType: string;            // e.g., \"order.created\"\n    payload: object;              // Event data\n    idempotencyKey?: string;      // Prevent duplicates\n    metadata?: Record<string, string>;\n  }\n  \n  Response:\n  {\n    eventId: string;              // Unique event identifier\n    status: \"queued\" | \"rejected\";\n    queuedAt: timestamp;\n  }\n}\n```\n\n**Responsibilities**:\n- Validate event schema\n- Check subscription exists and is active\n- Deduplicate using idempotencyKey\n- Persist event to database\n- Enqueue to message queue\n- Return immediately (async processing)\n\n### 2. Subscription Management\n\n**Data Model**:\n```typescript\ninterface WebhookSubscription {\n  id: string;\n  organizationId: string;\n  url: string;                    // Target endpoint\n  eventTypes: string[];           // Subscribed events\n  active: boolean;\n  createdAt: timestamp;\n  updatedAt: timestamp;\n  \n  // Delivery configuration\n  deliveryConfig: {\n    timeoutMs: number;            // Default: 15000\n    retryStrategy: RetryStrategy;\n    headers?: Record<string, string>; // Custom headers\n    signingSecret: string;        // For HMAC signature\n  };\n  \n  // Rate limiting\n  rateLimitConfig?: {\n    maxRequestsPerSecond: number;\n    maxConcurrentRequests: number;\n  };\n}\n\ninterface RetryStrategy {\n  maxAttempts: number;            // Default: 5\n  backoffType: \"exponential\" | \"linear\" | \"fixed\";\n  initialDelayMs: number;         // Default: 1000\n  maxDelayMs: number;             // Default: 3600000 (1 hour)\n  multiplier?: number;            // For exponential: 2\n}\n```\n\n**API**:\n```typescript\ninterface SubscriptionAPI {\n  POST /v1/subscriptions        // Create subscription\n  GET /v1/subscriptions/:id     // Get details\n  PATCH /v1/subscriptions/:id   // Update config\n  DELETE /v1/subscriptions/:id  // Deactivate\n  GET /v1/subscriptions/:id/events  // List events\n}\n```\n\n### 3. Event Storage (Database)\n\n**Schema**:\n```sql\nCREATE TABLE webhook_events (\n  id UUID PRIMARY KEY,\n  subscription_id UUID NOT NULL,\n  event_type VARCHAR(255) NOT NULL,\n  payload JSONB NOT NULL,\n  idempotency_key VARCHAR(255) UNIQUE,\n  metadata JSONB,\n  status VARCHAR(50) NOT NULL, -- queued, delivering, delivered, failed, dead_letter\n  \n  -- Delivery tracking\n  attempt_count INTEGER DEFAULT 0,\n  max_attempts INTEGER NOT NULL,\n  next_attempt_at TIMESTAMP,\n  last_attempt_at TIMESTAMP,\n  delivered_at TIMESTAMP,\n  failed_at TIMESTAMP,\n  \n  -- Timing\n  created_at TIMESTAMP NOT NULL,\n  updated_at TIMESTAMP NOT NULL,\n  \n  -- Indexing\n  INDEX idx_subscription_created (subscription_id, created_at),\n  INDEX idx_status_next_attempt (status, next_attempt_at),\n  INDEX idx_idempotency (idempotency_key)\n);\n\nCREATE TABLE webhook_delivery_attempts (\n  id UUID PRIMARY KEY,\n  event_id UUID NOT NULL,\n  attempt_number INTEGER NOT NULL,\n  \n  -- Request details\n  request_url TEXT NOT NULL,\n  request_headers JSONB,\n  request_body JSONB,\n  \n  -- Response details\n  response_status_code INTEGER,\n  response_headers JSONB,\n  response_body TEXT,\n  response_time_ms INTEGER,\n  \n  -- Error tracking\n  error_type VARCHAR(100), -- timeout, connection_error, http_error, etc.\n  error_message TEXT,\n  \n  attempted_at TIMESTAMP NOT NULL,\n  \n  INDEX idx_event_attempt (event_id, attempt_number)\n);\n```\n\n### 4. Message Queue\n\n**Queue Structure**:\n- **Primary Queue**: `webhook-delivery-queue`\n  - Messages ready for immediate delivery\n  - FIFO per subscription (maintain ordering)\n  \n- **Retry Queues**: `webhook-retry-queue-{delay}`\n  - Delayed queues for retry scheduling\n  - Messages move here after failed attempts\n  \n- **Dead Letter Queue**: `webhook-dead-letter-queue`\n  - Events that exhausted all retries\n  - Requires manual intervention or replay\n\n**Message Format**:\n```typescript\ninterface DeliveryMessage {\n  eventId: string;\n  subscriptionId: string;\n  attemptNumber: number;\n  scheduledFor: timestamp;\n  payload: {\n    eventType: string;\n    data: object;\n    metadata: Record<string, string>;\n  };\n}\n```\n\n### 5. Delivery Worker\n\n**Core Logic**:\n```typescript\nclass WebhookDeliveryWorker {\n  async processMessage(message: DeliveryMessage): Promise<void> {\n    const event = await db.getEvent(message.eventId);\n    const subscription = await db.getSubscription(message.subscriptionId);\n    \n    // Check if subscription is still active\n    if (!subscription.active) {\n      await this.markEventAsCancelled(event);\n      return;\n    }\n    \n    // Apply rate limiting\n    await this.acquireRateLimit(subscription);\n    \n    try {\n      // Prepare request\n      const request = this.buildRequest(event, subscription);\n      \n      // Sign request\n      const signature = this.generateSignature(\n        request.body, \n        subscription.deliveryConfig.signingSecret\n      );\n      request.headers['X-Webhook-Signature'] = signature;\n      request.headers['X-Webhook-Event-Id'] = event.id;\n      request.headers['X-Webhook-Attempt'] = message.attemptNumber.toString();\n      \n      // Execute delivery with timeout\n      const startTime = Date.now();\n      const response = await this.httpClient.post(\n        subscription.url,\n        request.body,\n        {\n          headers: request.headers,\n          timeout: subscription.deliveryConfig.timeoutMs\n        }\n      );\n      const responseTime = Date.now() - startTime;\n      \n      // Record attempt\n      await this.recordAttempt(event, message.attemptNumber, {\n        request,\n        response,\n        responseTime,\n        success: this.isSuccessStatus(response.status)\n      });\n      \n      // Handle response\n      if (this.isSuccessStatus(response.status)) {\n        await this.markEventAsDelivered(event);\n      } else {\n        await this.scheduleRetry(event, message, response);\n      }\n      \n    } catch (error) {\n      // Handle delivery failure\n      await this.recordAttempt(event, message.attemptNumber, {\n        request,\n        error,\n        success: false\n      });\n      \n      await this.scheduleRetry(event, message, error);\n    }\n  }\n  \n  private async scheduleRetry(\n    event: WebhookEvent, \n    message: DeliveryMessage,\n    failureContext: any\n  ): Promise<void> {\n    const subscription = await db.getSubscription(event.subscriptionId);\n    const nextAttempt = message.attemptNumber + 1;\n    \n    if (nextAttempt >= subscription.deliveryConfig.retryStrategy.maxAttempts) {\n      // Move to dead letter queue\n      await this.moveToDeadLetter(event, failureContext);\n      await db.updateEvent(event.id, {\n        status: 'dead_letter',\n        failed_at: new Date()\n      });\n      return;\n    }\n    \n    // Calculate retry delay\n    const delay = this.calculateBackoff(\n      subscription.deliveryConfig.retryStrategy,\n      nextAttempt\n    );\n    \n    const nextAttemptTime = new Date(Date.now() + delay);\n    \n    // Update event\n    await db.updateEvent(event.id, {\n      status: 'queued',\n      attempt_count: nextAttempt,\n      next_attempt_at: nextAttemptTime\n    });\n    \n    // Enqueue to retry queue\n    await messageQueue.publish('webhook-retry-queue', {\n      ...message,\n      attemptNumber: nextAttempt,\n      scheduledFor: nextAttemptTime\n    }, { delayMs: delay });\n  }\n  \n  private calculateBackoff(strategy: RetryStrategy, attempt: number): number {\n    let delay: number;\n    \n    switch (strategy.backoffType) {\n      case 'exponential':\n        delay = strategy.initialDelayMs * Math.pow(strategy.multiplier || 2, attempt - 1);\n        break;\n      case 'linear':\n        delay = strategy.initialDelayMs * attempt;\n        break;\n      case 'fixed':\n        delay = strategy.initialDelayMs;\n        break;\n    }\n    \n    // Apply jitter (\u00b125%)\n    const jitter = delay * 0.25 * (Math.random() - 0.5) * 2;\n    delay += jitter;\n    \n    // Cap at max delay\n    return Math.min(delay, strategy.maxDelayMs);\n  }\n  \n  private isSuccessStatus(statusCode: number): boolean {\n    return statusCode >= 200 && statusCode < 300;\n  }\n  \n  private generateSignature(payload: string, secret: string): string {\n    return crypto\n      .createHmac('sha256', secret)\n      .update(payload)\n      .digest('hex');\n  }\n}\n```\n\n### 6. Retry Scheduler\n\n**Purpose**: Move delayed retry messages back to primary queue when ready\n\n```typescript\nclass RetryScheduler {\n  async run(): Promise<void> {\n    while (true) {\n      // Find events ready for retry\n      const events = await db.query(`\n        SELECT * FROM webhook_events\n        WHERE status = 'queued'\n          AND next_attempt_at <= NOW()\n        ORDER BY next_attempt_at\n        LIMIT 1000\n      `);\n      \n      for (const event of events) {\n        await messageQueue.publish('webhook-delivery-queue', {\n          eventId: event.id,\n          subscriptionId: event.subscription_id,\n          attemptNumber: event.attempt_count,\n          scheduledFor: new Date(),\n          payload: event.payload\n        });\n        \n        await db.updateEvent(event.id, { status: 'delivering' });\n      }\n      \n      await sleep(5000); // Poll every 5 seconds\n    }\n  }\n}\n```\n\n## Error Handling Strategy\n\n### HTTP Status Code Handling\n\n| Status Code Range | Action | Retry? |\n|------------------|--------|--------|\n| 2xx (Success) | Mark delivered | No |\n| 3xx (Redirect) | Follow redirect (max 3 hops) | No |\n| 4xx (Client Error) | Move to dead letter (except 408, 429) | No |\n| 408 (Timeout) | Retry with backoff | Yes |\n| 429 (Rate Limited) | Retry with exponential backoff | Yes |\n| 5xx (Server Error) | Retry with backoff | Yes |\n| Network Errors | Retry with backoff | Yes |\n| Timeout | Retry with backoff | Yes |\n\n### Dead Letter Queue Processing\n\n```typescript\ninterface DeadLetterEvent {\n  eventId: string;\n  subscriptionId: string;\n  failureReason: string;\n  lastAttempt: DeliveryAttempt;\n  retriesExhausted: boolean;\n  deadLetteredAt: timestamp;\n}\n\n// API for dead letter management\ninterface DeadLetterAPI {\n  GET /v1/dead-letters                    // List failed events\n  GET /v1/dead-letters/:eventId           // Get details\n  POST /v1/dead-letters/:eventId/replay   // Retry manually\n  DELETE /v1/dead-letters/:eventId        // Discard permanently\n}\n```\n\n## Observability & Monitoring\n\n### Metrics\n```typescript\ninterface WebhookMetrics {\n  // Throughput\n  events_ingested_total: Counter;\n  events_delivered_total: Counter;\n  events_failed_total: Counter;\n  \n  // Latency\n  delivery_duration_seconds: Histogram;\n  queue_wait_time_seconds: Histogram;\n  \n  // Retry tracking\n  retry_attempts_total: Counter;\n  dead_letter_events_total: Counter;\n  \n  // Subscription health\n  subscription_success_rate: Gauge;\n  subscription_error_rate: Gauge;\n  \n  // Queue depth\n  queue_size: Gauge;\n  retry_queue_size: Gauge;\n  dead_letter_queue_size: Gauge;\n}\n```\n\n### Logging\n```typescript\ninterface DeliveryLog {\n  timestamp: string;\n  level: \"info\" | \"warn\" | \"error\";\n  eventId: string;\n  subscriptionId: string;\n  attemptNumber: number;\n  \n  // Contextual data\n  requestUrl: string;\n  responseStatus?: number;\n  responseTimeMs?: number;\n  errorType?: string;\n  errorMessage?: string;\n  \n  // Tracing\n  traceId: string;\n  spanId: string;\n}\n```\n\n### Alerting Rules\n- Dead letter queue size > 1000\n- Subscription error rate > 50% over 5 minutes\n- Average delivery latency > 30 seconds\n- Queue depth growing consistently (indicates worker lag)\n\n## Security Considerations\n\n### Request Signing\n- HMAC-SHA256 signature in `X-Webhook-Signature` header\n- Include timestamp to prevent replay attacks\n- Rotate secrets via API\n\n### Rate Limiting\n- Per-subscription rate limits\n- Global system rate limits\n- Backpressure mechanisms\n\n### Data Privacy\n- Encrypt sensitive payload data at rest\n- TLS 1.3 for all webhook deliveries\n- Option to exclude sensitive fields from logs\n\n## Scalability Considerations\n\n### Horizontal Scaling\n- Stateless delivery workers (scale to N instances)\n- Message queue handles distribution\n- Database sharding by subscription_id\n\n### Performance Optimizations\n- Connection pooling for HTTP clients\n- Keep-alive connections to frequently hit endpoints\n- Batch database operations\n- Cache subscription configurations\n\n### Capacity Planning\n- Worker instances: 1 instance per 1000 req/sec\n- Database: Partition by time (monthly tables)\n- Queue: Use multiple partitions for high throughput\n\n## Rationale\n\n**Message Queue as Central Hub**: Using a message queue (e.g., RabbitMQ, SQS, Kafka) ensures reliable, asynchronous delivery with natural retry scheduling through delayed queues. This decouples ingestion from delivery.\n\n**Database as Source of Truth**: Persisting events to a database before queuing provides durability, audit trails, and the ability to replay or query historical events. The queue is ephemeral; the database is permanent.\n\n**Exponential Backoff with Jitter**: Prevents thundering herd problems when services recover. Jitter distributes retry attempts over time to avoid synchronized retries.\n\n**Per-Subscription Rate Limiting**: Protects customer endpoints from overload while allowing the system to maintain high throughput for other subscriptions.\n\n**Dead Letter Queue**: Manual intervention path for events that can't be delivered automatically. Prevents infinite retry loops and allows investigation of persistent failures.\n\n**HMAC Signing**: Standard webhook security practice. Allows receivers to verify authenticity and integrity of webhooks without requiring mutual TLS.\n\n**Separate Delivery Attempts Table**: Keeps audit trail without bloating the events table. Essential for debugging and SLA reporting.\n\n## What I Changed\n\nThis is the initial design, so nothing changed yet.\n\n## What I Kept\n\nN/A - initial proposal.\n\n## Open Questions\n\n1. **Ordering Guarantees**: Should we guarantee strict ordering of events per subscription, or allow parallel delivery for better throughput?\n\n2. **Webhook Format**: Should we support multiple webhook formats (Standard Webhooks spec, CloudEvents, custom)?\n\n3. **Replay Strategy**: When replaying from dead letter queue, should we reset retry count or continue from where it failed?\n\n4. **Circuit Breaker**: Should we implement a circuit breaker to temporarily pause deliveries to consistently failing endpoints?\n\n5. **Batch Delivery**: Should we support batching multiple events into a single webhook call for high-volume subscriptions?\n\n## Convergence Status\n- **ITERATING**: This is the initial design and requires review and refinement.\n\nPROMPT_FOR_CRITIC:\nPlease review this design with particular focus on:\n1. **Failure scenarios**: Are there edge cases in retry logic or error handling that could cause data loss or infinite loops?\n2. **Scalability bottlenecks**: Will this architecture handle 100K+ webhooks/second? Where are the bottlenecks?\n3. **Operational complexity**: Is this system too complex to operate and debug in production?"
      },
      "agent_b": {
        "content": "## Design\n\n# Webhook Delivery System with Retries\n\n## Architecture Overview\n\nA distributed, scalable webhook delivery system that guarantees reliable event delivery through exponential backoff retries, dead-letter queues, circuit breakers, and comprehensive observability.\n\n### System Components\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Event Source   \u2502\n\u2502   (Producer)    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Ingestion API  \u2502\u2500\u2500\u2500\u2500\u2500\u25b6\u2502   Event Store    \u2502\n\u2502   (REST/gRPC)   \u2502      \u2502   (Database)     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Message Queue  \u2502\u2500\u2500\u2500\u2500\u2500\u25b6\u2502  Dead Letter Q   \u2502\n\u2502  (Primary)      \u2502      \u2502  (Failed Events) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Delivery Worker \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2502 Circuit Breaker  \u2502\n\u2502   (Scalable)    \u2502      \u2502    Registry      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Webhook Target  \u2502\n\u2502  (Customer)     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n## Core Components\n\n### 1. Ingestion API\n**Responsibility**: Accept webhook events from producers with deduplication and validation\n\n**Interface**:\n```typescript\ninterface IngestionAPI {\n  // Submit a webhook event for delivery\n  POST /v1/webhooks\n  \n  Request:\n  {\n    subscriptionId: string;      // Target webhook subscription\n    eventType: string;            // e.g., \"order.created\"\n    payload: object;              // Event data\n    idempotencyKey: string;       // REQUIRED - Prevent duplicates\n    metadata?: Record<string, string>;\n    priority?: \"high\" | \"normal\" | \"low\"; // Default: normal\n  }\n  \n  Response:\n  {\n    eventId: string;              // Unique event identifier\n    status: \"accepted\" | \"duplicate\" | \"rejected\";\n    queuedAt: timestamp;\n    reason?: string;              // For rejected/duplicate\n  }\n}\n```\n\n**Critical Implementation Details**:\n- **Idempotency**: Store idempotencyKey with 24-hour TTL in fast cache (Redis)\n- **Atomicity**: Use database transaction to persist event AND enqueue message\n- **Validation**: Reject events immediately if subscription is inactive or rate-limited\n- **Response Time**: Target <50ms p99 latency\n- **Backpressure**: Return 429 if queue depth exceeds threshold (prevents cascading failure)\n\n**Data Loss Prevention**:\n```typescript\nasync function ingestEvent(request: WebhookRequest): Promise<IngestResponse> {\n  // 1. Check idempotency FIRST (before any writes)\n  const cached = await redis.get(`idempotency:${request.idempotencyKey}`);\n  if (cached) {\n    return { status: 'duplicate', eventId: cached, queuedAt: null };\n  }\n  \n  // 2. Validate subscription exists and is active\n  const subscription = await db.getSubscription(request.subscriptionId);\n  if (!subscription || !subscription.active) {\n    return { status: 'rejected', reason: 'Invalid or inactive subscription' };\n  }\n  \n  // 3. BEGIN TRANSACTION - critical for data loss prevention\n  await db.transaction(async (tx) => {\n    // Insert event record\n    const event = await tx.insert('webhook_events', {\n      id: generateUUID(),\n      subscription_id: request.subscriptionId,\n      event_type: request.eventType,\n      payload: request.payload,\n      idempotency_key: request.idempotencyKey,\n      status: 'queued',\n      attempt_count: 0,\n      next_attempt_at: new Date(),\n      created_at: new Date()\n    });\n    \n    // Enqueue message (transactional outbox pattern)\n    await tx.insert('outbox', {\n      event_id: event.id,\n      queue_name: 'webhook-delivery-queue',\n      payload: { eventId: event.id, attemptNumber: 1 }\n    });\n    \n    // Cache idempotency key\n    await redis.setex(`idempotency:${request.idempotencyKey}`, 86400, event.id);\n    \n    return event;\n  });\n  \n  // 4. Outbox processor handles actual queue publishing asynchronously\n  // This ensures message is never lost even if queue is temporarily unavailable\n}\n```\n\n### 2. Subscription Management\n\n**Data Model**:\n```typescript\ninterface WebhookSubscription {\n  id: string;\n  organizationId: string;\n  url: string;                    // Target endpoint\n  eventTypes: string[];           // Subscribed events\n  active: boolean;\n  createdAt: timestamp;\n  updatedAt: timestamp;\n  \n  // Delivery configuration\n  deliveryConfig: {\n    timeoutMs: number;            // Default: 10000 (10s max)\n    retryStrategy: RetryStrategy;\n    headers?: Record<string, string>; // Custom headers\n    signingSecret: string;        // For HMAC signature\n    signingAlgorithm: \"sha256\" | \"sha512\"; // Default: sha256\n  };\n  \n  // Circuit breaker settings\n  circuitBreaker: {\n    enabled: boolean;             // Default: true\n    failureThreshold: number;     // Default: 10 consecutive failures\n    successThreshold: number;     // Default: 3 consecutive successes to close\n    halfOpenTimeoutMs: number;    // Default: 60000 (1 minute)\n    openTimeoutMs: number;        // Default: 300000 (5 minutes)\n  };\n  \n  // Rate limiting (prevents overwhelming customer endpoints)\n  rateLimitConfig: {\n    maxRequestsPerSecond: number; // Default: 100\n    maxConcurrentRequests: number; // Default: 10\n    burstAllowance?: number;      // Default: maxRequestsPerSecond * 2\n  };\n  \n  // Ordering guarantee\n  orderingConfig: {\n    guaranteeOrder: boolean;      // Default: false (allows parallelism)\n    orderingKey?: string;         // JSONPath to extract ordering key from payload\n  };\n}\n\ninterface RetryStrategy {\n  maxAttempts: number;            // Default: 5\n  backoffType: \"exponential\" | \"linear\" | \"fixed\";\n  initialDelayMs: number;         // Default: 1000\n  maxDelayMs: number;             // Default: 3600000 (1 hour)\n  multiplier?: number;            // For exponential: 2\n  retryableStatusCodes: number[]; // Default: [408, 429, 500, 502, 503, 504]\n}\n```\n\n### 3. Event Storage (Database)\n\n**Schema with Improved Indexing**:\n```sql\nCREATE TABLE webhook_events (\n  id UUID PRIMARY KEY,\n  subscription_id UUID NOT NULL,\n  event_type VARCHAR(255) NOT NULL,\n  payload JSONB NOT NULL,\n  idempotency_key VARCHAR(255) NOT NULL,\n  metadata JSONB,\n  status VARCHAR(50) NOT NULL, -- queued, delivering, delivered, failed, dead_letter, cancelled\n  \n  -- Delivery tracking\n  attempt_count INTEGER DEFAULT 0,\n  max_attempts INTEGER NOT NULL,\n  next_attempt_at TIMESTAMP,\n  last_attempt_at TIMESTAMP,\n  delivered_at TIMESTAMP,\n  failed_at TIMESTAMP,\n  \n  -- Timing\n  created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n  updated_at TIMESTAMP NOT NULL DEFAULT NOW(),\n  \n  -- Partitioning hint (for time-based partitioning)\n  partition_date DATE GENERATED ALWAYS AS (DATE(created_at)) STORED,\n  \n  -- Constraints\n  CONSTRAINT unique_idempotency_key UNIQUE (idempotency_key),\n  CONSTRAINT fk_subscription FOREIGN KEY (subscription_id) \n    REFERENCES webhook_subscriptions(id) ON DELETE CASCADE\n) PARTITION BY RANGE (partition_date);\n\n-- Critical indexes for performance\nCREATE INDEX idx_status_next_attempt ON webhook_events (status, next_attempt_at) \n  WHERE status IN ('queued', 'delivering'); -- Partial index for active events only\n\nCREATE INDEX idx_subscription_created ON webhook_events (subscription_id, created_at DESC);\n\nCREATE INDEX idx_subscription_status ON webhook_events (subscription_id, status)\n  INCLUDE (created_at, attempt_count); -- Covering index for dashboard queries\n\n-- Separate table for delivery attempts (append-only for performance)\nCREATE TABLE webhook_delivery_attempts (\n  id UUID PRIMARY KEY,\n  event_id UUID NOT NULL,\n  attempt_number INTEGER NOT NULL,\n  \n  -- Request details\n  request_url TEXT NOT NULL,\n  request_headers JSONB,\n  request_body_hash VARCHAR(64), -- Store hash instead of full body to save space\n  \n  -- Response details\n  response_status_code INTEGER,\n  response_headers JSONB,\n  response_body TEXT, -- Truncate to 10KB max\n  response_time_ms INTEGER,\n  \n  -- Error tracking\n  error_type VARCHAR(100), -- timeout, connection_refused, dns_error, http_error, circuit_open\n  error_message TEXT,\n  \n  attempted_at TIMESTAMP NOT NULL DEFAULT NOW(),\n  \n  CONSTRAINT fk_event FOREIGN KEY (event_id) \n    REFERENCES webhook_events(id) ON DELETE CASCADE\n) PARTITION BY RANGE (attempted_at);\n\n-- Index for querying attempts by event\nCREATE INDEX idx_event_attempts ON webhook_delivery_attempts (event_id, attempt_number DESC);\n\n-- Outbox table for reliable message publishing (transactional outbox pattern)\nCREATE TABLE outbox (\n  id BIGSERIAL PRIMARY KEY,\n  event_id UUID NOT NULL,\n  queue_name VARCHAR(255) NOT NULL,\n  payload JSONB NOT NULL,\n  published BOOLEAN DEFAULT FALSE,\n  created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n  published_at TIMESTAMP\n);\n\nCREATE INDEX idx_outbox_unpublished ON outbox (published, created_at) WHERE NOT published;\n\n-- Circuit breaker state (cached in Redis, persisted in DB for recovery)\nCREATE TABLE circuit_breaker_state (\n  subscription_id UUID PRIMARY KEY,\n  state VARCHAR(20) NOT NULL, -- closed, open, half_open\n  failure_count INTEGER DEFAULT 0,\n  success_count INTEGER DEFAULT 0,\n  last_failure_at TIMESTAMP,\n  opened_at TIMESTAMP,\n  half_opened_at TIMESTAMP,\n  updated_at TIMESTAMP NOT NULL DEFAULT NOW(),\n  \n  CONSTRAINT fk_subscription FOREIGN KEY (subscription_id)\n    REFERENCES webhook_subscriptions(id) ON DELETE CASCADE\n);\n```\n\n### 4. Message Queue Architecture\n\n**Queue Structure with Ordering Guarantees**:\n- **Primary Queue**: `webhook-delivery-queue`\n  - Partitioned by subscription_id for ordered subscriptions\n  - Messages include priority field for priority-based delivery\n  \n- **Delayed Retry Queue**: `webhook-retry-queue`\n  - Single queue with message visibility timeout (for SQS-style queues)\n  - OR delay exchanges (for RabbitMQ-style queues)\n  \n- **Dead Letter Queue**: `webhook-dead-letter-queue`\n  - Events that exhausted all retries\n  - Requires manual intervention or replay\n\n**Message Format**:\n```typescript\ninterface DeliveryMessage {\n  eventId: string;\n  subscriptionId: string;\n  attemptNumber: number;\n  scheduledFor: timestamp;\n  priority: \"high\" | \"normal\" | \"low\";\n  \n  // Deduplication (prevents duplicate processing if worker crashes)\n  messageDeduplicationId: string; // eventId + attemptNumber\n  \n  // Tracing\n  traceId: string;\n  \n  // Cached data to avoid DB lookup on every attempt\n  payload: {\n    eventType: string;\n    data: object;\n    metadata: Record<string, string>;\n  };\n}\n```\n\n**Queue Selection Strategy**:\n- **SQS + Lambda**: Best for AWS-native, serverless deployment\n- **RabbitMQ**: Best for on-prem or complex routing needs\n- **Kafka**: Best for high throughput (100K+ msgs/sec) with ordering guarantees\n\n### 5. Delivery Worker\n\n**Core Logic with Circuit Breaker and Improved Error Handling**:\n```typescript\nclass WebhookDeliveryWorker {\n  private readonly httpClient: HttpClient;\n  private readonly circuitBreakerRegistry: CircuitBreakerRegistry;\n  private readonly rateLimiterRegistry: RateLimiterRegistry;\n  \n  async processMessage(message: DeliveryMessage): Promise<void> {\n    const startTime = Date.now();\n    const traceId = message.traceId;\n    \n    logger.info({ traceId, eventId: message.eventId, attemptNumber: message.attemptNumber }, \n                \"Processing webhook delivery\");\n    \n    // 1. Load event and subscription (with caching)\n    const [event, subscription] = await Promise.all([\n      this.getEvent(message.eventId),\n      this.getSubscription(message.subscriptionId) // Cached for 60s\n    ]);\n    \n    // 2. Pre-delivery validation\n    if (!subscription || !subscription.active) {\n      await this.markEventAsCancelled(event, \"Subscription inactive or deleted\");\n      return;\n    }\n    \n    if (event.status !== 'queued' && event.status !== 'delivering') {\n      logger.warn({ traceId, eventId: event.id, status: event.status }, \n                   \"Event no longer in deliverable state, skipping\");\n      return; // Prevents duplicate processing\n    }\n    \n    // 3. Check circuit breaker\n    const circuitBreaker = this.circuitBreakerRegistry.get(subscription.id);\n    if (circuitBreaker.isOpen()) {\n      logger.warn({ traceId, subscriptionId: subscription.id }, \n                   \"Circuit breaker OPEN, moving to retry queue\");\n      \n      await this.scheduleRetry(event, message, {\n        errorType: 'circuit_open',\n        skipAttemptIncrement: true // Don't count this as a delivery attempt\n      });\n      return;\n    }\n    \n    // 4. Acquire rate limit token\n    const rateLimiter = this.rateLimiterRegistry.get(subscription.id);\n    const rateLimitAcquired = await rateLimiter.tryAcquire(\n      subscription.rateLimitConfig.maxRequestsPerSecond,\n      subscription.rateLimitConfig.maxConcurrentRequests\n    );\n    \n    if (!rateLimitAcquired) {\n      // Rate limited, retry in 1 second without incrementing attempt count\n      await this.scheduleRetry(event, message, {\n        errorType: 'rate_limited',\n        skipAttemptIncrement: true,\n        fixedDelayMs: 1000\n      });\n      return;\n    }\n    \n    // 5. Mark as delivering (optimistic locking to prevent double delivery)\n    const updated = await db.updateEventWithLock(event.id, {\n      status: 'delivering',\n      last_attempt_at: new Date(),\n      attempt_count: event.attempt_count + 1\n    }, { expectedStatus: ['queued', 'delivering'] });\n    \n    if (!updated) {\n      logger.warn({ traceId, eventId: event.id }, \n                   \"Failed to acquire event lock, another worker may have claimed it\");\n      return; // Another worker is processing this event\n    }\n    \n    let deliveryResult: DeliveryResult;\n    \n    try {\n      // 6. Prepare and execute delivery\n      const request = this.buildRequest(event, subscription, message.attemptNumber);\n      \n      // 7. Execute with timeout and retries at HTTP level (for transient network errors)\n      deliveryResult = await this.executeDeliveryWithTimeout(\n        subscription.url,\n        request,\n        subscription.deliveryConfig.timeoutMs,\n        traceId\n      );\n      \n      // 8. Record successful attempt\n      await this.recordAttempt(event, message.attemptNumber, deliveryResult);\n      \n      // 9. Handle response\n      if (this.isSuccessResponse(deliveryResult)) {\n        await this.handleSuccessfulDelivery(event, subscription, deliveryResult, circuitBreaker);\n      } else {\n        await this.handleFailedDelivery(event, subscription, message, deliveryResult, circuitBreaker);\n      }\n      \n    } catch (error) {\n      // 10. Handle catastrophic failure (network error, timeout, etc.)\n      deliveryResult = {\n        success: false,\n        error: error,\n        errorType: this.classifyError(error),\n        responseTimeMs: Date.now() - startTime\n      };\n      \n      await this.recordAttempt(event, message.attemptNumber, deliveryResult);\n      await this.handleFailedDelivery(event, subscription, message, deliveryResult, circuitBreaker);\n      \n    } finally {\n      // 11. Release rate limit token\n      rateLimiter.release();\n      \n      // 12. Emit metrics\n      this.emitMetrics(subscription.id, deliveryResult, Date.now() - startTime);\n    }\n  }\n  \n  private async executeDeliveryWithTimeout(\n    url: string,\n    request: WebhookRequest,\n    timeoutMs: number,\n    traceId: string\n  ): Promise<DeliveryResult> {\n    const controller = new AbortController();\n    const timeoutHandle = setTimeout(() => controller.abort(), timeoutMs);\n    \n    try {\n      const response = await this.httpClient.post(url, request.body, {\n        headers: request.headers,\n        signal: controller.signal,\n        // Follow redirects (max 3)\n        maxRedirects: 3,\n        // Disable keep-alive for initial implementation (can enable later for perf)\n        keepAlive: false,\n        // Validate SSL certificates\n        rejectUnauthorized: true\n      });\n      \n      return {\n        success: this.isSuccessStatus(response.status),\n        statusCode: response.status,\n        responseHeaders: response.headers,\n        responseBody: this.truncateResponseBody(response.data),\n        responseTimeMs: response.duration,\n        request: request\n      };\n      \n    } catch (error) {\n      throw new DeliveryError(this.classifyError(error), error.message, error);\n    } finally {\n      clearTimeout(timeoutHandle);\n    }\n  }\n  \n  private classifyError(error: any): string {\n    if (error.name === 'AbortError') return 'timeout';\n    if (error.code === 'ECONNREFUSED') return 'connection_refused';\n    if (error.code === 'ENOTFOUND') return 'dns_error';\n    if (error.code === 'ECONNRESET') return 'connection_reset';\n    if (error.code === 'ETIMEDOUT') return 'timeout';\n    if (error.code === 'DEPTH_ZERO_SELF_SIGNED_CERT') return 'ssl_error';\n    return 'unknown_error';\n  }\n  \n  private async handleSuccessfulDelivery(\n    event: WebhookEvent,\n    subscription: WebhookSubscription,\n    result: DeliveryResult,\n    circuitBreaker: CircuitBreaker\n  ): Promise<void> {\n    // Mark event as delivered\n    await db.updateEvent(event.id, {\n      status: 'delivered',\n      delivered_at: new Date()\n    });\n    \n    // Record success in circuit breaker\n    circuitBreaker.recordSuccess();\n    \n    logger.info({ \n      eventId: event.id, \n      subscriptionId: subscription.id,\n      attemptNumber: event.attempt_count + 1,\n      responseTimeMs: result.responseTimeMs\n    }, \"Webhook delivered successfully\");\n  }\n  \n  private async handleFailedDelivery(\n    event: WebhookEvent,\n    subscription: WebhookSubscription,\n    message: DeliveryMessage,\n    result: DeliveryResult,\n    circuitBreaker: CircuitBreaker\n  ): Promise<void> {\n    const isRetryable = this.isRetryableFailure(result, subscription);\n    \n    // Record failure in circuit breaker\n    circuitBreaker.recordFailure();\n    \n    if (!isRetryable) {\n      // Non-retryable error (e.g., 4xx), move to dead letter immediately\n      await this.moveToDeadLetter(event, result, \"Non-retryable error\");\n      await db.updateEvent(event.id, {\n        status: 'dead_letter',\n        failed_at: new Date()\n      });\n      \n      logger.error({\n        eventId: event.id,\n        subscriptionId: subscription.id,\n        errorType: result.errorType,\n        statusCode: result.statusCode\n      }, \"Non-retryable delivery failure\");\n      \n      return;\n    }\n    \n    // Schedule retry\n    await this.scheduleRetry(event, message, result);\n  }\n  \n  private async scheduleRetry(\n    event: WebhookEvent,\n    message: DeliveryMessage,\n    failureContext: any\n  ): Promise<void> {\n    const subscription = await this.getSubscription(event.subscription_id);\n    \n    // Skip increment if this is a rate limit or circuit breaker delay\n    const nextAttempt = failureContext.skipAttemptIncrement \n      ? message.attemptNumber \n      : message.attemptNumber + 1;\n    \n    if (nextAttempt > subscription.deliveryConfig.retryStrategy.maxAttempts) {\n      // Exhausted retries, move to dead letter\n      await this.moveToDeadLetter(event, failureContext, \"Max retries exceeded\");\n      await db.updateEvent(event.id, {\n        status: 'dead_letter',\n        failed_at: new Date()\n      });\n      \n      logger.error({\n        eventId: event.id,\n        subscriptionId: subscription.id,\n        attempts: nextAttempt\n      }, \"Exhausted retry attempts, moved to dead letter\");\n      \n      return;\n    }\n    \n    // Calculate retry delay\n    const delay = failureContext.fixedDelayMs || this.calculateBackoff(\n      subscription.deliveryConfig.retryStrategy,\n      nextAttempt\n    );\n    \n    const nextAttemptTime = new Date(Date.now() + delay);\n    \n    // Update event status\n    await db.updateEvent(event.id, {\n      status: 'queued',\n      next_attempt_at: nextAttemptTime\n    });\n    \n    // Enqueue retry message\n    await messageQueue.publish('webhook-retry-queue', {\n      ...message,\n      attemptNumber: nextAttempt,\n      scheduledFor: nextAttemptTime\n    }, { \n      delayMs: delay,\n      messageDeduplicationId: `${event.id}-${nextAttempt}`\n    });\n    \n    logger.info({\n      eventId: event.id,\n      attemptNumber: nextAttempt,\n      retryInMs: delay\n    }, \"Scheduled retry\");\n  }\n  \n  private calculateBackoff(strategy: RetryStrategy, attempt: number): number {\n    let delay: number;\n    \n    switch (strategy.backoffType) {\n      case 'exponential':\n        delay = strategy.initialDelayMs * Math.pow(strategy.multiplier || 2, attempt - 1);\n        break;\n      case 'linear':\n        delay = strategy.initialDelayMs * attempt;\n        break;\n      case 'fixed':\n        delay = strategy.initialDelayMs;\n        break;\n    }\n    \n    // Apply jitter (\u00b125%) to prevent thundering herd\n    const jitter = delay * 0.25 * (Math.random() * 2 - 1);\n    delay += jitter;\n    \n    // Cap at max delay\n    return Math.min(delay, strategy.maxDelayMs);\n  }\n  \n  private isSuccessResponse(result: DeliveryResult): boolean {\n    return result.success && result.statusCode >= 200 && result.statusCode < 300;\n  }\n  \n  private isRetryableFailure(result: DeliveryResult, subscription: WebhookSubscription): boolean {\n    // Network errors are always retryable\n    if (result.errorType && result.errorType !== 'http_error') {\n      return true;\n    }\n    \n    // Check if status code is in retryable list\n    const retryableStatus = subscription.deliveryConfig.retryStrategy.retryableStatusCodes;\n    return retryableStatus.includes(result.statusCode);\n  }\n  \n  private buildRequest(\n    event: WebhookEvent, \n    subscription: WebhookSubscription,\n    attemptNumber: number\n  ): WebhookRequest {\n    const body = JSON.stringify({\n      id: event.id,\n      type: event.event_type,\n      data: event.payload,\n      metadata: event.metadata,\n      timestamp: event.created_at.toISOString()\n    });\n    \n    // Generate HMAC signature with timestamp to prevent replay attacks\n    const timestamp = Math.floor(Date.now() / 1000);\n    const signaturePayload = `${timestamp}.${body}`;\n    const signature = this.generateSignature(\n      signaturePayload,\n      subscription.deliveryConfig.signingSecret,\n      subscription.deliveryConfig.signingAlgorithm\n    );\n    \n    return {\n      body: body,\n      headers: {\n        'Content-Type': 'application/json',\n        'User-Agent': 'WebhookDeliverySystem/1.0',\n        'X-Webhook-Signature': signature,\n        'X-Webhook-Signature-Algorithm': subscription.deliveryConfig.signingAlgorithm,\n        'X-Webhook-Timestamp': timestamp.toString(),\n        'X-Webhook-Event-Id': event.id,\n        'X-Webhook-Event-Type': event.event_type,\n        'X-Webhook-Attempt': attemptNumber.toString(),\n        'X-Webhook-Subscription-Id': subscription.id,\n        ...subscription.deliveryConfig.headers // Custom headers last (can't override security headers)\n      }\n    };\n  }\n  \n  private generateSignature(payload: string, secret: string, algorithm: string): string {\n    return crypto\n      .createHmac(algorithm, secret)\n      .update(payload)\n      .digest('hex');\n  }\n  \n  private truncateResponseBody(body: string): string {\n    const MAX_SIZE = 10240; // 10KB\n    return body.length > MAX_SIZE ? body.substring(0, MAX_SIZE) + '...[truncated]' : body;\n  }\n}\n```\n\n### 6. Circuit Breaker Implementation\n\n```typescript\nclass CircuitBreaker {\n  private state: 'closed' | 'open' | 'half_open' = 'closed';\n  private failureCount = 0;\n  private successCount = 0;\n  private openedAt: Date | null = null;\n  private halfOpenedAt: Date | null = null;\n  \n  constructor(\n    private subscriptionId: string,\n    private config: CircuitBreakerConfig,\n    private stateStore: CircuitBreakerStateStore // Redis + DB\n  ) {}\n  \n  async recordSuccess(): Promise<void> {\n    if (this.state === 'half_open') {\n      this.successCount++;\n      \n      if (this.successCount >= this.config.successThreshold) {\n        await this.close();\n        logger.info({ subscriptionId: this.subscriptionId }, \"Circuit breaker CLOSED\");\n      }\n    } else if (this.state === 'closed') {\n      // Reset failure count on success\n      this.failureCount = 0;\n    }\n    \n    await this.persist();\n  }\n  \n  async recordFailure(): Promise<void> {\n    if (this.state === 'half_open') {\n      // Failure during half-open, go back to open\n      await this.open();\n      logger.warn({ subscriptionId: this.subscriptionId }, \"Circuit breaker reopened due to failure in half-open state\");\n      return;\n    }\n    \n    if (this.state === 'closed') {\n      this.failureCount++;\n      \n      if (this.failureCount >= this.config.failureThreshold) {\n        await this.open();\n        logger.error({ subscriptionId: this.subscriptionId, failures: this.failureCount }, \n                     \"Circuit breaker OPENED due to consecutive failures\");\n      }\n    }\n    \n    await this.persist();\n  }\n  \n  isOpen(): boolean {\n    if (this.state === 'open') {\n      // Check if we should transition to half-open\n      const elapsed = Date.now() - this.openedAt!.getTime();\n      if (elapsed >= this.config.openTimeoutMs) {\n        this.halfOpen();\n        return false; // Allow one request through\n      }\n      return true;\n    }\n    \n    return false;\n  }\n  \n  private async open(): Promise<void> {\n    this.state = 'open';\n    this.openedAt = new Date();\n    this.failureCount = 0;\n    await this.persist();\n    \n    // Schedule automatic transition to half-open\n    setTimeout(() => this.halfOpen(), this.config.openTimeoutMs);\n  }\n  \n  private async halfOpen(): Promise<void> {\n    this.state = 'half_open';\n    this.halfOpenedAt = new Date();\n    this.successCount = 0;\n    await this.persist();\n    \n    logger.info({ subscriptionId: this.subscriptionId }, \"Circuit breaker transitioned to HALF-OPEN\");\n  }\n  \n  private async close(): Promise<void> {\n    this.state = 'closed';\n    this.failureCount = 0;\n    this.successCount = 0;\n    this.openedAt = null;\n    this.halfOpenedAt = null;\n    await this.persist();\n  }\n  \n  private async persist(): Promise<void> {\n    await this.stateStore.save(this.subscriptionId, {\n      state: this.state,\n      failureCount: this.failureCount,\n      successCount: this.successCount,\n      openedAt: this.openedAt,\n      halfOpenedAt: this.halfOpenedAt\n    });\n  }\n}\n```\n\n### 7. Outbox Processor (Prevents Message Loss)\n\n```typescript\nclass OutboxProcessor {\n  async run(): Promise<void> {\n    while (true) {\n      try {\n        // Fetch unpublished messages\n        const messages = await db.query(`\n          SELECT * FROM outbox\n          WHERE NOT published\n          ORDER BY created_at\n          LIMIT 1000\n          FOR UPDATE SKIP LOCKED\n        `);\n        \n        for (const msg of messages) {\n          try {\n            // Publish to queue\n            await messageQueue.publish(msg.queue_name, msg.payload, {\n              messageDeduplicationId: `${msg.event_id}-${msg.payload.attemptNumber}`\n            });\n            \n            // Mark as published\n            await db.update('outbox', msg.id, {\n              published: true,\n              published_at: new Date()\n            });\n            \n          } catch (error) {\n            logger.error({ outboxId: msg.id, error }, \"Failed to publish message from outbox\");\n            // Will retry on next iteration\n          }\n        }\n        \n        // Clean up old published messages (retention: 7 days)\n        await db.query(`\n          DELETE FROM outbox\n          WHERE published AND published_at < NOW() - INTERVAL '7 days'\n        `);\n        \n        await sleep(1000); // Poll every second\n        \n      } catch (error) {\n        logger.error({ error }, \"Outbox processor error\");\n        await sleep(5000);\n      }\n    }\n  }\n}\n```\n\n## Error Handling Strategy\n\n### HTTP Status Code Handling (Improved)\n\n| Status Code | Action | Retry? | Reason |\n|-------------|--------|--------|--------|\n| 2xx | Mark delivered | No | Success |\n| 3xx | Follow redirect (max 3) | No | Redirect handled automatically |\n| 400, 401, 403, 404, 405, 410, 422 | Dead letter immediately | No | Client error, won't fix with retry |\n| 408 | Retry with backoff | Yes | Request timeout |\n| 409, 412 | Dead letter immediately | No | Conflict/precondition failed |\n| 429 | Retry with exponential backoff | Yes | Rate limited |\n| 5xx | Retry with backoff | Yes | Server error |\n| Network timeout | Retry with backoff | Yes | May be transient |\n| DNS error | Retry with backoff | Yes | May be transient DNS issue |\n| Connection refused | Retry with backoff | Yes | Service may be restarting |\n| SSL errors | Dead letter immediately | No | Configuration issue |\n\n### Data Loss Prevention Guarantees\n\n1. **At-Least-Once Delivery**: Every accepted event will be delivered at least once (may have duplicates due to retries)\n2. **Transactional Outbox**: Events are persisted before queuing, preventing loss if queue is unavailable\n3. **Optimistic Locking**: Prevents duplicate processing by multiple workers\n4. **Idempotency Keys**: Prevents duplicate ingestion of same event\n5. **Message Deduplication**: Queue-level deduplication prevents processing same message twice\n\n## Observability & Monitoring\n\n### Metrics (Prometheus-compatible)\n```typescript\ninterface WebhookMetrics {\n  // Throughput\n  events_ingested_total: Counter<{ status: \"accepted\" | \"duplicate\" | \"rejected\" }>;\n  events_delivered_total: Counter<{ subscription_id: string }>;\n  events_failed_total: Counter<{ subscription_id: string, error_type: string, status_code: string }>;\n  \n  // Latency (critical for SLA monitoring)\n  delivery_duration_seconds: Histogram<{ subscription_id: string, status: \"success\" | \"failure\" }>;\n  queue_wait_time_seconds: Histogram<{ queue_name: string }>;\n  ingestion_duration_seconds: Histogram;\n  \n  // Retry tracking\n  retry_attempts_total: Counter<{ subscription_id: string, attempt_number: string }>;\n  dead_letter_events_total: Counter<{ subscription_id: string, reason: string }>;\n  \n  // Subscription health\n  subscription_success_rate: Gauge<{ subscription_id: string }>;\n  subscription_error_rate: Gauge<{ subscription_id: string }>;\n  circuit_breaker_state: Gauge<{ subscription_id: string, state: \"closed\" | \"open\" | \"half_open\" }>;\n  \n  // Queue depth (critical for capacity planning)\n  queue_depth: Gauge<{ queue_name: string }>;\n  queue_age_seconds: Gauge<{ queue_name: string }>; // Age of oldest message\n  \n  // Worker health\n  worker_active_deliveries: Gauge<{ worker_id: string }>;\n  worker_processing_rate: Counter<{ worker_id: string }>;\n}\n```\n\n### Structured Logging\n```typescript\ninterface DeliveryLog {\n  timestamp: string;\n  level: \"debug\" | \"info\" | \"warn\" | \"error\";\n  eventId: string;\n  subscriptionId: string;\n  organizationId: string;\n  attemptNumber: number;\n  \n  // Contextual data\n  requestUrl: string;\n  responseStatus?: number;\n  responseTimeMs?: number;\n  errorType?: string;\n  errorMessage?: string;\n  \n  // Tracing (OpenTelemetry compatible)\n  traceId: string;\n  spanId: string;\n  parentSpanId?: string;\n  \n  // Business context\n  eventType: string;\n  circuitBreakerState?: string;\n}\n```\n\n### Alerting Rules (PagerDuty/OpsGenie)\n\n**Critical (Page Immediately)**:\n- Dead letter queue size > 10,000 (sustained for 5 minutes)\n- Overall delivery error rate > 10% (5 minute window)\n- Queue depth growing at >1000 msgs/min for 10 minutes (worker lag)\n- Outbox depth > 50,000 (queue publishing failure)\n\n**Warning (Slack/Email)**:\n- Subscription error rate > 50% for single subscription (5 minutes)\n- Circuit breaker open for > 15 minutes\n- Average delivery latency > 30 seconds (p95)\n- Worker crash rate > 3 restarts/hour\n\n**Info**:\n- Circuit breaker state changes\n- Subscription activated/deactivated\n- Dead letter event replayed\n\n## Security Considerations\n\n### Request Signing (Improved)\n```typescript\n// Signature format: timestamp.payload\n// Prevents replay attacks (timestamp validation)\n// Customer verification code:\n\nfunction verifyWebhook(request: Request, secret: string): boolean {\n  const signature = request.headers['x-webhook-signature'];\n  const timestamp = request.headers['x-webhook-timestamp'];\n  const body = request.body;\n  \n  // Reject old requests (prevent replay attacks)\n  const age = Date.now() / 1000 - parseInt(timestamp);\n  if (age > 300) { // 5 minute window\n    throw new Error('Webhook timestamp too old');\n  }\n  \n  // Verify signature\n  const payload = `${timestamp}.${body}`;\n  const expectedSignature = crypto\n    .createHmac('sha256', secret)\n    .update(payload)\n    .digest('hex');\n  \n  return crypto.timingSafeEqual(\n    Buffer.from(signature),\n    Buffer.from(expectedSignature)\n  );\n}\n```\n\n### Rate Limiting (Token Bucket Algorithm)\n```typescript\nclass TokenBucketRateLimiter {\n  private tokens: number;\n  private lastRefill: number;\n  \n  constructor(\n    private maxTokens: number,\n    private refillRate: number // tokens per second\n  ) {\n    this.tokens = maxTokens;\n    this.lastRefill = Date.now();\n  }\n  \n  async tryAcquire(): Promise<boolean> {\n    this.refill();\n    \n    if (this.tokens >= 1) {\n      this.tokens -= 1;\n      return true;\n    }\n    \n    return false;\n  }\n  \n  private refill(): void {\n    const now = Date.now();\n    const elapsed = (now - this.lastRefill) / 1000;\n    const tokensToAdd = elapsed * this.refillRate;\n    \n    this.tokens = Math.min(this.maxTokens, this.tokens + tokensToAdd);\n    this.lastRefill = now;\n  }\n}\n```\n\n### Data Privacy\n- Encrypt sensitive payload fields at rest (AES-256)\n- PII redaction in logs (email, phone, SSN patterns)\n- TLS 1.3 for all webhook deliveries\n- Option to disable response body logging per subscription\n\n## Scalability Considerations\n\n### Horizontal Scaling\n\n**Worker Scaling**:\n- Kubernetes HPA based on queue depth metric\n- Target: <1000 messages per worker instance\n- Auto-scale up to 100 workers (adjust based on load testing)\n\n**Database Scaling**:\n- Read replicas for dashboard queries\n- Partition tables by date (monthly partitions)\n- Archive old events to cold storage (S3/GCS) after 90 days\n\n**Queue Scaling**:\n- Use multiple queue partitions (sharded by subscription_id)\n- Enable queue compression for large payloads\n\n### Performance Optimizations\n\n1. **Connection Pooling**: Reuse HTTP connections to frequently-hit endpoints\n2. **Subscription Caching**: Cache subscription configs in Redis (60s TTL)\n3. **Batch Database Operations**: Use `INSERT ... ON CONFLICT` for idempotency checks\n4. **Async Logging**: Buffer logs and flush in batches\n5. **Worker Concurrency**: Process multiple messages per worker (default: 10 concurrent)\n\n### Capacity Planning\n\n**Throughput Targets**:\n- 100,000 webhooks/second ingestion\n- 50,000 webhooks/second delivery (accounting for retries)\n- <100ms p99 ingestion latency\n- <5s p95 end-to-end delivery latency (first attempt)\n\n**Resource Estimates** (for 100K/sec):\n- Workers: 200 instances (500 webhooks/sec per instance)\n- Database: 4 vCPU, 16GB RAM (Postgres)\n- Queue: 1000 partitions (Kafka) or 100 SQS queues\n- Redis: 8GB (for caching + rate limiting)\n\n## What I Improved\n\n### 1. **Data Loss Prevention**\n- **Added transactional outbox pattern**: Ensures events are never lost even if message queue is temporarily unavailable. The architect's design had a race condition where events could be persisted to DB but fail to enqueue.\n- **Optimistic locking**: Added status checking before marking as \"delivering\" to prevent duplicate processing by multiple workers.\n- **Idempotency enforcement**: Made idempotencyKey REQUIRED (not optional) and added Redis caching for fast duplicate detection.\n\n### 2. **Circuit Breaker Pattern**\n- **Added comprehensive circuit breaker implementation**: Prevents wasting resources on consistently failing endpoints. This was mentioned in \"Open Questions\" but not implemented.\n- **State transitions**: Closed \u2192 Open \u2192 Half-Open \u2192 Closed with configurable thresholds.\n- **Persistent state**: Store circuit breaker state in both Redis (fast) and DB (recovery after restart).\n\n### 3. **Error Classification and Retry Logic**\n- **More granular error classification**: Network errors (DNS, connection refused, timeouts) vs HTTP errors vs SSL errors.\n- **Non-retryable errors**: Immediately dead-letter 4xx errors (except 408, 429) to avoid wasting retry attempts on permanent failures.\n- **SSL error handling**: Added specific handling for certificate errors (non-retryable).\n\n### 4. **Security Enhancements**\n- **Timestamp-based signatures**: Added timestamp to signature payload to prevent replay attacks (5-minute window).\n- **Signature algorithm flexibility**: Support both SHA256 and SHA512.\n- **Header protection**: Custom headers can't override security headers.\n\n### 5. **Operational Excellence**\n- **Outbox processor**: Separate background process to handle queue publishing, ensuring no messages are lost due to queue unavailability.\n- **Message deduplication**: Added messageDeduplicationId at queue level to prevent duplicate processing.\n- **Better indexing**: Added partial indexes and covering indexes for common query patterns.\n- **Database partitioning**: Added partition_date column for time-based partitioning (improves query performance and enables archival).\n\n### 6. **Observability Improvements**\n- **Queue age metric**: Added tracking of oldest message age (critical for detecting worker lag).\n- **Worker-level metrics**: Track per-worker processing rate and active deliveries.\n- **Structured trace IDs**: OpenTelemetry-compatible tracing for end-to-end request tracking.\n- **Better alerting thresholds**: More specific alert conditions with severity levels.\n\n### 7. **Scalability Improvements**\n- **Rate limiter implementation**: Added actual token bucket algorithm implementation (not just interface).\n- **Worker concurrency**: Each worker processes multiple messages concurrently (10 by default).\n- **Subscription caching**: Cache frequently-accessed subscription configs to reduce DB load.\n\n## What I Kept\n\n- **Overall architecture**: The message queue-based design with retry queues and dead letter queue is solid.\n- **Database schema**: Well-designed event and attempt tracking tables.\n- **Exponential backoff with jitter**: Correct approach to prevent thundering herd.\n- **HMAC signing**: Industry-standard webhook security.\n- **Subscription-based configuration**: Flexible per-subscription retry and rate limiting config.\n\n## Remaining Concerns\n\n### 1. **Ordering Guarantees Trade-off**\nThe design supports optional ordering per subscription, but enforcing strict ordering significantly reduces throughput (can't parallelize deliveries). For 100K/sec target, we may need to default to unordered delivery.\n\n**Recommendation**: Default to `guaranteeOrder: false`, and clearly document that ordered delivery has ~10x throughput penalty.\n\n### 2. **Database as Bottleneck**\nAt 100K/sec ingestion, we're writing ~8.6M events/day. Even with partitioning, the database may become a bottleneck.\n\n**Mitigation options**:\n- Use time-series database (TimescaleDB) instead of vanilla Postgres\n- Implement write-through caching for event status\n- Consider event sourcing pattern with append-only log\n\n### 3. **Webhook Response Body Storage**\nStoring 10KB response bodies for millions of events will consume significant storage.\n\n**Recommendation**: Make response body storage configurable per subscription (default: disabled). Only store for debugging or compliance requirements.\n\n### 4. **Cold Start Problem**\nIf all workers crash simultaneously, the retry scheduler needs to catch up on millions of queued events.\n\n**Mitigation**: \n- Multiple retry scheduler instances with distributed locking\n- Priority processing for events with oldest next_attempt_at\n- Emergency mode: skip scheduling, let workers pull directly from DB\n\n## Convergence Status\n- **ITERATING**: This is the first review. The design addresses critical failure scenarios and scalability concerns, but needs validation on ordering guarantees and database scaling strategy.",
        "prompt_for_other": "Please review the following additions and provide feedback:\n\n1. **Transactional outbox pattern**: Does this add too much complexity, or is it necessary for zero data loss? Could we use queue-native transactions instead?\n\n2. **Circuit breaker implementation**: Should we make circuit breaker optional per subscription, or always-on? Some customers may prefer to control this at their end.\n\n3. **Database partitioning strategy**: Should we partition by time (monthly) or by subscription_id? Monthly is better for archival, but subscription-based is better for per-customer queries.\n\n4. **Ordering vs throughput**: How critical is event ordering for typical webhook use cases? Should we recommend against ordered delivery for high-volume scenarios?",
        "convergence_signal": "ITERATING",
        "raw_response": "## Design\n\n# Webhook Delivery System with Retries\n\n## Architecture Overview\n\nA distributed, scalable webhook delivery system that guarantees reliable event delivery through exponential backoff retries, dead-letter queues, circuit breakers, and comprehensive observability.\n\n### System Components\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Event Source   \u2502\n\u2502   (Producer)    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Ingestion API  \u2502\u2500\u2500\u2500\u2500\u2500\u25b6\u2502   Event Store    \u2502\n\u2502   (REST/gRPC)   \u2502      \u2502   (Database)     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Message Queue  \u2502\u2500\u2500\u2500\u2500\u2500\u25b6\u2502  Dead Letter Q   \u2502\n\u2502  (Primary)      \u2502      \u2502  (Failed Events) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Delivery Worker \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2502 Circuit Breaker  \u2502\n\u2502   (Scalable)    \u2502      \u2502    Registry      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Webhook Target  \u2502\n\u2502  (Customer)     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n## Core Components\n\n### 1. Ingestion API\n**Responsibility**: Accept webhook events from producers with deduplication and validation\n\n**Interface**:\n```typescript\ninterface IngestionAPI {\n  // Submit a webhook event for delivery\n  POST /v1/webhooks\n  \n  Request:\n  {\n    subscriptionId: string;      // Target webhook subscription\n    eventType: string;            // e.g., \"order.created\"\n    payload: object;              // Event data\n    idempotencyKey: string;       // REQUIRED - Prevent duplicates\n    metadata?: Record<string, string>;\n    priority?: \"high\" | \"normal\" | \"low\"; // Default: normal\n  }\n  \n  Response:\n  {\n    eventId: string;              // Unique event identifier\n    status: \"accepted\" | \"duplicate\" | \"rejected\";\n    queuedAt: timestamp;\n    reason?: string;              // For rejected/duplicate\n  }\n}\n```\n\n**Critical Implementation Details**:\n- **Idempotency**: Store idempotencyKey with 24-hour TTL in fast cache (Redis)\n- **Atomicity**: Use database transaction to persist event AND enqueue message\n- **Validation**: Reject events immediately if subscription is inactive or rate-limited\n- **Response Time**: Target <50ms p99 latency\n- **Backpressure**: Return 429 if queue depth exceeds threshold (prevents cascading failure)\n\n**Data Loss Prevention**:\n```typescript\nasync function ingestEvent(request: WebhookRequest): Promise<IngestResponse> {\n  // 1. Check idempotency FIRST (before any writes)\n  const cached = await redis.get(`idempotency:${request.idempotencyKey}`);\n  if (cached) {\n    return { status: 'duplicate', eventId: cached, queuedAt: null };\n  }\n  \n  // 2. Validate subscription exists and is active\n  const subscription = await db.getSubscription(request.subscriptionId);\n  if (!subscription || !subscription.active) {\n    return { status: 'rejected', reason: 'Invalid or inactive subscription' };\n  }\n  \n  // 3. BEGIN TRANSACTION - critical for data loss prevention\n  await db.transaction(async (tx) => {\n    // Insert event record\n    const event = await tx.insert('webhook_events', {\n      id: generateUUID(),\n      subscription_id: request.subscriptionId,\n      event_type: request.eventType,\n      payload: request.payload,\n      idempotency_key: request.idempotencyKey,\n      status: 'queued',\n      attempt_count: 0,\n      next_attempt_at: new Date(),\n      created_at: new Date()\n    });\n    \n    // Enqueue message (transactional outbox pattern)\n    await tx.insert('outbox', {\n      event_id: event.id,\n      queue_name: 'webhook-delivery-queue',\n      payload: { eventId: event.id, attemptNumber: 1 }\n    });\n    \n    // Cache idempotency key\n    await redis.setex(`idempotency:${request.idempotencyKey}`, 86400, event.id);\n    \n    return event;\n  });\n  \n  // 4. Outbox processor handles actual queue publishing asynchronously\n  // This ensures message is never lost even if queue is temporarily unavailable\n}\n```\n\n### 2. Subscription Management\n\n**Data Model**:\n```typescript\ninterface WebhookSubscription {\n  id: string;\n  organizationId: string;\n  url: string;                    // Target endpoint\n  eventTypes: string[];           // Subscribed events\n  active: boolean;\n  createdAt: timestamp;\n  updatedAt: timestamp;\n  \n  // Delivery configuration\n  deliveryConfig: {\n    timeoutMs: number;            // Default: 10000 (10s max)\n    retryStrategy: RetryStrategy;\n    headers?: Record<string, string>; // Custom headers\n    signingSecret: string;        // For HMAC signature\n    signingAlgorithm: \"sha256\" | \"sha512\"; // Default: sha256\n  };\n  \n  // Circuit breaker settings\n  circuitBreaker: {\n    enabled: boolean;             // Default: true\n    failureThreshold: number;     // Default: 10 consecutive failures\n    successThreshold: number;     // Default: 3 consecutive successes to close\n    halfOpenTimeoutMs: number;    // Default: 60000 (1 minute)\n    openTimeoutMs: number;        // Default: 300000 (5 minutes)\n  };\n  \n  // Rate limiting (prevents overwhelming customer endpoints)\n  rateLimitConfig: {\n    maxRequestsPerSecond: number; // Default: 100\n    maxConcurrentRequests: number; // Default: 10\n    burstAllowance?: number;      // Default: maxRequestsPerSecond * 2\n  };\n  \n  // Ordering guarantee\n  orderingConfig: {\n    guaranteeOrder: boolean;      // Default: false (allows parallelism)\n    orderingKey?: string;         // JSONPath to extract ordering key from payload\n  };\n}\n\ninterface RetryStrategy {\n  maxAttempts: number;            // Default: 5\n  backoffType: \"exponential\" | \"linear\" | \"fixed\";\n  initialDelayMs: number;         // Default: 1000\n  maxDelayMs: number;             // Default: 3600000 (1 hour)\n  multiplier?: number;            // For exponential: 2\n  retryableStatusCodes: number[]; // Default: [408, 429, 500, 502, 503, 504]\n}\n```\n\n### 3. Event Storage (Database)\n\n**Schema with Improved Indexing**:\n```sql\nCREATE TABLE webhook_events (\n  id UUID PRIMARY KEY,\n  subscription_id UUID NOT NULL,\n  event_type VARCHAR(255) NOT NULL,\n  payload JSONB NOT NULL,\n  idempotency_key VARCHAR(255) NOT NULL,\n  metadata JSONB,\n  status VARCHAR(50) NOT NULL, -- queued, delivering, delivered, failed, dead_letter, cancelled\n  \n  -- Delivery tracking\n  attempt_count INTEGER DEFAULT 0,\n  max_attempts INTEGER NOT NULL,\n  next_attempt_at TIMESTAMP,\n  last_attempt_at TIMESTAMP,\n  delivered_at TIMESTAMP,\n  failed_at TIMESTAMP,\n  \n  -- Timing\n  created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n  updated_at TIMESTAMP NOT NULL DEFAULT NOW(),\n  \n  -- Partitioning hint (for time-based partitioning)\n  partition_date DATE GENERATED ALWAYS AS (DATE(created_at)) STORED,\n  \n  -- Constraints\n  CONSTRAINT unique_idempotency_key UNIQUE (idempotency_key),\n  CONSTRAINT fk_subscription FOREIGN KEY (subscription_id) \n    REFERENCES webhook_subscriptions(id) ON DELETE CASCADE\n) PARTITION BY RANGE (partition_date);\n\n-- Critical indexes for performance\nCREATE INDEX idx_status_next_attempt ON webhook_events (status, next_attempt_at) \n  WHERE status IN ('queued', 'delivering'); -- Partial index for active events only\n\nCREATE INDEX idx_subscription_created ON webhook_events (subscription_id, created_at DESC);\n\nCREATE INDEX idx_subscription_status ON webhook_events (subscription_id, status)\n  INCLUDE (created_at, attempt_count); -- Covering index for dashboard queries\n\n-- Separate table for delivery attempts (append-only for performance)\nCREATE TABLE webhook_delivery_attempts (\n  id UUID PRIMARY KEY,\n  event_id UUID NOT NULL,\n  attempt_number INTEGER NOT NULL,\n  \n  -- Request details\n  request_url TEXT NOT NULL,\n  request_headers JSONB,\n  request_body_hash VARCHAR(64), -- Store hash instead of full body to save space\n  \n  -- Response details\n  response_status_code INTEGER,\n  response_headers JSONB,\n  response_body TEXT, -- Truncate to 10KB max\n  response_time_ms INTEGER,\n  \n  -- Error tracking\n  error_type VARCHAR(100), -- timeout, connection_refused, dns_error, http_error, circuit_open\n  error_message TEXT,\n  \n  attempted_at TIMESTAMP NOT NULL DEFAULT NOW(),\n  \n  CONSTRAINT fk_event FOREIGN KEY (event_id) \n    REFERENCES webhook_events(id) ON DELETE CASCADE\n) PARTITION BY RANGE (attempted_at);\n\n-- Index for querying attempts by event\nCREATE INDEX idx_event_attempts ON webhook_delivery_attempts (event_id, attempt_number DESC);\n\n-- Outbox table for reliable message publishing (transactional outbox pattern)\nCREATE TABLE outbox (\n  id BIGSERIAL PRIMARY KEY,\n  event_id UUID NOT NULL,\n  queue_name VARCHAR(255) NOT NULL,\n  payload JSONB NOT NULL,\n  published BOOLEAN DEFAULT FALSE,\n  created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n  published_at TIMESTAMP\n);\n\nCREATE INDEX idx_outbox_unpublished ON outbox (published, created_at) WHERE NOT published;\n\n-- Circuit breaker state (cached in Redis, persisted in DB for recovery)\nCREATE TABLE circuit_breaker_state (\n  subscription_id UUID PRIMARY KEY,\n  state VARCHAR(20) NOT NULL, -- closed, open, half_open\n  failure_count INTEGER DEFAULT 0,\n  success_count INTEGER DEFAULT 0,\n  last_failure_at TIMESTAMP,\n  opened_at TIMESTAMP,\n  half_opened_at TIMESTAMP,\n  updated_at TIMESTAMP NOT NULL DEFAULT NOW(),\n  \n  CONSTRAINT fk_subscription FOREIGN KEY (subscription_id)\n    REFERENCES webhook_subscriptions(id) ON DELETE CASCADE\n);\n```\n\n### 4. Message Queue Architecture\n\n**Queue Structure with Ordering Guarantees**:\n- **Primary Queue**: `webhook-delivery-queue`\n  - Partitioned by subscription_id for ordered subscriptions\n  - Messages include priority field for priority-based delivery\n  \n- **Delayed Retry Queue**: `webhook-retry-queue`\n  - Single queue with message visibility timeout (for SQS-style queues)\n  - OR delay exchanges (for RabbitMQ-style queues)\n  \n- **Dead Letter Queue**: `webhook-dead-letter-queue`\n  - Events that exhausted all retries\n  - Requires manual intervention or replay\n\n**Message Format**:\n```typescript\ninterface DeliveryMessage {\n  eventId: string;\n  subscriptionId: string;\n  attemptNumber: number;\n  scheduledFor: timestamp;\n  priority: \"high\" | \"normal\" | \"low\";\n  \n  // Deduplication (prevents duplicate processing if worker crashes)\n  messageDeduplicationId: string; // eventId + attemptNumber\n  \n  // Tracing\n  traceId: string;\n  \n  // Cached data to avoid DB lookup on every attempt\n  payload: {\n    eventType: string;\n    data: object;\n    metadata: Record<string, string>;\n  };\n}\n```\n\n**Queue Selection Strategy**:\n- **SQS + Lambda**: Best for AWS-native, serverless deployment\n- **RabbitMQ**: Best for on-prem or complex routing needs\n- **Kafka**: Best for high throughput (100K+ msgs/sec) with ordering guarantees\n\n### 5. Delivery Worker\n\n**Core Logic with Circuit Breaker and Improved Error Handling**:\n```typescript\nclass WebhookDeliveryWorker {\n  private readonly httpClient: HttpClient;\n  private readonly circuitBreakerRegistry: CircuitBreakerRegistry;\n  private readonly rateLimiterRegistry: RateLimiterRegistry;\n  \n  async processMessage(message: DeliveryMessage): Promise<void> {\n    const startTime = Date.now();\n    const traceId = message.traceId;\n    \n    logger.info({ traceId, eventId: message.eventId, attemptNumber: message.attemptNumber }, \n                \"Processing webhook delivery\");\n    \n    // 1. Load event and subscription (with caching)\n    const [event, subscription] = await Promise.all([\n      this.getEvent(message.eventId),\n      this.getSubscription(message.subscriptionId) // Cached for 60s\n    ]);\n    \n    // 2. Pre-delivery validation\n    if (!subscription || !subscription.active) {\n      await this.markEventAsCancelled(event, \"Subscription inactive or deleted\");\n      return;\n    }\n    \n    if (event.status !== 'queued' && event.status !== 'delivering') {\n      logger.warn({ traceId, eventId: event.id, status: event.status }, \n                   \"Event no longer in deliverable state, skipping\");\n      return; // Prevents duplicate processing\n    }\n    \n    // 3. Check circuit breaker\n    const circuitBreaker = this.circuitBreakerRegistry.get(subscription.id);\n    if (circuitBreaker.isOpen()) {\n      logger.warn({ traceId, subscriptionId: subscription.id }, \n                   \"Circuit breaker OPEN, moving to retry queue\");\n      \n      await this.scheduleRetry(event, message, {\n        errorType: 'circuit_open',\n        skipAttemptIncrement: true // Don't count this as a delivery attempt\n      });\n      return;\n    }\n    \n    // 4. Acquire rate limit token\n    const rateLimiter = this.rateLimiterRegistry.get(subscription.id);\n    const rateLimitAcquired = await rateLimiter.tryAcquire(\n      subscription.rateLimitConfig.maxRequestsPerSecond,\n      subscription.rateLimitConfig.maxConcurrentRequests\n    );\n    \n    if (!rateLimitAcquired) {\n      // Rate limited, retry in 1 second without incrementing attempt count\n      await this.scheduleRetry(event, message, {\n        errorType: 'rate_limited',\n        skipAttemptIncrement: true,\n        fixedDelayMs: 1000\n      });\n      return;\n    }\n    \n    // 5. Mark as delivering (optimistic locking to prevent double delivery)\n    const updated = await db.updateEventWithLock(event.id, {\n      status: 'delivering',\n      last_attempt_at: new Date(),\n      attempt_count: event.attempt_count + 1\n    }, { expectedStatus: ['queued', 'delivering'] });\n    \n    if (!updated) {\n      logger.warn({ traceId, eventId: event.id }, \n                   \"Failed to acquire event lock, another worker may have claimed it\");\n      return; // Another worker is processing this event\n    }\n    \n    let deliveryResult: DeliveryResult;\n    \n    try {\n      // 6. Prepare and execute delivery\n      const request = this.buildRequest(event, subscription, message.attemptNumber);\n      \n      // 7. Execute with timeout and retries at HTTP level (for transient network errors)\n      deliveryResult = await this.executeDeliveryWithTimeout(\n        subscription.url,\n        request,\n        subscription.deliveryConfig.timeoutMs,\n        traceId\n      );\n      \n      // 8. Record successful attempt\n      await this.recordAttempt(event, message.attemptNumber, deliveryResult);\n      \n      // 9. Handle response\n      if (this.isSuccessResponse(deliveryResult)) {\n        await this.handleSuccessfulDelivery(event, subscription, deliveryResult, circuitBreaker);\n      } else {\n        await this.handleFailedDelivery(event, subscription, message, deliveryResult, circuitBreaker);\n      }\n      \n    } catch (error) {\n      // 10. Handle catastrophic failure (network error, timeout, etc.)\n      deliveryResult = {\n        success: false,\n        error: error,\n        errorType: this.classifyError(error),\n        responseTimeMs: Date.now() - startTime\n      };\n      \n      await this.recordAttempt(event, message.attemptNumber, deliveryResult);\n      await this.handleFailedDelivery(event, subscription, message, deliveryResult, circuitBreaker);\n      \n    } finally {\n      // 11. Release rate limit token\n      rateLimiter.release();\n      \n      // 12. Emit metrics\n      this.emitMetrics(subscription.id, deliveryResult, Date.now() - startTime);\n    }\n  }\n  \n  private async executeDeliveryWithTimeout(\n    url: string,\n    request: WebhookRequest,\n    timeoutMs: number,\n    traceId: string\n  ): Promise<DeliveryResult> {\n    const controller = new AbortController();\n    const timeoutHandle = setTimeout(() => controller.abort(), timeoutMs);\n    \n    try {\n      const response = await this.httpClient.post(url, request.body, {\n        headers: request.headers,\n        signal: controller.signal,\n        // Follow redirects (max 3)\n        maxRedirects: 3,\n        // Disable keep-alive for initial implementation (can enable later for perf)\n        keepAlive: false,\n        // Validate SSL certificates\n        rejectUnauthorized: true\n      });\n      \n      return {\n        success: this.isSuccessStatus(response.status),\n        statusCode: response.status,\n        responseHeaders: response.headers,\n        responseBody: this.truncateResponseBody(response.data),\n        responseTimeMs: response.duration,\n        request: request\n      };\n      \n    } catch (error) {\n      throw new DeliveryError(this.classifyError(error), error.message, error);\n    } finally {\n      clearTimeout(timeoutHandle);\n    }\n  }\n  \n  private classifyError(error: any): string {\n    if (error.name === 'AbortError') return 'timeout';\n    if (error.code === 'ECONNREFUSED') return 'connection_refused';\n    if (error.code === 'ENOTFOUND') return 'dns_error';\n    if (error.code === 'ECONNRESET') return 'connection_reset';\n    if (error.code === 'ETIMEDOUT') return 'timeout';\n    if (error.code === 'DEPTH_ZERO_SELF_SIGNED_CERT') return 'ssl_error';\n    return 'unknown_error';\n  }\n  \n  private async handleSuccessfulDelivery(\n    event: WebhookEvent,\n    subscription: WebhookSubscription,\n    result: DeliveryResult,\n    circuitBreaker: CircuitBreaker\n  ): Promise<void> {\n    // Mark event as delivered\n    await db.updateEvent(event.id, {\n      status: 'delivered',\n      delivered_at: new Date()\n    });\n    \n    // Record success in circuit breaker\n    circuitBreaker.recordSuccess();\n    \n    logger.info({ \n      eventId: event.id, \n      subscriptionId: subscription.id,\n      attemptNumber: event.attempt_count + 1,\n      responseTimeMs: result.responseTimeMs\n    }, \"Webhook delivered successfully\");\n  }\n  \n  private async handleFailedDelivery(\n    event: WebhookEvent,\n    subscription: WebhookSubscription,\n    message: DeliveryMessage,\n    result: DeliveryResult,\n    circuitBreaker: CircuitBreaker\n  ): Promise<void> {\n    const isRetryable = this.isRetryableFailure(result, subscription);\n    \n    // Record failure in circuit breaker\n    circuitBreaker.recordFailure();\n    \n    if (!isRetryable) {\n      // Non-retryable error (e.g., 4xx), move to dead letter immediately\n      await this.moveToDeadLetter(event, result, \"Non-retryable error\");\n      await db.updateEvent(event.id, {\n        status: 'dead_letter',\n        failed_at: new Date()\n      });\n      \n      logger.error({\n        eventId: event.id,\n        subscriptionId: subscription.id,\n        errorType: result.errorType,\n        statusCode: result.statusCode\n      }, \"Non-retryable delivery failure\");\n      \n      return;\n    }\n    \n    // Schedule retry\n    await this.scheduleRetry(event, message, result);\n  }\n  \n  private async scheduleRetry(\n    event: WebhookEvent,\n    message: DeliveryMessage,\n    failureContext: any\n  ): Promise<void> {\n    const subscription = await this.getSubscription(event.subscription_id);\n    \n    // Skip increment if this is a rate limit or circuit breaker delay\n    const nextAttempt = failureContext.skipAttemptIncrement \n      ? message.attemptNumber \n      : message.attemptNumber + 1;\n    \n    if (nextAttempt > subscription.deliveryConfig.retryStrategy.maxAttempts) {\n      // Exhausted retries, move to dead letter\n      await this.moveToDeadLetter(event, failureContext, \"Max retries exceeded\");\n      await db.updateEvent(event.id, {\n        status: 'dead_letter',\n        failed_at: new Date()\n      });\n      \n      logger.error({\n        eventId: event.id,\n        subscriptionId: subscription.id,\n        attempts: nextAttempt\n      }, \"Exhausted retry attempts, moved to dead letter\");\n      \n      return;\n    }\n    \n    // Calculate retry delay\n    const delay = failureContext.fixedDelayMs || this.calculateBackoff(\n      subscription.deliveryConfig.retryStrategy,\n      nextAttempt\n    );\n    \n    const nextAttemptTime = new Date(Date.now() + delay);\n    \n    // Update event status\n    await db.updateEvent(event.id, {\n      status: 'queued',\n      next_attempt_at: nextAttemptTime\n    });\n    \n    // Enqueue retry message\n    await messageQueue.publish('webhook-retry-queue', {\n      ...message,\n      attemptNumber: nextAttempt,\n      scheduledFor: nextAttemptTime\n    }, { \n      delayMs: delay,\n      messageDeduplicationId: `${event.id}-${nextAttempt}`\n    });\n    \n    logger.info({\n      eventId: event.id,\n      attemptNumber: nextAttempt,\n      retryInMs: delay\n    }, \"Scheduled retry\");\n  }\n  \n  private calculateBackoff(strategy: RetryStrategy, attempt: number): number {\n    let delay: number;\n    \n    switch (strategy.backoffType) {\n      case 'exponential':\n        delay = strategy.initialDelayMs * Math.pow(strategy.multiplier || 2, attempt - 1);\n        break;\n      case 'linear':\n        delay = strategy.initialDelayMs * attempt;\n        break;\n      case 'fixed':\n        delay = strategy.initialDelayMs;\n        break;\n    }\n    \n    // Apply jitter (\u00b125%) to prevent thundering herd\n    const jitter = delay * 0.25 * (Math.random() * 2 - 1);\n    delay += jitter;\n    \n    // Cap at max delay\n    return Math.min(delay, strategy.maxDelayMs);\n  }\n  \n  private isSuccessResponse(result: DeliveryResult): boolean {\n    return result.success && result.statusCode >= 200 && result.statusCode < 300;\n  }\n  \n  private isRetryableFailure(result: DeliveryResult, subscription: WebhookSubscription): boolean {\n    // Network errors are always retryable\n    if (result.errorType && result.errorType !== 'http_error') {\n      return true;\n    }\n    \n    // Check if status code is in retryable list\n    const retryableStatus = subscription.deliveryConfig.retryStrategy.retryableStatusCodes;\n    return retryableStatus.includes(result.statusCode);\n  }\n  \n  private buildRequest(\n    event: WebhookEvent, \n    subscription: WebhookSubscription,\n    attemptNumber: number\n  ): WebhookRequest {\n    const body = JSON.stringify({\n      id: event.id,\n      type: event.event_type,\n      data: event.payload,\n      metadata: event.metadata,\n      timestamp: event.created_at.toISOString()\n    });\n    \n    // Generate HMAC signature with timestamp to prevent replay attacks\n    const timestamp = Math.floor(Date.now() / 1000);\n    const signaturePayload = `${timestamp}.${body}`;\n    const signature = this.generateSignature(\n      signaturePayload,\n      subscription.deliveryConfig.signingSecret,\n      subscription.deliveryConfig.signingAlgorithm\n    );\n    \n    return {\n      body: body,\n      headers: {\n        'Content-Type': 'application/json',\n        'User-Agent': 'WebhookDeliverySystem/1.0',\n        'X-Webhook-Signature': signature,\n        'X-Webhook-Signature-Algorithm': subscription.deliveryConfig.signingAlgorithm,\n        'X-Webhook-Timestamp': timestamp.toString(),\n        'X-Webhook-Event-Id': event.id,\n        'X-Webhook-Event-Type': event.event_type,\n        'X-Webhook-Attempt': attemptNumber.toString(),\n        'X-Webhook-Subscription-Id': subscription.id,\n        ...subscription.deliveryConfig.headers // Custom headers last (can't override security headers)\n      }\n    };\n  }\n  \n  private generateSignature(payload: string, secret: string, algorithm: string): string {\n    return crypto\n      .createHmac(algorithm, secret)\n      .update(payload)\n      .digest('hex');\n  }\n  \n  private truncateResponseBody(body: string): string {\n    const MAX_SIZE = 10240; // 10KB\n    return body.length > MAX_SIZE ? body.substring(0, MAX_SIZE) + '...[truncated]' : body;\n  }\n}\n```\n\n### 6. Circuit Breaker Implementation\n\n```typescript\nclass CircuitBreaker {\n  private state: 'closed' | 'open' | 'half_open' = 'closed';\n  private failureCount = 0;\n  private successCount = 0;\n  private openedAt: Date | null = null;\n  private halfOpenedAt: Date | null = null;\n  \n  constructor(\n    private subscriptionId: string,\n    private config: CircuitBreakerConfig,\n    private stateStore: CircuitBreakerStateStore // Redis + DB\n  ) {}\n  \n  async recordSuccess(): Promise<void> {\n    if (this.state === 'half_open') {\n      this.successCount++;\n      \n      if (this.successCount >= this.config.successThreshold) {\n        await this.close();\n        logger.info({ subscriptionId: this.subscriptionId }, \"Circuit breaker CLOSED\");\n      }\n    } else if (this.state === 'closed') {\n      // Reset failure count on success\n      this.failureCount = 0;\n    }\n    \n    await this.persist();\n  }\n  \n  async recordFailure(): Promise<void> {\n    if (this.state === 'half_open') {\n      // Failure during half-open, go back to open\n      await this.open();\n      logger.warn({ subscriptionId: this.subscriptionId }, \"Circuit breaker reopened due to failure in half-open state\");\n      return;\n    }\n    \n    if (this.state === 'closed') {\n      this.failureCount++;\n      \n      if (this.failureCount >= this.config.failureThreshold) {\n        await this.open();\n        logger.error({ subscriptionId: this.subscriptionId, failures: this.failureCount }, \n                     \"Circuit breaker OPENED due to consecutive failures\");\n      }\n    }\n    \n    await this.persist();\n  }\n  \n  isOpen(): boolean {\n    if (this.state === 'open') {\n      // Check if we should transition to half-open\n      const elapsed = Date.now() - this.openedAt!.getTime();\n      if (elapsed >= this.config.openTimeoutMs) {\n        this.halfOpen();\n        return false; // Allow one request through\n      }\n      return true;\n    }\n    \n    return false;\n  }\n  \n  private async open(): Promise<void> {\n    this.state = 'open';\n    this.openedAt = new Date();\n    this.failureCount = 0;\n    await this.persist();\n    \n    // Schedule automatic transition to half-open\n    setTimeout(() => this.halfOpen(), this.config.openTimeoutMs);\n  }\n  \n  private async halfOpen(): Promise<void> {\n    this.state = 'half_open';\n    this.halfOpenedAt = new Date();\n    this.successCount = 0;\n    await this.persist();\n    \n    logger.info({ subscriptionId: this.subscriptionId }, \"Circuit breaker transitioned to HALF-OPEN\");\n  }\n  \n  private async close(): Promise<void> {\n    this.state = 'closed';\n    this.failureCount = 0;\n    this.successCount = 0;\n    this.openedAt = null;\n    this.halfOpenedAt = null;\n    await this.persist();\n  }\n  \n  private async persist(): Promise<void> {\n    await this.stateStore.save(this.subscriptionId, {\n      state: this.state,\n      failureCount: this.failureCount,\n      successCount: this.successCount,\n      openedAt: this.openedAt,\n      halfOpenedAt: this.halfOpenedAt\n    });\n  }\n}\n```\n\n### 7. Outbox Processor (Prevents Message Loss)\n\n```typescript\nclass OutboxProcessor {\n  async run(): Promise<void> {\n    while (true) {\n      try {\n        // Fetch unpublished messages\n        const messages = await db.query(`\n          SELECT * FROM outbox\n          WHERE NOT published\n          ORDER BY created_at\n          LIMIT 1000\n          FOR UPDATE SKIP LOCKED\n        `);\n        \n        for (const msg of messages) {\n          try {\n            // Publish to queue\n            await messageQueue.publish(msg.queue_name, msg.payload, {\n              messageDeduplicationId: `${msg.event_id}-${msg.payload.attemptNumber}`\n            });\n            \n            // Mark as published\n            await db.update('outbox', msg.id, {\n              published: true,\n              published_at: new Date()\n            });\n            \n          } catch (error) {\n            logger.error({ outboxId: msg.id, error }, \"Failed to publish message from outbox\");\n            // Will retry on next iteration\n          }\n        }\n        \n        // Clean up old published messages (retention: 7 days)\n        await db.query(`\n          DELETE FROM outbox\n          WHERE published AND published_at < NOW() - INTERVAL '7 days'\n        `);\n        \n        await sleep(1000); // Poll every second\n        \n      } catch (error) {\n        logger.error({ error }, \"Outbox processor error\");\n        await sleep(5000);\n      }\n    }\n  }\n}\n```\n\n## Error Handling Strategy\n\n### HTTP Status Code Handling (Improved)\n\n| Status Code | Action | Retry? | Reason |\n|-------------|--------|--------|--------|\n| 2xx | Mark delivered | No | Success |\n| 3xx | Follow redirect (max 3) | No | Redirect handled automatically |\n| 400, 401, 403, 404, 405, 410, 422 | Dead letter immediately | No | Client error, won't fix with retry |\n| 408 | Retry with backoff | Yes | Request timeout |\n| 409, 412 | Dead letter immediately | No | Conflict/precondition failed |\n| 429 | Retry with exponential backoff | Yes | Rate limited |\n| 5xx | Retry with backoff | Yes | Server error |\n| Network timeout | Retry with backoff | Yes | May be transient |\n| DNS error | Retry with backoff | Yes | May be transient DNS issue |\n| Connection refused | Retry with backoff | Yes | Service may be restarting |\n| SSL errors | Dead letter immediately | No | Configuration issue |\n\n### Data Loss Prevention Guarantees\n\n1. **At-Least-Once Delivery**: Every accepted event will be delivered at least once (may have duplicates due to retries)\n2. **Transactional Outbox**: Events are persisted before queuing, preventing loss if queue is unavailable\n3. **Optimistic Locking**: Prevents duplicate processing by multiple workers\n4. **Idempotency Keys**: Prevents duplicate ingestion of same event\n5. **Message Deduplication**: Queue-level deduplication prevents processing same message twice\n\n## Observability & Monitoring\n\n### Metrics (Prometheus-compatible)\n```typescript\ninterface WebhookMetrics {\n  // Throughput\n  events_ingested_total: Counter<{ status: \"accepted\" | \"duplicate\" | \"rejected\" }>;\n  events_delivered_total: Counter<{ subscription_id: string }>;\n  events_failed_total: Counter<{ subscription_id: string, error_type: string, status_code: string }>;\n  \n  // Latency (critical for SLA monitoring)\n  delivery_duration_seconds: Histogram<{ subscription_id: string, status: \"success\" | \"failure\" }>;\n  queue_wait_time_seconds: Histogram<{ queue_name: string }>;\n  ingestion_duration_seconds: Histogram;\n  \n  // Retry tracking\n  retry_attempts_total: Counter<{ subscription_id: string, attempt_number: string }>;\n  dead_letter_events_total: Counter<{ subscription_id: string, reason: string }>;\n  \n  // Subscription health\n  subscription_success_rate: Gauge<{ subscription_id: string }>;\n  subscription_error_rate: Gauge<{ subscription_id: string }>;\n  circuit_breaker_state: Gauge<{ subscription_id: string, state: \"closed\" | \"open\" | \"half_open\" }>;\n  \n  // Queue depth (critical for capacity planning)\n  queue_depth: Gauge<{ queue_name: string }>;\n  queue_age_seconds: Gauge<{ queue_name: string }>; // Age of oldest message\n  \n  // Worker health\n  worker_active_deliveries: Gauge<{ worker_id: string }>;\n  worker_processing_rate: Counter<{ worker_id: string }>;\n}\n```\n\n### Structured Logging\n```typescript\ninterface DeliveryLog {\n  timestamp: string;\n  level: \"debug\" | \"info\" | \"warn\" | \"error\";\n  eventId: string;\n  subscriptionId: string;\n  organizationId: string;\n  attemptNumber: number;\n  \n  // Contextual data\n  requestUrl: string;\n  responseStatus?: number;\n  responseTimeMs?: number;\n  errorType?: string;\n  errorMessage?: string;\n  \n  // Tracing (OpenTelemetry compatible)\n  traceId: string;\n  spanId: string;\n  parentSpanId?: string;\n  \n  // Business context\n  eventType: string;\n  circuitBreakerState?: string;\n}\n```\n\n### Alerting Rules (PagerDuty/OpsGenie)\n\n**Critical (Page Immediately)**:\n- Dead letter queue size > 10,000 (sustained for 5 minutes)\n- Overall delivery error rate > 10% (5 minute window)\n- Queue depth growing at >1000 msgs/min for 10 minutes (worker lag)\n- Outbox depth > 50,000 (queue publishing failure)\n\n**Warning (Slack/Email)**:\n- Subscription error rate > 50% for single subscription (5 minutes)\n- Circuit breaker open for > 15 minutes\n- Average delivery latency > 30 seconds (p95)\n- Worker crash rate > 3 restarts/hour\n\n**Info**:\n- Circuit breaker state changes\n- Subscription activated/deactivated\n- Dead letter event replayed\n\n## Security Considerations\n\n### Request Signing (Improved)\n```typescript\n// Signature format: timestamp.payload\n// Prevents replay attacks (timestamp validation)\n// Customer verification code:\n\nfunction verifyWebhook(request: Request, secret: string): boolean {\n  const signature = request.headers['x-webhook-signature'];\n  const timestamp = request.headers['x-webhook-timestamp'];\n  const body = request.body;\n  \n  // Reject old requests (prevent replay attacks)\n  const age = Date.now() / 1000 - parseInt(timestamp);\n  if (age > 300) { // 5 minute window\n    throw new Error('Webhook timestamp too old');\n  }\n  \n  // Verify signature\n  const payload = `${timestamp}.${body}`;\n  const expectedSignature = crypto\n    .createHmac('sha256', secret)\n    .update(payload)\n    .digest('hex');\n  \n  return crypto.timingSafeEqual(\n    Buffer.from(signature),\n    Buffer.from(expectedSignature)\n  );\n}\n```\n\n### Rate Limiting (Token Bucket Algorithm)\n```typescript\nclass TokenBucketRateLimiter {\n  private tokens: number;\n  private lastRefill: number;\n  \n  constructor(\n    private maxTokens: number,\n    private refillRate: number // tokens per second\n  ) {\n    this.tokens = maxTokens;\n    this.lastRefill = Date.now();\n  }\n  \n  async tryAcquire(): Promise<boolean> {\n    this.refill();\n    \n    if (this.tokens >= 1) {\n      this.tokens -= 1;\n      return true;\n    }\n    \n    return false;\n  }\n  \n  private refill(): void {\n    const now = Date.now();\n    const elapsed = (now - this.lastRefill) / 1000;\n    const tokensToAdd = elapsed * this.refillRate;\n    \n    this.tokens = Math.min(this.maxTokens, this.tokens + tokensToAdd);\n    this.lastRefill = now;\n  }\n}\n```\n\n### Data Privacy\n- Encrypt sensitive payload fields at rest (AES-256)\n- PII redaction in logs (email, phone, SSN patterns)\n- TLS 1.3 for all webhook deliveries\n- Option to disable response body logging per subscription\n\n## Scalability Considerations\n\n### Horizontal Scaling\n\n**Worker Scaling**:\n- Kubernetes HPA based on queue depth metric\n- Target: <1000 messages per worker instance\n- Auto-scale up to 100 workers (adjust based on load testing)\n\n**Database Scaling**:\n- Read replicas for dashboard queries\n- Partition tables by date (monthly partitions)\n- Archive old events to cold storage (S3/GCS) after 90 days\n\n**Queue Scaling**:\n- Use multiple queue partitions (sharded by subscription_id)\n- Enable queue compression for large payloads\n\n### Performance Optimizations\n\n1. **Connection Pooling**: Reuse HTTP connections to frequently-hit endpoints\n2. **Subscription Caching**: Cache subscription configs in Redis (60s TTL)\n3. **Batch Database Operations**: Use `INSERT ... ON CONFLICT` for idempotency checks\n4. **Async Logging**: Buffer logs and flush in batches\n5. **Worker Concurrency**: Process multiple messages per worker (default: 10 concurrent)\n\n### Capacity Planning\n\n**Throughput Targets**:\n- 100,000 webhooks/second ingestion\n- 50,000 webhooks/second delivery (accounting for retries)\n- <100ms p99 ingestion latency\n- <5s p95 end-to-end delivery latency (first attempt)\n\n**Resource Estimates** (for 100K/sec):\n- Workers: 200 instances (500 webhooks/sec per instance)\n- Database: 4 vCPU, 16GB RAM (Postgres)\n- Queue: 1000 partitions (Kafka) or 100 SQS queues\n- Redis: 8GB (for caching + rate limiting)\n\n## What I Improved\n\n### 1. **Data Loss Prevention**\n- **Added transactional outbox pattern**: Ensures events are never lost even if message queue is temporarily unavailable. The architect's design had a race condition where events could be persisted to DB but fail to enqueue.\n- **Optimistic locking**: Added status checking before marking as \"delivering\" to prevent duplicate processing by multiple workers.\n- **Idempotency enforcement**: Made idempotencyKey REQUIRED (not optional) and added Redis caching for fast duplicate detection.\n\n### 2. **Circuit Breaker Pattern**\n- **Added comprehensive circuit breaker implementation**: Prevents wasting resources on consistently failing endpoints. This was mentioned in \"Open Questions\" but not implemented.\n- **State transitions**: Closed \u2192 Open \u2192 Half-Open \u2192 Closed with configurable thresholds.\n- **Persistent state**: Store circuit breaker state in both Redis (fast) and DB (recovery after restart).\n\n### 3. **Error Classification and Retry Logic**\n- **More granular error classification**: Network errors (DNS, connection refused, timeouts) vs HTTP errors vs SSL errors.\n- **Non-retryable errors**: Immediately dead-letter 4xx errors (except 408, 429) to avoid wasting retry attempts on permanent failures.\n- **SSL error handling**: Added specific handling for certificate errors (non-retryable).\n\n### 4. **Security Enhancements**\n- **Timestamp-based signatures**: Added timestamp to signature payload to prevent replay attacks (5-minute window).\n- **Signature algorithm flexibility**: Support both SHA256 and SHA512.\n- **Header protection**: Custom headers can't override security headers.\n\n### 5. **Operational Excellence**\n- **Outbox processor**: Separate background process to handle queue publishing, ensuring no messages are lost due to queue unavailability.\n- **Message deduplication**: Added messageDeduplicationId at queue level to prevent duplicate processing.\n- **Better indexing**: Added partial indexes and covering indexes for common query patterns.\n- **Database partitioning**: Added partition_date column for time-based partitioning (improves query performance and enables archival).\n\n### 6. **Observability Improvements**\n- **Queue age metric**: Added tracking of oldest message age (critical for detecting worker lag).\n- **Worker-level metrics**: Track per-worker processing rate and active deliveries.\n- **Structured trace IDs**: OpenTelemetry-compatible tracing for end-to-end request tracking.\n- **Better alerting thresholds**: More specific alert conditions with severity levels.\n\n### 7. **Scalability Improvements**\n- **Rate limiter implementation**: Added actual token bucket algorithm implementation (not just interface).\n- **Worker concurrency**: Each worker processes multiple messages concurrently (10 by default).\n- **Subscription caching**: Cache frequently-accessed subscription configs to reduce DB load.\n\n## What I Kept\n\n- **Overall architecture**: The message queue-based design with retry queues and dead letter queue is solid.\n- **Database schema**: Well-designed event and attempt tracking tables.\n- **Exponential backoff with jitter**: Correct approach to prevent thundering herd.\n- **HMAC signing**: Industry-standard webhook security.\n- **Subscription-based configuration**: Flexible per-subscription retry and rate limiting config.\n\n## Remaining Concerns\n\n### 1. **Ordering Guarantees Trade-off**\nThe design supports optional ordering per subscription, but enforcing strict ordering significantly reduces throughput (can't parallelize deliveries). For 100K/sec target, we may need to default to unordered delivery.\n\n**Recommendation**: Default to `guaranteeOrder: false`, and clearly document that ordered delivery has ~10x throughput penalty.\n\n### 2. **Database as Bottleneck**\nAt 100K/sec ingestion, we're writing ~8.6M events/day. Even with partitioning, the database may become a bottleneck.\n\n**Mitigation options**:\n- Use time-series database (TimescaleDB) instead of vanilla Postgres\n- Implement write-through caching for event status\n- Consider event sourcing pattern with append-only log\n\n### 3. **Webhook Response Body Storage**\nStoring 10KB response bodies for millions of events will consume significant storage.\n\n**Recommendation**: Make response body storage configurable per subscription (default: disabled). Only store for debugging or compliance requirements.\n\n### 4. **Cold Start Problem**\nIf all workers crash simultaneously, the retry scheduler needs to catch up on millions of queued events.\n\n**Mitigation**: \n- Multiple retry scheduler instances with distributed locking\n- Priority processing for events with oldest next_attempt_at\n- Emergency mode: skip scheduling, let workers pull directly from DB\n\n## Convergence Status\n- **ITERATING**: This is the first review. The design addresses critical failure scenarios and scalability concerns, but needs validation on ordering guarantees and database scaling strategy.\n\nPROMPT_FOR_ARCHITECT:\nPlease review the following additions and provide feedback:\n\n1. **Transactional outbox pattern**: Does this add too much complexity, or is it necessary for zero data loss? Could we use queue-native transactions instead?\n\n2. **Circuit breaker implementation**: Should we make circuit breaker optional per subscription, or always-on? Some customers may prefer to control this at their end.\n\n3. **Database partitioning strategy**: Should we partition by time (monthly) or by subscription_id? Monthly is better for archival, but subscription-based is better for per-customer queries.\n\n4. **Ordering vs throughput**: How critical is event ordering for typical webhook use cases? Should we recommend against ordered delivery for high-volume scenarios?"
      }
    }
  ],
  "final_design": "",
  "status": "debating",
  "started_at": "2026-01-17T09:04:58.993529",
  "ended_at": "",
  "max_rounds": 2,
  "working_dir": ".",
  "current_round": 1,
  "round_times": [
    219.24748826026917
  ]
}