{
  "initial_prompt": "Design a simple caching layer with TTL support",
  "status": "debating",
  "rounds": 2,
  "started_at": "2026-01-17T10:01:59.200205",
  "ended_at": "2026-01-17T10:06:47.379851",
  "final_design": "## Design\n\n# Simple Caching Layer with TTL Support\n\n## Architecture Overview\n\nA lightweight, in-memory caching system with automatic expiration based on Time-To-Live (TTL) values. Uses a **single-data-structure approach** that eliminates heap synchronization complexity while maintaining efficient cleanup.\n\n**Core Components:**\n1. **Cache Store**: Thread-safe dictionary with integrated expiration tracking\n2. **Cache Entry**: Wrapper containing value, metadata, and expiration time\n3. **Expiration Buckets**: Time-based buckets for O(1) expiration tracking\n4. **Cleanup Scheduler**: Background task for bucket-based cleanup\n\n## Data Models\n\n```python\nfrom dataclasses import dataclass\nfrom typing import Any, Optional, Dict\nfrom datetime import datetime, timedelta\nfrom collections import OrderedDict\nimport threading\nimport time\n\n@dataclass\nclass CacheEntry:\n    \"\"\"Represents a single cache entry with expiration\"\"\"\n    value: Any\n    created_at: datetime\n    expires_at: datetime\n    access_count: int = 0\n    last_accessed: Optional[datetime] = None\n    \n    def is_expired(self, current_time: Optional[datetime] = None) -> bool:\n        \"\"\"Check expiration with optional time parameter for testing\"\"\"\n        check_time = current_time if current_time else datetime.now()\n        return check_time >= self.expires_at\n    \n    def mark_accessed(self) -> None:\n        self.access_count += 1\n        self.last_accessed = datetime.now()\n\n@dataclass\nclass CacheStats:\n    \"\"\"Cache statistics for monitoring\"\"\"\n    hits: int = 0\n    misses: int = 0\n    evictions: int = 0\n    expirations: int = 0\n    total_entries: int = 0\n    \n    @property\n    def hit_rate(self) -> float:\n        total = self.hits + self.misses\n        return self.hits / total if total > 0 else 0.0\n```\n\n## Core Interface\n\n```python\nclass Cache:\n    \"\"\"Thread-safe caching layer with TTL support\"\"\"\n    \n    def __init__(\n        self, \n        default_ttl: int = 300,  # seconds\n        max_size: Optional[int] = None,\n        cleanup_interval: int = 60,  # seconds\n        enable_lru: bool = True,  # Use LRU for eviction\n        bucket_size: int = 10  # Expiration bucket size in seconds\n    ):\n        \"\"\"\n        Args:\n            default_ttl: Default time-to-live in seconds (must be > 0)\n            max_size: Maximum number of entries (None = unlimited)\n            cleanup_interval: How often to run cleanup task (seconds)\n            enable_lru: If True, use LRU eviction; if False, use FIFO\n            bucket_size: Granularity of expiration buckets (seconds)\n        \n        Raises:\n            ValueError: If default_ttl <= 0 or cleanup_interval <= 0\n        \"\"\"\n        if default_ttl <= 0:\n            raise ValueError(\"default_ttl must be positive\")\n        if cleanup_interval <= 0:\n            raise ValueError(\"cleanup_interval must be positive\")\n        if bucket_size <= 0:\n            raise ValueError(\"bucket_size must be positive\")\n            \n        # Use OrderedDict for LRU support if enabled\n        self._store: Dict[str, CacheEntry] = OrderedDict() if enable_lru else {}\n        # Expiration buckets: {bucket_timestamp: set of keys}\n        self._expiration_buckets: Dict[int, set] = {}\n        # Reverse index: {key: bucket_timestamp}\n        self._key_to_bucket: Dict[str, int] = {}\n        \n        self._lock = threading.RLock()\n        self._default_ttl = default_ttl\n        self._max_size = max_size\n        self._stats = CacheStats()\n        self._cleanup_interval = cleanup_interval\n        self._bucket_size = bucket_size\n        self._cleanup_thread: Optional[threading.Thread] = None\n        self._shutdown_event = threading.Event()\n        self._enable_lru = enable_lru\n        self._started = False\n    \n    def get(self, key: str) -> Optional[Any]:\n        \"\"\"\n        Retrieve value from cache.\n        Returns None if key doesn't exist or has expired.\n        Thread-safe and updates LRU order if enabled.\n        \"\"\"\n        with self._lock:\n            if not self._started:\n                raise CacheShutdownError(\"Cache not started\")\n                \n            entry = self._store.get(key)\n            if entry is None:\n                self._stats.misses += 1\n                return None\n            \n            # Check expiration (lazy)\n            if entry.is_expired():\n                self._remove_entry(key)\n                self._stats.misses += 1\n                self._stats.expirations += 1\n                return None\n            \n            # Update access metadata\n            entry.mark_accessed()\n            self._stats.hits += 1\n            \n            # Move to end for LRU (OrderedDict optimization)\n            if self._enable_lru:\n                self._store.move_to_end(key)\n            \n            return entry.value\n    \n    def set(\n        self, \n        key: str, \n        value: Any, \n        ttl: Optional[int] = None\n    ) -> bool:\n        \"\"\"\n        Store value in cache with specified TTL.\n        \n        Args:\n            key: Cache key\n            value: Value to store (any picklable Python object)\n            ttl: Time-to-live in seconds (uses default if None)\n        \n        Returns:\n            True if successful, False if cache is full and eviction failed\n        \n        Raises:\n            ValueError: If ttl <= 0\n            CacheShutdownError: If cache is stopped\n        \"\"\"\n        if ttl is not None and ttl <= 0:\n            raise ValueError(\"TTL must be positive\")\n            \n        with self._lock:\n            if not self._started:\n                raise CacheShutdownError(\"Cache not started\")\n            \n            effective_ttl = ttl if ttl is not None else self._default_ttl\n            now = datetime.now()\n            expires_at = now + timedelta(seconds=effective_ttl)\n            \n            # If key exists, remove from old bucket\n            if key in self._store:\n                self._remove_from_bucket(key)\n            # Check capacity before adding new entry\n            elif self._max_size and len(self._store) >= self._max_size:\n                if not self._evict_one():\n                    return False  # Could not evict, cache full\n            \n            # Create new entry\n            entry = CacheEntry(\n                value=value,\n                created_at=now,\n                expires_at=expires_at,\n                last_accessed=now\n            )\n            \n            # Add to store\n            self._store[key] = entry\n            \n            # Add to expiration bucket\n            self._add_to_bucket(key, expires_at)\n            \n            self._stats.total_entries = len(self._store)\n            return True\n    \n    def delete(self, key: str) -> bool:\n        \"\"\"\n        Remove entry from cache. Returns True if existed.\n        Thread-safe operation.\n        \"\"\"\n        with self._lock:\n            if key in self._store:\n                self._remove_entry(key)\n                return True\n            return False\n    \n    def clear(self) -> None:\n        \"\"\"Remove all entries from cache. Thread-safe.\"\"\"\n        with self._lock:\n            self._store.clear()\n            self._expiration_buckets.clear()\n            self._key_to_bucket.clear()\n            self._stats.total_entries = 0\n    \n    def exists(self, key: str) -> bool:\n        \"\"\"Check if key exists and is not expired. Thread-safe.\"\"\"\n        with self._lock:\n            if key not in self._store:\n                return False\n            entry = self._store[key]\n            if entry.is_expired():\n                self._remove_entry(key)\n                self._stats.expirations += 1\n                return False\n            return True\n    \n    def get_stats(self) -> CacheStats:\n        \"\"\"Get cache statistics. Returns a copy for thread safety.\"\"\"\n        with self._lock:\n            return CacheStats(\n                hits=self._stats.hits,\n                misses=self._stats.misses,\n                evictions=self._stats.evictions,\n                expirations=self._stats.expirations,\n                total_entries=self._stats.total_entries\n            )\n    \n    def start(self) -> None:\n        \"\"\"\n        Start the background cleanup task.\n        \n        Raises:\n            RuntimeError: If already started\n        \"\"\"\n        with self._lock:\n            if self._started:\n                raise RuntimeError(\"Cache already started\")\n            \n            self._started = True\n            self._shutdown_event.clear()\n            self._cleanup_thread = threading.Thread(\n                target=self._cleanup_worker,\n                daemon=True,\n                name=\"CacheCleanup\"\n            )\n            self._cleanup_thread.start()\n    \n    def stop(self, timeout: float = 5.0) -> None:\n        \"\"\"\n        Stop the background cleanup task and cleanup resources.\n        \n        Args:\n            timeout: Maximum seconds to wait for cleanup thread to stop\n        \n        Raises:\n            RuntimeWarning: If cleanup thread doesn't stop within timeout\n        \"\"\"\n        with self._lock:\n            if not self._started:\n                return\n            \n            self._started = False\n            self._shutdown_event.set()\n        \n        # Wait for cleanup thread outside the lock\n        if self._cleanup_thread and self._cleanup_thread.is_alive():\n            self._cleanup_thread.join(timeout=timeout)\n            if self._cleanup_thread.is_alive():\n                import warnings\n                warnings.warn(\n                    f\"Cleanup thread did not stop within {timeout}s timeout\",\n                    RuntimeWarning\n                )\n    \n    def _add_to_bucket(self, key: str, expires_at: datetime) -> None:\n        \"\"\"\n        Add key to appropriate expiration bucket.\n        Must be called with lock held.\n        \"\"\"\n        # Calculate bucket timestamp (round down to bucket_size)\n        bucket_ts = int(expires_at.timestamp() / self._bucket_size) * self._bucket_size\n        \n        # Add to bucket\n        if bucket_ts not in self._expiration_buckets:\n            self._expiration_buckets[bucket_ts] = set()\n        self._expiration_buckets[bucket_ts].add(key)\n        \n        # Update reverse index\n        self._key_to_bucket[key] = bucket_ts\n    \n    def _remove_from_bucket(self, key: str) -> None:\n        \"\"\"\n        Remove key from its expiration bucket.\n        Must be called with lock held.\n        \"\"\"\n        if key not in self._key_to_bucket:\n            return\n        \n        bucket_ts = self._key_to_bucket[key]\n        \n        # Remove from bucket\n        if bucket_ts in self._expiration_buckets:\n            self._expiration_buckets[bucket_ts].discard(key)\n            # Clean up empty bucket\n            if not self._expiration_buckets[bucket_ts]:\n                del self._expiration_buckets[bucket_ts]\n        \n        # Remove from reverse index\n        del self._key_to_bucket[key]\n    \n    def _remove_entry(self, key: str) -> None:\n        \"\"\"\n        Remove entry from store and bucket.\n        Must be called with lock held.\n        \"\"\"\n        if key in self._store:\n            del self._store[key]\n            self._remove_from_bucket(key)\n            self._stats.total_entries = len(self._store)\n    \n    def _evict_one(self) -> bool:\n        \"\"\"\n        Evict one entry to make space.\n        Strategy: First try expired entries, then use LRU/FIFO.\n        Must be called with lock held.\n        \n        Returns:\n            True if eviction successful, False otherwise\n        \"\"\"\n        # First, try to remove expired entries from oldest buckets\n        now = datetime.now()\n        current_ts = int(now.timestamp() / self._bucket_size) * self._bucket_size\n        \n        # Check buckets up to current time\n        for bucket_ts in sorted(self._expiration_buckets.keys()):\n            if bucket_ts > current_ts:\n                break\n            \n            # Try to evict from this bucket\n            bucket = self._expiration_buckets[bucket_ts]\n            for key in list(bucket):  # Copy to avoid modification during iteration\n                if key in self._store:\n                    entry = self._store[key]\n                    if entry.is_expired(now):\n                        self._remove_entry(key)\n                        self._stats.evictions += 1\n                        self._stats.expirations += 1\n                        return True\n        \n        # No expired entries, evict based on access pattern\n        if not self._store:\n            return False\n        \n        if self._enable_lru:\n            # Remove least recently used (first item in OrderedDict)\n            key_to_evict = next(iter(self._store))\n        else:\n            # Remove first inserted (FIFO)\n            key_to_evict = next(iter(self._store))\n        \n        self._remove_entry(key_to_evict)\n        self._stats.evictions += 1\n        return True\n    \n    def _cleanup_expired(self) -> int:\n        \"\"\"\n        Remove expired entries from cache using bucket approach.\n        Returns number of entries removed.\n        Must be called with lock held.\n        \"\"\"\n        removed_count = 0\n        now = datetime.now()\n        current_ts = int(now.timestamp() / self._bucket_size) * self._bucket_size\n        \n        # Process all buckets up to current time\n        expired_buckets = [\n            bucket_ts for bucket_ts in self._expiration_buckets.keys()\n            if bucket_ts <= current_ts\n        ]\n        \n        for bucket_ts in expired_buckets:\n            bucket = self._expiration_buckets[bucket_ts]\n            \n            # Process all keys in bucket\n            for key in list(bucket):  # Copy to avoid modification during iteration\n                if key in self._store:\n                    entry = self._store[key]\n                    if entry.is_expired(now):\n                        del self._store[key]\n                        removed_count += 1\n                        self._stats.expirations += 1\n                \n                # Remove from bucket (whether expired or not, for consistency)\n                bucket.discard(key)\n                self._key_to_bucket.pop(key, None)\n            \n            # Remove empty bucket\n            if not bucket:\n                del self._expiration_buckets[bucket_ts]\n        \n        self._stats.total_entries = len(self._store)\n        return removed_count\n    \n    def _cleanup_worker(self) -> None:\n        \"\"\"Background thread worker for periodic cleanup.\"\"\"\n        while not self._shutdown_event.is_set():\n            try:\n                # Wait for cleanup interval or shutdown signal\n                if self._shutdown_event.wait(timeout=self._cleanup_interval):\n                    break  # Shutdown requested\n                \n                # Perform cleanup\n                with self._lock:\n                    if self._started:\n                        self._cleanup_expired()\n                        \n            except Exception as e:\n                # Log error but don't crash the thread\n                import warnings\n                warnings.warn(f\"Error in cleanup worker: {e}\", RuntimeWarning)\n```\n\n## Error Handling\n\n### Exception Types\n```python\nclass CacheError(Exception):\n    \"\"\"Base exception for cache operations\"\"\"\n    pass\n\nclass CacheShutdownError(CacheError):\n    \"\"\"Raised when operation attempted on stopped cache\"\"\"\n    pass\n```\n\n### Error Scenarios\n1. **Cache Full**: Return `False` from `set()` when cannot evict\n2. **Invalid TTL**: Raise `ValueError` immediately if TTL <= 0\n3. **Shutdown State**: Raise `CacheShutdownError` for operations on non-started cache\n4. **Thread Errors**: Log warnings and continue; cleanup failures don't crash\n5. **Invalid Parameters**: Validate in `__init__` and raise `ValueError`\n6. **Thread Timeout**: Warn if cleanup thread doesn't stop within timeout\n\n## Usage Example\n\n```python\n# Initialize cache\ncache = Cache(\n    default_ttl=300,      # 5 minutes default\n    max_size=1000,        # Limit to 1000 entries\n    cleanup_interval=60,  # Cleanup every minute\n    enable_lru=True,      # Use LRU eviction\n    bucket_size=10        # 10-second bucket granularity\n)\ncache.start()\n\ntry:\n    # Store values\n    cache.set(\"user:123\", {\"name\": \"Alice\"}, ttl=600)\n    cache.set(\"temp:token\", \"abc123\", ttl=30)\n    \n    # Retrieve values\n    user = cache.get(\"user:123\")  # Returns dict or None\n    exists = cache.exists(\"temp:token\")\n    \n    # Statistics\n    stats = cache.get_stats()\n    print(f\"Hit rate: {stats.hit_rate:.2%}\")\n    print(f\"Expirations: {stats.expirations}\")\n    \nfinally:\n    # Cleanup\n    cache.stop(timeout=5.0)\n```\n\n## Implementation Details\n\n### Thread Safety Strategy\n- **RLock Usage**: Reentrant lock allows same thread to acquire multiple times\n- **Lock Granularity**: Single lock protects store, buckets, and reverse index\n- **Lock Duration**: Minimal hold time - all operations are O(1) average case\n- **Atomic Updates**: Bucket and store updates happen within same lock acquisition\n- **Consistent State**: Reverse index ensures bucket-store synchronization\n\n### TTL Management with Expiration Buckets\n\n**Why Buckets Instead of Heap:**\n1. **No Synchronization Overhead**: Single data structure group (store + buckets + index) vs separate heap requiring careful sync\n2. **O(1) Insertion**: Adding to bucket is O(1) vs O(log n) heap insertion\n3. **O(1) Deletion**: Removing from bucket is O(1) vs O(n) heap search or lazy accumulation\n4. **Predictable Memory**: 3 structures with 1:1 key relationships vs heap with potential lazy deletion bloat\n5. **Batch Cleanup**: Process entire expired buckets at once, more cache-friendly\n\n**How It Works:**\n1. **Bucketing**: Round expiration times down to bucket_size (e.g., 10s)\n   - Entry expiring at 13:45:37 \u2192 bucket 13:45:30\n   - Entry expiring at 13:45:42 \u2192 bucket 13:45:40\n2. **Cleanup**: Every cleanup_interval, process all buckets <= current time\n3. **Granularity Trade-off**: Larger bucket_size = fewer buckets but less precise expiration\n\n### Eviction Strategy (when max_size is set)\n- **Priority 1**: Remove expired entries from oldest buckets (O(1) per entry)\n- **Priority 2**: LRU eviction using OrderedDict (O(1))\n- **Priority 3**: FIFO if LRU disabled (O(1))\n- **Triggered**: Before inserting new entry when at capacity\n\n### Performance Characteristics\n\n- **Time Complexity**:\n  - `get()`: O(1) average (OrderedDict move_to_end is O(1))\n  - `set()`: O(1) for bucket insertion\n  - `delete()`: O(1) for both store and bucket\n  - Cleanup: O(k) where k = entries in expired buckets\n  - Eviction: O(1) with LRU/FIFO\n\n- **Space Complexity**: \n  - Store: O(n)\n  - Buckets: O(n) keys across all buckets\n  - Reverse index: O(n) \n  - Total: O(3n) = O(n)\n\n**Memory Comparison:**\n- Heap approach: Store (n entries) + Heap (n entries) = ~2n objects\n- Bucket approach: Store (n entries) + Buckets (n keys) + Index (n mappings) = ~3n references\n- **But**: Bucket approach has simpler objects (sets/ints vs heap nodes), often smaller in practice\n\n## Testing Strategy\n\n1. **Unit Tests**:\n   - Basic get/set/delete operations\n   - TTL expiration (lazy and active)\n   - Bucket consistency after operations\n   - Thread safety (concurrent operations)\n   - Eviction behavior at max capacity\n   - Statistics accuracy\n   - Error handling (invalid TTL, operations on stopped cache)\n   - Bucket boundary cases (entries at exact bucket boundaries)\n\n2. **Integration Tests**:\n   - Long-running cleanup thread\n   - High-concurrency scenarios (100+ threads)\n   - Memory leak detection\n   - Bucket-store synchronization under load\n   - Mixed TTL values (short and long)\n\n3. **Edge Cases**:\n   - Minimum TTL (1 second)\n   - TTL smaller than bucket_size\n   - Very large TTL values\n   - Rapid set/delete cycles on same key\n   - Cache full with no evictable entries\n   - Starting/stopping multiple times\n   - Cleanup during heavy write load"
}